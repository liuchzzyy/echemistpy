{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biologic MPR File Reading Verification\n",
    "\n",
    "This notebook demonstrates step-by-step verification of reading BioLogic `.mpr` files using the optimized `BiologicMPTReader`.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Load `Biologic_GPCL.mpr` file\n",
    "2. Verify data structure and completeness\n",
    "3. Inspect all data columns\n",
    "4. Examine comprehensive metadata\n",
    "5. Validate data quality\n",
    "6. Visualize electrochemical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Import the BiologicMPTReader\n",
    "from echemistpy.utils.external.echem.biologic_reader import BiologicMPTReader\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MPR File\n",
    "\n",
    "Load the `Biologic_GPCL.mpr` file using the `BiologicMPTReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "file_path = Path(\"examples/echem/Biologic_GPCL.mpr\")\n",
    "\n",
    "# Check file exists\n",
    "if not file_path.exists():\n",
    "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "print(f\"File path: {file_path.absolute()}\")\n",
    "print(f\"File size: {file_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Create reader and load file\n",
    "reader = BiologicMPTReader()\n",
    "measurement = reader.read(file_path)\n",
    "\n",
    "print(f\"\\n‚úì Successfully loaded {file_path.name}\")\n",
    "print(f\"  Measurement type: {type(measurement).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Raw Data Structure\n",
    "\n",
    "Examine the structure of the loaded data including dimensions, coordinates, and data variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the xarray Dataset\n",
    "dataset = measurement.data.data\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "print(dataset)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Display dimensions\n",
    "print(\"\\nDIMENSIONS:\")\n",
    "for dim, size in dataset.dims.items():\n",
    "    print(f\"  {dim}: {size}\")\n",
    "\n",
    "# Display coordinates\n",
    "print(\"\\nCOORDINATES:\")\n",
    "for coord_name in dataset.coords:\n",
    "    coord = dataset.coords[coord_name]\n",
    "    print(f\"  {coord_name}: shape={coord.shape}, dtype={coord.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify All Data Columns\n",
    "\n",
    "List all available data columns with their properties using the new `get_column_info()` API method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new API method to get column information\n",
    "column_info = reader.get_column_info()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"DATA COLUMNS ({len(column_info)} total)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create a DataFrame for better display\n",
    "info_df = pd.DataFrame.from_dict(column_info, orient='index')\n",
    "print(info_df.to_string())\n",
    "\n",
    "# Display basic statistics for each column\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMN STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stats_data = []\n",
    "for col_name in dataset.data_vars:\n",
    "    values = dataset[col_name].values\n",
    "    stats_data.append({\n",
    "        'Column': col_name,\n",
    "        'Min': f\"{np.min(values):.6g}\",\n",
    "        'Max': f\"{np.max(values):.6g}\",\n",
    "        'Mean': f\"{np.mean(values):.6g}\",\n",
    "        'Std': f\"{np.std(values):.6g}\",\n",
    "        'Unit': column_info[col_name]['unit'] or 'N/A'\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Metadata\n",
    "\n",
    "Inspect comprehensive metadata including standard fields and MPR-specific information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata summary using the new API method\n",
    "metadata_summary = reader.get_metadata_summary()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"METADATA SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "pprint(metadata_summary, width=80)\n",
    "\n",
    "# Get full metadata\n",
    "full_meta = measurement.metadata.meta\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FULL METADATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display standard metadata\n",
    "print(\"\\nStandard Metadata:\")\n",
    "standard_keys = ['technique', 'sample_name', 'instrument', 'source_file', 'original_filename']\n",
    "for key in standard_keys:\n",
    "    if key in full_meta:\n",
    "        print(f\"  {key}: {full_meta[key]}\")\n",
    "\n",
    "# Display MPR-specific metadata\n",
    "print(\"\\nMPR-Specific Metadata:\")\n",
    "mpr_keys = [k for k in full_meta.keys() if k.startswith('mpr_')]\n",
    "for key in mpr_keys:\n",
    "    value = full_meta[key]\n",
    "    # Format large lists/dicts more compactly\n",
    "    if isinstance(value, (list, tuple)) and len(value) > 10:\n",
    "        print(f\"  {key}: [{len(value)} items]\")\n",
    "    elif isinstance(value, dict) and len(value) > 5:\n",
    "        print(f\"  {key}: {{{len(value)} keys}}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Detailed MPR Module Information\n",
    "\n",
    "Examine the MPR module structure in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mpr_modules' in full_meta:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"MPR MODULES\")\n",
    "    print(\"=\" * 80)\n",
    "    modules_df = pd.DataFrame(full_meta['mpr_modules'])\n",
    "    print(modules_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No MPR module information available\")\n",
    "\n",
    "# Display VMP settings if available\n",
    "if 'mpr_vmp_settings' in full_meta:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"VMP SETTINGS\")\n",
    "    print(\"=\" * 80)\n",
    "    pprint(full_meta['mpr_vmp_settings'], width=80)\n",
    "\n",
    "# Display flags dictionary if available\n",
    "if 'mpr_flags_dict' in full_meta:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FLAGS DICTIONARY\")\n",
    "    print(\"=\" * 80)\n",
    "    flags_df = pd.DataFrame([\n",
    "        {'Flag': k, 'Meaning': v} \n",
    "        for k, v in full_meta['mpr_flags_dict'].items()\n",
    "    ])\n",
    "    print(flags_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Validation\n",
    "\n",
    "Validate the loaded data for consistency and completeness using the new `validate_data()` API method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the new validation API method\n",
    "validation_results = reader.validate_data()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA VALIDATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nValidation Status: {'‚úì PASSED' if validation_results['is_valid'] else '‚úó FAILED'}\")\n",
    "print(f\"Number of rows: {validation_results['n_rows']}\")\n",
    "print(f\"Number of columns: {validation_results['n_columns']}\")\n",
    "print(f\"Has time column: {'‚úì' if validation_results['has_time'] else '‚úó'}\")\n",
    "\n",
    "if validation_results['issues']:\n",
    "    print(\"\\nIssues found:\")\n",
    "    for i, issue in enumerate(validation_results['issues'], 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"\\n‚úì No issues found - data is valid and consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Visualization\n",
    "\n",
    "Visualize key electrochemical data to verify the measurements are meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Time Series Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time data\n",
    "time_col = 'time/s'\n",
    "if time_col in dataset.coords:\n",
    "    time = dataset.coords[time_col].values\n",
    "elif time_col in dataset.data_vars:\n",
    "    time = dataset[time_col].values\n",
    "else:\n",
    "    raise ValueError(f\"Time column '{time_col}' not found\")\n",
    "\n",
    "# Find voltage and current columns\n",
    "voltage_cols = [col for col in dataset.data_vars if 'ewe' in col.lower() and '/v' in col.lower()]\n",
    "current_cols = [col for col in dataset.data_vars if 'i' in col.lower() and 'ma' in col.lower()]\n",
    "\n",
    "print(f\"Found voltage columns: {voltage_cols}\")\n",
    "print(f\"Found current columns: {current_cols}\")\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot voltage vs time\n",
    "if voltage_cols:\n",
    "    for col in voltage_cols[:3]:  # Plot up to 3 voltage columns\n",
    "        axes[0].plot(time, dataset[col].values, label=col, linewidth=1.5)\n",
    "    axes[0].set_ylabel('Voltage (V)', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend(loc='best')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_title('Voltage vs Time', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot current vs time\n",
    "if current_cols:\n",
    "    for col in current_cols[:3]:  # Plot up to 3 current columns\n",
    "        axes[1].plot(time, dataset[col].values, label=col, linewidth=1.5)\n",
    "    axes[1].set_ylabel('Current (mA)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend(loc='best')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_title('Current vs Time', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Time series plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Voltage vs Capacity (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find capacity columns\n",
    "capacity_cols = [\n",
    "    col for col in dataset.data_vars \n",
    "    if any(keyword in col.lower() for keyword in ['capacity', 'q charge', 'q discharge', '(q-qo)'])\n",
    "]\n",
    "\n",
    "print(f\"Found capacity columns: {capacity_cols}\")\n",
    "\n",
    "if capacity_cols and voltage_cols:\n",
    "    fig, axes = plt.subplots(1, len(capacity_cols[:2]), figsize=(14, 6))\n",
    "    if len(capacity_cols) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, cap_col in enumerate(capacity_cols[:2]):\n",
    "        capacity = dataset[cap_col].values\n",
    "        voltage = dataset[voltage_cols[0]].values\n",
    "        \n",
    "        axes[idx].plot(capacity, voltage, linewidth=1.5, color='darkblue')\n",
    "        axes[idx].set_xlabel(cap_col, fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel(voltage_cols[0], fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_title(f'Voltage vs {cap_col}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\n‚úì Voltage vs capacity plots generated\")\n",
    "else:\n",
    "    print(\"\\nCapacity data not available for plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Cycle Analysis (if cycle data available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cycle-related columns\n",
    "cycle_cols = [\n",
    "    col for col in dataset.data_vars \n",
    "    if any(keyword in col.lower() for keyword in ['cycle', 'half cycle', 'loop'])\n",
    "]\n",
    "\n",
    "print(f\"Found cycle columns: {cycle_cols}\")\n",
    "\n",
    "if cycle_cols:\n",
    "    cycle_col = cycle_cols[0]\n",
    "    cycles = dataset[cycle_col].values\n",
    "    unique_cycles = np.unique(cycles)\n",
    "    \n",
    "    print(f\"\\nCycle information:\")\n",
    "    print(f\"  Column: {cycle_col}\")\n",
    "    print(f\"  Number of unique cycles: {len(unique_cycles)}\")\n",
    "    print(f\"  Cycle range: {unique_cycles.min()} to {unique_cycles.max()}\")\n",
    "    \n",
    "    # Plot a few cycles if voltage and capacity data available\n",
    "    if voltage_cols and capacity_cols and len(unique_cycles) > 1:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Plot first 5 cycles\n",
    "        for cycle_num in unique_cycles[:5]:\n",
    "            mask = cycles == cycle_num\n",
    "            if mask.sum() > 0:\n",
    "                cap = dataset[capacity_cols[0]].values[mask]\n",
    "                volt = dataset[voltage_cols[0]].values[mask]\n",
    "                ax.plot(cap, volt, label=f'Cycle {int(cycle_num)}', linewidth=1.5, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel(capacity_cols[0], fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(voltage_cols[0], fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Voltage vs Capacity by Cycle', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"\\n‚úì Cycle analysis plots generated\")\n",
    "else:\n",
    "    print(\"\\nNo cycle data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Report\n",
    "\n",
    "Generate a comprehensive summary of the verification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"VERIFICATION SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìÅ File: {file_path.name}\")\n",
    "print(f\"   Size: {file_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"   Path: {file_path.absolute()}\")\n",
    "\n",
    "print(f\"\\nüìä Data Structure:\")\n",
    "print(f\"   Rows: {validation_results['n_rows']:,}\")\n",
    "print(f\"   Columns: {validation_results['n_columns']}\")\n",
    "print(f\"   Dimensions: {list(dataset.dims.keys())}\")\n",
    "\n",
    "print(f\"\\nüî¨ Measurement Information:\")\n",
    "print(f\"   Technique: {metadata_summary.get('ec_technique', 'N/A')}\")\n",
    "print(f\"   Sample: {metadata_summary.get('sample_name', 'N/A')}\")\n",
    "print(f\"   Instrument: {metadata_summary.get('instrument', 'N/A')}\")\n",
    "\n",
    "if 'mpr_version' in metadata_summary:\n",
    "    print(f\"\\nüìã MPR File Information:\")\n",
    "    print(f\"   Version: {metadata_summary.get('mpr_version', 'N/A')}\")\n",
    "    if 'mpr_npts' in metadata_summary:\n",
    "        print(f\"   Data points: {metadata_summary['mpr_npts']}\")\n",
    "    if 'mpr_start_date' in metadata_summary:\n",
    "        print(f\"   Start date: {metadata_summary['mpr_start_date']}\")\n",
    "    if 'mpr_end_date' in metadata_summary:\n",
    "        print(f\"   End date: {metadata_summary['mpr_end_date']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Validation Results:\")\n",
    "print(f\"   Status: {'PASSED ‚úì' if validation_results['is_valid'] else 'FAILED ‚úó'}\")\n",
    "print(f\"   Time column present: {'Yes ‚úì' if validation_results['has_time'] else 'No ‚úó'}\")\n",
    "if validation_results['issues']:\n",
    "    print(f\"   Issues: {len(validation_results['issues'])}\")\n",
    "    for issue in validation_results['issues']:\n",
    "        print(f\"     - {issue}\")\n",
    "else:\n",
    "    print(f\"   Issues: None ‚úì\")\n",
    "\n",
    "print(f\"\\nüìà Available Data Types:\")\n",
    "if voltage_cols:\n",
    "    print(f\"   Voltage columns: {len(voltage_cols)} ({', '.join(voltage_cols[:3])})\")\n",
    "if current_cols:\n",
    "    print(f\"   Current columns: {len(current_cols)} ({', '.join(current_cols[:3])})\")\n",
    "if capacity_cols:\n",
    "    print(f\"   Capacity columns: {len(capacity_cols)} ({', '.join(capacity_cols[:3])})\")\n",
    "if cycle_cols:\n",
    "    print(f\"   Cycle columns: {len(cycle_cols)} ({', '.join(cycle_cols)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì VERIFICATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nAll verification steps completed successfully!\")\n",
    "print(\"The BiologicMPTReader can correctly read and parse the MPR file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
