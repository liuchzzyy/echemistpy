{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345d7b86",
   "metadata": {},
   "source": [
    "## Operando Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649faac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T10:09:25.774063Z",
     "iopub.status.busy": "2024-04-25T10:09:25.773011Z",
     "iopub.status.idle": "2024-04-25T10:09:26.077980Z",
     "shell.execute_reply": "2024-04-25T10:09:26.077980Z",
     "shell.execute_reply.started": "2024-04-25T10:09:25.774063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- conding:utf-8 -*-\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from matplotlib import gridspec, ticker\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm.notebook import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121040b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure custom module Path is set before import\n",
    "sys.path.append(r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Python\\Figure\")\n",
    "from colors import tol_cmap, tol_cset  # type: ignore\n",
    "\n",
    "# 画图的初始设置\n",
    "plt.style.use(r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Python\\Figure\\liuchzzyy.mplstyle\")\n",
    "# print(plt.style.available)  # noqa: ERA001\n",
    "\n",
    "# xarray setting\n",
    "xr.set_options(\n",
    "    cmap_sequential=\"viridis\",\n",
    "    cmap_divergent=\"viridis\",\n",
    "    display_width=150,\n",
    ")  # viridis, gray\n",
    "\n",
    "# 颜色设定\n",
    "colors = tol_cset(\"vibrant\")\n",
    "if colors is not None:\n",
    "    colors = list(colors)\n",
    "else:\n",
    "    # Fallback colors in case tol_cset returns None\n",
    "    colors = [\"#0077BB\", \"#33BBEE\", \"#009988\", \"#EE7733\", \"#CC3311\", \"#EE3377\", \"#BBBBBB\"]\n",
    "if r\"sunset\" not in plt.colormaps():\n",
    "    cmap = tol_cmap(\"sunset\")\n",
    "    if isinstance(cmap, LinearSegmentedColormap):\n",
    "        plt.colormaps.register(cmap)\n",
    "if r\"rainbow_PuRd\" not in plt.colormaps():\n",
    "    cmap = tol_cmap(\"rainbow_PuRd\")\n",
    "    if isinstance(cmap, LinearSegmentedColormap):\n",
    "        plt.colormaps.register(cmap)  # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = Path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")\n",
    "\n",
    "# Set math font\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"custom\"\n",
    "mpl.rcParams[\"mathtext.rm\"] = \"Arial\"\n",
    "mpl.rcParams[\"mathtext.it\"] = \"Arial:italic\"\n",
    "mpl.rcParams[\"mathtext.bf\"] = \"Arial:bold\"\n",
    "mpl.rcParams[\"mathtext.sf\"] = \"Arial\"\n",
    "mpl.rcParams[\"mathtext.tt\"] = \"Arial\"\n",
    "mpl.rcParams[\"mathtext.cal\"] = \"Arial\"\n",
    "mpl.rcParams[\"mathtext.default\"] = \"regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333908d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def create_folders(base_path: Path, folder_name: str) -> Path:\n",
    "    folder_path = Path.joinpath(base_path, folder_name)\n",
    "    if not folder_path.exists():\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    return folder_path\n",
    "\n",
    "\n",
    "def data2map(df: pd.DataFrame, file_name: str, todisplay: bool = False, vmin: float = 2, vmax: float = 3.5):\n",
    "    fig = plt.figure(file_name, dpi=100)\n",
    "    ax = fig.add_subplot()\n",
    "    p1 = ax.matshow(\n",
    "        df.iloc[:, :],\n",
    "        cmap=\"jet\",\n",
    "        interpolation=\"nearest\",\n",
    "        interpolation_stage=\"rgba\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax + 1e-9,\n",
    "        aspect=(0.067 / 0.032),\n",
    "    )\n",
    "    cbar = plt.colorbar(p1, fraction=0.05, pad=0.01)  # noqa: F841\n",
    "    # cbar.ax.set_ylabel('Intensity', fontsize=9)  # noqa: ERA001\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if todisplay:\n",
    "        display(df.head(5))\n",
    "        plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def parse_log_file(filepath):\n",
    "    results = []\n",
    "    current_sample = None\n",
    "    start_time = None\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        timestamp = line[:23]\n",
    "        msg = line[26:].strip()\n",
    "\n",
    "        if \"Scan sample\" in msg:\n",
    "            current_sample = re.sub(r\"^INFO\\s+\", \"\", msg).replace(\"Scan sample \", \"\").strip()\n",
    "            start_time = timestamp\n",
    "\n",
    "        elif \"Scan done:\" in msg:\n",
    "            match = re.search(r\"scans_id:\\s*(\\d+)\\s*-\\s*(\\d+)\", msg)\n",
    "            if match:\n",
    "                scan_start = int(match.group(1))\n",
    "                scan_end = int(match.group(2))\n",
    "                results.append({\n",
    "                    \"Sample\": current_sample,\n",
    "                    \"Start Time\": start_time,\n",
    "                    \"End Time\": timestamp,\n",
    "                    \"Scan ID Start\": scan_start,\n",
    "                    \"Scan ID End\": scan_end,\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_experiment_metadata(folder_path, pattern=r\"**\\*.dat\"):\n",
    "    results = []\n",
    "\n",
    "    for file_path in Path(folder_path).glob(pattern):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        sample = file_path.stem.split(\"_\")[0]\n",
    "        element = file_path.stem.split(\"_\")[-3]\n",
    "        energy = file_path.stem.split(\"_\")[-1]\n",
    "\n",
    "        ScanID = []  # noqa: N806\n",
    "        Time = []  # noqa: N806\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith(\"#S \"):\n",
    "                # 提取 #S 行的第一个整数\n",
    "                match = re.match(r\"#S\\s+(\\d+)\", line)\n",
    "                if match:\n",
    "                    ScanID.append(int(match.group(1)))\n",
    "            elif line.startswith(\"#C\") and \"end\" in line.lower():\n",
    "                # 提取 'Acquisition ended at Wed Jul  5 16:50:07 2023' 中的时间\n",
    "                match = re.search(r\"\\w{3} \\w{3}\\s+\\d{1,2} \\d{2}:\\d{2}:\\d{2} \\d{4}\", line)\n",
    "                if match:\n",
    "                    Time.append(match.group(0))\n",
    "\n",
    "        for s, c in zip(ScanID, Time):\n",
    "            results.append({\"Sample\": sample, \"Element\": element, 'Energy':energy, \"ScanID\": s, \"Time\": c})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c115d5a9",
   "metadata": {},
   "source": [
    "### Echem, Mn4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7c68b",
   "metadata": {},
   "source": [
    "#### 匹配谱线的时间和电化学的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志文件读取所有的时间和ID\n",
    "log_folder = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\"  # noqa: RUF001\n",
    ")\n",
    "results = []\n",
    "for file in log_folder.glob(\"*.txt\"):\n",
    "    results.extend(parse_log_file(file))\n",
    "exp_df = pd.DataFrame(results)\n",
    "exp_df[[\"Scan ID Start\", \"Scan ID End\"]] = exp_df[[\"Scan ID Start\", \"Scan ID End\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "exp_df[[\"Start Time\", 'End Time']] = exp_df[[\"Start Time\", 'End Time']].apply(\n",
    "    pd.to_datetime, format=\"mixed\", errors=\"coerce\"\n",
    "    )\n",
    "exp_df.to_csv(path_out.joinpath(r\"log_metadata.csv\"), index=False, header=True)  # noqa: ERA001\n",
    "\n",
    "# 对应的实验的时间和ID\n",
    "folder = r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\"  # noqa: E501, RUF001\n",
    "exp_df2 = extract_experiment_metadata(folder)\n",
    "exp_df2[[\"Energy\", \"ScanID\"]] = exp_df2[[\"Energy\", \"ScanID\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")  # noqa: E501\n",
    "exp_df2[\"Time\"] = exp_df2[\"Time\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "exp_df2.to_csv(path_out.joinpath(r\"Time_Index_Spectrum.csv\"), index=False, header=True)  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对应实验上的电化学时间\n",
    "path_filelist = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\Echem\"  # noqa: E501, RUF001\n",
    "    ).glob(r\"*up*.txt\")\n",
    ")\n",
    "# 读取电化学数据\n",
    "echem = []\n",
    "for path_file in path_filelist:\n",
    "    with open(path_file, \"r\", encoding=\"latin_1\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Nb header lines\"):\n",
    "                line_skip = int(line.split(\":\")[1].strip())\n",
    "                break  # 发现后立即退出循环，提高效率\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path_file, sep=\"\\t\", comment=\"#\", skiprows=line_skip - 1, encoding=\"latin_1\", index_col=None, decimal=\".\"\n",
    "    ).dropna(axis=1, how=\"all\")  # noqa: E501\n",
    "    # # 转换数据格式\n",
    "    df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]] = df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]].apply(\n",
    "        pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "    df[\"time/s\"] = df[\"time/s\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "    df[\"cycle number\"] = df[\"cycle number\"].astype(float).astype(np.int16)\n",
    "    echem.append(df)\n",
    "\n",
    "# 选取每个数据的第一到第二圈\n",
    "for i in range(len(echem)):\n",
    "    echem[i] = echem[i][echem[i].iloc[:, 0].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ffcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "# 图\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.8)\n",
    "labels = [\n",
    "    [r\"$\\mathrm{1^{st}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{2^{nd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{3^{rd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{4^{th}}$\", None, None, None],\n",
    "]\n",
    "for i, data in enumerate(echem):\n",
    "    for j, idx in enumerate(data.iloc[:, 0].unique()):\n",
    "        temp = data[data.iloc[:, 0] == idx].reset_index(drop=True)\n",
    "        # 找到电压最小值的索引\n",
    "        idx_min = temp[\"Ewe/V\"].idxmin()\n",
    "        # 断开最小值前后的曲线\n",
    "        ax.plot(\n",
    "            temp.loc[:idx_min, \"Capacity/mA.h\"] * 1000 / 0.661,\n",
    "            temp.loc[:idx_min, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=labels[j][i],\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.plot(\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Capacity/mA.h\"] * 1000 / 0.661,\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=None,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "# 设置刻度线等格式\n",
    "ax.set_xlabel(r\"$\\mathrm{Capacity \\ (mAh \\,g^{-1}_{MnO2})}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_xlim(0, 300)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(base=50, offset=0))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=25, offset=0))\n",
    "\n",
    "ax.set_ylabel(r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_ylim(0.8, 2.0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.0))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.0))\n",
    "\n",
    "ax.tick_params(axis=\"both\", which='both', direction=\"out\", labelsize=9)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 0.6), ncols=1, frameon=False, labelcolor=\"linecolor\", fontsize=9)\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.07,\n",
    "    r\"$\\mathrm{0.5M \\ ZnSO_4}$\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=9,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "# 保存图片\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Upcell_0_300.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Upcell_0_600.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([echem[0]], ignore_index=True, axis=0)\n",
    "data.drop(columns=[\"Unnamed: 3\"], inplace=True, errors=\"ignore\")  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 谱线上的时间\n",
    "path_file = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Results\\V8\\case2_1stDischarge\"  # noqa: E501, RUF001\n",
    ")\n",
    "# 读取谱线的时间和ID\n",
    "time_spectrum = pd.read_csv(\n",
    "    Path.joinpath(path_file, r\"Time_Index_Spectrum.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=None,\n",
    "    header=0,\n",
    "    comment=\"#\",\n",
    "    date_format=\"%m/%d/%y %H:%M:%S.%f\",\n",
    "    parse_dates=[4],\n",
    ")\n",
    "time_spectrum[\"Time\"] = pd.to_datetime(time_spectrum[\"Time\"])\n",
    "time_spectrum[\"ScanID\"] = pd.to_numeric(time_spectrum[\"ScanID\"])\n",
    "# time_spectrum.info()  # noqa: ERA001\n",
    "\n",
    "# 匹配谱线和电化学上的时间\n",
    "echem_time = data[\"time/s\"].values\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"UpCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "\n",
    "index_spectrum_Mn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"UpCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "index_spectrum_Zn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "# 提取对应的电位和电流数据，并按电位排序\n",
    "Mn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"UpCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Mn_Voltage = data.loc[index_spectrum_Mn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Mn = pd.concat([Mn_Voltage, Mn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816\n",
    "\n",
    "Zn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"UpCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Zn_Voltage = data.loc[index_spectrum_Zn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Zn = pd.concat([Zn_Voltage, Zn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(7.0, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.3)\n",
    "\n",
    "ax.plot(data[\"time/s\"], data[\"Ewe/V\"], ls=\"-\", lw=1.0, c=colors[0], label=r\"Voltage\", zorder=0)\n",
    "\n",
    "# Mn\n",
    "for i, j in enumerate(index_voltage_Mn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Mn.loc[index_voltage_Mn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Mn[\"index\"][index_voltage_Mn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", alpha=1.0, zorder=1)\n",
    "\n",
    "# 添加索引文本标注\n",
    "# 只标记一次，选取 r'6533' 的点\n",
    "Index_special = [0, 5, 9, 15]\n",
    "energy = index_voltage_Mn['Energy']\n",
    "for i in [energy.unique()[0],]:\n",
    "\n",
    "    row_index = np.array([\n",
    "        np.abs(index_voltage_Mn[energy == i].loc[:, \"level_0\"] - val).argmin()\n",
    "        for val in Index_special\n",
    "    ])\n",
    "    row_index = index_voltage_Mn[energy == i].iloc[row_index, 1]\n",
    "\n",
    "    for j, idx in enumerate(row_index):\n",
    "        ax.scatter(\n",
    "            data[\"time/s\"].iloc[idx], data[\"Ewe/V\"].iloc[idx], c=colors[0], edgecolors=\"face\", marker=\"o\", zorder=2\n",
    "        )\n",
    "        ax.text(\n",
    "            data[\"time/s\"].iloc[idx],\n",
    "            data[\"Ewe/V\"].iloc[idx] + 0.03,\n",
    "            str(Index_special[j]),\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"bottom\",\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "# Zn\n",
    "for i, j in enumerate(index_voltage_Zn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Zn.loc[index_voltage_Zn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Zn[\"index\"][index_voltage_Zn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", marker='*', alpha=1.0, zorder=1)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax.set_ylim(0.85, 1.85)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.05))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.05))\n",
    "\n",
    "# 确保时间刻度从数据最开始时间显示\n",
    "ax.set_xlim(data[\"time/s\"].min() - pd.Timedelta(minutes=20), data[\"time/s\"].max() + pd.Timedelta(minutes=20))\n",
    "ax.set_xlabel(r\"Duration Time (hour)\", fontsize=11, labelpad=5)\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))  # 设定日期格式为小时:分钟  # noqa: ERA001\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # 设定日期格式为小时:分钟\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(byhour=range(0, 24, 1)))\n",
    "ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(0, 60, 30)))\n",
    "plt.xticks(rotation=60, horizontalalignment=\"right\")  # 旋转刻度标签，防止重叠\n",
    "\n",
    "ax.tick_params(\n",
    "    axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, left=True, labelleft=True, top=False, labeltop=False\n",
    ")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(0.5, 1), frameon=False, fontsize=11)\n",
    "\n",
    "ax.text(\n",
    "    0.17,\n",
    "    0.95,\n",
    "    r\"$\\text{1.322 mg cm}^{-2}$\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    color=colors[3],\n",
    "    va=\"top\",\n",
    "    ha=\"right\",\n",
    "    fontfamily=\"Arial\",\n",
    ")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_position((0, 0, 1, 1))\n",
    "ax2.set_box_aspect(0.3)\n",
    "\n",
    "ax2.plot(data[\"time/s\"], data[\"<I>/mA\"], ls=\"--\", lw=1.0, c=colors[3], label=r\"Current\", zorder=0)\n",
    "\n",
    "ax2.set_ylabel(\n",
    "    r\"Current (mA)\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax2.set_ylim(-0.2, 0.2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.1, offset=0))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.05, offset=0))\n",
    "ax2.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, right=True, labelright=True)\n",
    "\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(0.65, 1), frameon=False, fontsize=11)\n",
    "\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Upcell_1_300_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Upcell_1_600_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor(\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36cc3ea",
   "metadata": {},
   "source": [
    "### Echem, Mn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71964eed",
   "metadata": {},
   "source": [
    "#### 匹配谱线的时间和电化学的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5782f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志文件读取所有的时间和ID\n",
    "log_folder = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\"  # noqa: RUF001\n",
    ")\n",
    "results = []\n",
    "for file in log_folder.glob(\"*.txt\"):\n",
    "    results.extend(parse_log_file(file))\n",
    "exp_df = pd.DataFrame(results)\n",
    "exp_df[[\"Scan ID Start\", \"Scan ID End\"]] = exp_df[[\"Scan ID Start\", \"Scan ID End\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "exp_df[[\"Start Time\", 'End Time']] = exp_df[[\"Start Time\", 'End Time']].apply(\n",
    "    pd.to_datetime, format=\"mixed\", errors=\"coerce\"\n",
    "    )\n",
    "exp_df.to_csv(path_out.joinpath(r\"log_metadata.csv\"), index=False, header=True)  # noqa: ERA001\n",
    "\n",
    "# 对应的实验的时间和ID\n",
    "folder = r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\"  # noqa: E501, RUF001\n",
    "exp_df2 = extract_experiment_metadata(folder)\n",
    "exp_df2[[\"Energy\", \"ScanID\"]] = exp_df2[[\"Energy\", \"ScanID\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")  # noqa: E501\n",
    "exp_df2[\"Time\"] = exp_df2[\"Time\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "exp_df2.to_csv(path_out.joinpath(r\"Time_Index_Spectrum.csv\"), index=False, header=True)  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d337c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对应实验上的电化学时间\n",
    "path_filelist = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\Echem\"  # noqa: E501, RUF001\n",
    "    ).glob(r\"*down*.txt\")\n",
    ")\n",
    "# 读取电化学数据\n",
    "echem = []\n",
    "for path_file in path_filelist:\n",
    "    with open(path_file, \"r\", encoding=\"latin_1\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Nb header lines\"):\n",
    "                line_skip = int(line.split(\":\")[1].strip())\n",
    "                break  # 发现后立即退出循环，提高效率\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path_file, sep=\"\\t\", comment=\"#\", skiprows=line_skip - 1, encoding=\"latin_1\", index_col=None, decimal=\".\"\n",
    "    ).dropna(axis=1, how=\"all\")  # noqa: E501\n",
    "    # # 转换数据格式\n",
    "    df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]] = df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]].apply(\n",
    "        pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "    df[\"time/s\"] = df[\"time/s\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "    df[\"cycle number\"] = df[\"cycle number\"].astype(float).astype(np.int16)\n",
    "    echem.append(df)\n",
    "\n",
    "# 选取每个数据的第一到第二圈\n",
    "for i in range(len(echem)):\n",
    "    echem[i] = echem[i][echem[i].iloc[:, 0].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28968b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "# 图\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.8)\n",
    "labels = [\n",
    "    [r\"$\\mathrm{1^{st}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{2^{nd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{3^{rd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{4^{th}}$\", None, None, None],\n",
    "]\n",
    "for i, data in enumerate(echem):\n",
    "    for j, idx in enumerate(data.iloc[:, 0].unique()):\n",
    "        temp = data[data.iloc[:, 0] == idx].reset_index(drop=True)\n",
    "        # 找到电压最小值的索引\n",
    "        idx_min = temp[\"Ewe/V\"].idxmin()\n",
    "        # 断开最小值前后的曲线\n",
    "        ax.plot(\n",
    "            temp.loc[:idx_min, \"Capacity/mA.h\"] * 1000 / 0.653,\n",
    "            temp.loc[:idx_min, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=labels[j][i],\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.plot(\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Capacity/mA.h\"] * 1000 / 0.653,\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=None,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "# 设置刻度线等格式\n",
    "ax.set_xlabel(r\"$\\mathrm{Capacity \\ (mAh \\,g^{-1}_{MnO2})}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_xlim(0, 300)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(base=60, offset=0))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=30, offset=0))\n",
    "\n",
    "ax.set_ylabel(r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_ylim(0.8, 2.0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.0))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.0))\n",
    "\n",
    "ax.tick_params(axis=\"both\", which='both', direction=\"out\", labelsize=9)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 0.6), ncols=1, frameon=False, labelcolor=\"linecolor\", fontsize=9)\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.07,\n",
    "    r\"$\\mathrm{0.5M \\ ZnSO_4 + 0.2M \\ MnSO_4}$\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=9,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "# 保存图片\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Downcell_0_300.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Downcell_0_600.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([echem[0]], ignore_index=True, axis=0)\n",
    "data.drop(columns=[\"Unnamed: 3\"], inplace=True, errors=\"ignore\")  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f485e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 谱线上的时间\n",
    "path_file = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Results\\V8\\case2_1stDischarge\"  # noqa: E501, RUF001\n",
    ")\n",
    "# 读取谱线的时间和ID\n",
    "time_spectrum = pd.read_csv(\n",
    "    Path.joinpath(path_file, r\"Time_Index_Spectrum.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=None,\n",
    "    header=0,\n",
    "    comment=\"#\",\n",
    "    date_format=\"%m/%d/%y %H:%M:%S.%f\",\n",
    "    parse_dates=[4],\n",
    ")\n",
    "time_spectrum[\"Time\"] = pd.to_datetime(time_spectrum[\"Time\"])\n",
    "time_spectrum[\"ScanID\"] = pd.to_numeric(time_spectrum[\"ScanID\"])\n",
    "# time_spectrum.info()  # noqa: ERA001\n",
    "\n",
    "# 匹配谱线和电化学上的时间\n",
    "echem_time = data[\"time/s\"].values\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "\n",
    "index_spectrum_Mn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "index_spectrum_Zn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "# 提取对应的电位和电流数据，并按电位排序\n",
    "Mn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Mn_Voltage = data.loc[index_spectrum_Mn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Mn = pd.concat([Mn_Voltage, Mn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816\n",
    "\n",
    "Zn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Zn_Voltage = data.loc[index_spectrum_Zn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Zn = pd.concat([Zn_Voltage, Zn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(7.0, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.3)\n",
    "\n",
    "ax.plot(data[\"time/s\"], data[\"Ewe/V\"], ls=\"-\", lw=1.0, c=colors[0], label=r\"Voltage\", zorder=0)\n",
    "\n",
    "# Mn\n",
    "for i, j in enumerate(index_voltage_Mn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Mn.loc[index_voltage_Mn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Mn[\"index\"][index_voltage_Mn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", alpha=1.0, zorder=1)\n",
    "\n",
    "# 添加索引文本标注\n",
    "# 只标记一次，选取 r'6533' 的点\n",
    "Index_special = [0, 5, 9, 15]\n",
    "energy = index_voltage_Mn['Energy']\n",
    "for i in [energy.unique()[0],]:\n",
    "    row_index = np.array([\n",
    "        np.abs(index_voltage_Mn[energy == i].loc[:, \"level_0\"] - val).argmin()\n",
    "        for val in Index_special\n",
    "    ])\n",
    "    row_index = index_voltage_Mn[energy == i].iloc[row_index, 1]\n",
    "\n",
    "    for j, idx in enumerate(row_index):\n",
    "        ax.scatter(\n",
    "            data[\"time/s\"].iloc[idx], data[\"Ewe/V\"].iloc[idx], c=colors[0], edgecolors=\"face\", marker=\"o\", zorder=2\n",
    "        )\n",
    "        ax.text(\n",
    "            data[\"time/s\"].iloc[idx],\n",
    "            data[\"Ewe/V\"].iloc[idx] + 0.03,\n",
    "            str(Index_special[j]),\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"bottom\",\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "# Zn\n",
    "for i, j in enumerate(index_voltage_Zn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Zn.loc[index_voltage_Zn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Zn[\"index\"][index_voltage_Zn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", marker='*', alpha=1.0, zorder=1)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax.set_ylim(0.85, 1.85)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.05))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.05))\n",
    "\n",
    "# 确保时间刻度从数据最开始时间显示\n",
    "ax.set_xlim(data[\"time/s\"].min() - pd.Timedelta(minutes=20), data[\"time/s\"].max() + pd.Timedelta(minutes=20))\n",
    "ax.set_xlabel(r\"Duration Time (hour)\", fontsize=11, labelpad=5)\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))  # 设定日期格式为小时:分钟  # noqa: ERA001\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # 设定日期格式为小时:分钟\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(byhour=range(0, 24, 1)))\n",
    "ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(0, 60, 30)))\n",
    "plt.xticks(rotation=60, horizontalalignment=\"right\")  # 旋转刻度标签，防止重叠\n",
    "\n",
    "ax.tick_params(\n",
    "    axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, left=True, labelleft=True, top=False, labeltop=False\n",
    ")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(0.5, 1), frameon=False, fontsize=11)\n",
    "\n",
    "ax.text(\n",
    "    0.17,\n",
    "    0.95,\n",
    "    r\"$\\text{1.306 mg cm}^{-2}$\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    color=colors[3],\n",
    "    va=\"top\",\n",
    "    ha=\"right\",\n",
    "    fontfamily=\"Arial\",\n",
    ")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_position((0, 0, 1, 1))\n",
    "ax2.set_box_aspect(0.3)\n",
    "\n",
    "ax2.plot(data[\"time/s\"], data[\"<I>/mA\"], ls=\"--\", lw=1.0, c=colors[3], label=r\"Current\", zorder=0)\n",
    "\n",
    "ax2.set_ylabel(\n",
    "    r\"Current (mA)\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax2.set_ylim(-0.2, 0.2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.1, offset=0))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.05, offset=0))\n",
    "ax2.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, right=True, labelright=True)\n",
    "\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(0.65, 1), frameon=False, fontsize=11)\n",
    "\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Downcell_1_300_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case2_Downcell_1_600_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor(\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211350b",
   "metadata": {},
   "source": [
    "### Echem, Mn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d05d894",
   "metadata": {},
   "source": [
    "#### 匹配谱线的时间和电化学的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bd4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志文件读取所有的时间和ID\n",
    "log_folder = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\"  # noqa: RUF001\n",
    ")\n",
    "results = []\n",
    "for file in log_folder.glob(\"*.txt\"):\n",
    "    results.extend(parse_log_file(file))\n",
    "exp_df = pd.DataFrame(results)\n",
    "exp_df[[\"Scan ID Start\", \"Scan ID End\"]] = exp_df[[\"Scan ID Start\", \"Scan ID End\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "exp_df[[\"Start Time\", 'End Time']] = exp_df[[\"Start Time\", 'End Time']].apply(\n",
    "    pd.to_datetime, format=\"mixed\", errors=\"coerce\"\n",
    "    )\n",
    "exp_df.to_csv(path_out.joinpath(r\"log_metadata.csv\"), index=False, header=True)  # noqa: ERA001\n",
    "\n",
    "# 对应的实验的时间和ID\n",
    "folder = r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\"  # noqa: E501, RUF001\n",
    "exp_df2 = extract_experiment_metadata(folder)\n",
    "exp_df2[[\"Energy\", \"ScanID\"]] = exp_df2[[\"Energy\", \"ScanID\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")  # noqa: E501\n",
    "exp_df2[\"Time\"] = exp_df2[\"Time\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "exp_df2.to_csv(path_out.joinpath(r\"Time_Index_Spectrum.csv\"), index=False, header=True)  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dffd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对应实验上的电化学时间\n",
    "path_filelist = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\Echem\"  # noqa: E501, RUF001\n",
    "    ).glob(r\"*up*.txt\")\n",
    ")\n",
    "# 读取电化学数据\n",
    "echem = []\n",
    "for path_file in path_filelist:\n",
    "    with open(path_file, \"r\", encoding=\"latin_1\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Nb header lines\"):\n",
    "                line_skip = int(line.split(\":\")[1].strip())\n",
    "                break  # 发现后立即退出循环，提高效率\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path_file, sep=\"\\t\", comment=\"#\", skiprows=line_skip - 1, encoding=\"latin_1\", index_col=None, decimal=\".\"\n",
    "    ).dropna(axis=1, how=\"all\")  # noqa: E501\n",
    "    # # 转换数据格式\n",
    "    df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]] = df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]].apply(\n",
    "        pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "    df[\"time/s\"] = df[\"time/s\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "    df[\"cycle number\"] = df[\"cycle number\"].astype(float).astype(np.int16)\n",
    "    echem.append(df)\n",
    "\n",
    "# 选取每个数据的第一到第二圈\n",
    "for i in range(len(echem)):\n",
    "    echem[i] = echem[i][echem[i].iloc[:, 0].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "# 图\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.8)\n",
    "labels = [\n",
    "    [r\"$\\mathrm{1^{st}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{2^{nd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{3^{rd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{4^{th}}$\", None, None, None],\n",
    "]\n",
    "for i, data in enumerate(echem):\n",
    "    for j, idx in enumerate(data.iloc[:, 0].unique()):\n",
    "        temp = data[data.iloc[:, 0] == idx].reset_index(drop=True)\n",
    "        # 找到电压最小值的索引\n",
    "        idx_min = temp[\"Ewe/V\"].idxmin()\n",
    "        # 断开最小值前后的曲线\n",
    "        ax.plot(\n",
    "            temp.loc[:idx_min, \"Capacity/mA.h\"] * 1000 / 0.582,\n",
    "            temp.loc[:idx_min, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=labels[j][i],\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.plot(\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Capacity/mA.h\"] * 1000 / 0.582,\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=None,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "# 设置刻度线等格式\n",
    "ax.set_xlabel(r\"$\\mathrm{Capacity \\ (mAh \\,g^{-1}_{MnO2})}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_xlim(0, 300)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(base=50, offset=0))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=25, offset=0))\n",
    "\n",
    "ax.set_ylabel(r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_ylim(0.8, 2.0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.0))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.0))\n",
    "\n",
    "ax.tick_params(axis=\"both\", which='both', direction=\"out\", labelsize=9)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 0.6), ncols=1, frameon=False, labelcolor=\"linecolor\", fontsize=9)\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.07,\n",
    "    r\"$\\mathrm{0.5M \\ ZnSO_4}$\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=9,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "# 保存图片\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Upcell_0_300.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Upcell_0_600.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([echem[1], echem[0]], ignore_index=True, axis=0)\n",
    "data.drop(columns=[\"Unnamed: 3\"], inplace=True, errors=\"ignore\")  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13477b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 谱线上的时间\n",
    "path_file = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Results\\V8\\case1_1stCharge_1stDischarge\"  # noqa: E501, RUF001\n",
    ")\n",
    "# 读取谱线的时间和ID\n",
    "time_spectrum = pd.read_csv(\n",
    "    Path.joinpath(path_file, r\"Time_Index_Spectrum.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=None,\n",
    "    header=0,\n",
    "    comment=\"#\",\n",
    "    date_format=\"%m/%d/%y %H:%M:%S.%f\",\n",
    "    parse_dates=[4],\n",
    ")\n",
    "time_spectrum[\"Time\"] = pd.to_datetime(time_spectrum[\"Time\"])\n",
    "time_spectrum[\"ScanID\"] = pd.to_numeric(time_spectrum[\"ScanID\"])\n",
    "# time_spectrum.info()  # noqa: ERA001\n",
    "\n",
    "# 匹配谱线和电化学上的时间\n",
    "echem_time = data[\"time/s\"].values\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "\n",
    "index_spectrum_Mn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "index_spectrum_Zn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "# 提取对应的电位和电流数据，并按电位排序\n",
    "Mn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Mn_Voltage = data.loc[index_spectrum_Mn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Mn = pd.concat([Mn_Voltage, Mn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816\n",
    "\n",
    "Zn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Zn_Voltage = data.loc[index_spectrum_Zn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Zn = pd.concat([Zn_Voltage, Zn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(7.0, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.3)\n",
    "\n",
    "ax.plot(data[\"time/s\"], data[\"Ewe/V\"], ls=\"-\", lw=1.0, c=colors[0], label=r\"Voltage\", zorder=0)\n",
    "\n",
    "# Mn\n",
    "for i, j in enumerate(index_voltage_Mn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Mn.loc[index_voltage_Mn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Mn[\"index\"][index_voltage_Mn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", alpha=1.0, zorder=1)\n",
    "\n",
    "# 添加索引文本标注\n",
    "# 只标记一次，选取 r'6533' 的点\n",
    "Index_special = [0, 5, 8, 12, 17, 22, 27, 32, 40]\n",
    "energy = index_voltage_Mn['Energy']\n",
    "for i in [energy.unique()[0],]:\n",
    "    row_index = np.array([\n",
    "        np.abs(index_voltage_Mn[energy == i].loc[:, \"level_0\"] - val).argmin()\n",
    "        for val in Index_special\n",
    "    ])\n",
    "    row_index = index_voltage_Mn[energy == i].iloc[row_index, 1]\n",
    "\n",
    "    for j, idx in enumerate(row_index):\n",
    "        ax.scatter(\n",
    "            data[\"time/s\"].iloc[idx], data[\"Ewe/V\"].iloc[idx], c=colors[0], edgecolors=\"face\", marker=\"o\", zorder=2\n",
    "        )\n",
    "        ax.text(\n",
    "            data[\"time/s\"].iloc[idx],\n",
    "            data[\"Ewe/V\"].iloc[idx] + 0.03,\n",
    "            str(Index_special[j]),\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"bottom\",\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "# Zn\n",
    "for i, j in enumerate(index_voltage_Zn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Zn.loc[index_voltage_Zn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Zn[\"index\"][index_voltage_Zn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", marker='*', alpha=1.0, zorder=1)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax.set_ylim(0.85, 1.85)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.05))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.05))\n",
    "\n",
    "# 确保时间刻度从数据最开始时间显示\n",
    "ax.set_xlim(data[\"time/s\"].min() - pd.Timedelta(minutes=20), data[\"time/s\"].max() + pd.Timedelta(minutes=20))\n",
    "ax.set_xlabel(r\"Duration Time (hour)\", fontsize=11, labelpad=5)\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))  # 设定日期格式为小时:分钟  # noqa: ERA001\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # 设定日期格式为小时:分钟\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(byhour=range(0, 24, 1)))\n",
    "ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(0, 60, 30)))\n",
    "plt.xticks(rotation=60, horizontalalignment=\"right\")  # 旋转刻度标签，防止重叠\n",
    "\n",
    "ax.tick_params(\n",
    "    axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, left=True, labelleft=True, top=False, labeltop=False\n",
    ")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(0.5, 1), frameon=False, fontsize=11)\n",
    "\n",
    "ax.text(\n",
    "    0.17,\n",
    "    0.95,\n",
    "    r\"$\\text{1.164 mg cm}^{-2}$\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    color=colors[3],\n",
    "    va=\"top\",\n",
    "    ha=\"right\",\n",
    "    fontfamily=\"Arial\",\n",
    ")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_position((0, 0, 1, 1))\n",
    "ax2.set_box_aspect(0.3)\n",
    "\n",
    "ax2.plot(data[\"time/s\"], data[\"<I>/mA\"], ls=\"--\", lw=1.0, c=colors[3], label=r\"Current\", zorder=0)\n",
    "\n",
    "ax2.set_ylabel(\n",
    "    r\"Current (mA)\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax2.set_ylim(-0.2, 0.2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.1, offset=0))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.05, offset=0))\n",
    "ax2.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, right=True, labelright=True)\n",
    "\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(0.65, 1), frameon=False, fontsize=11)\n",
    "\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Upcell_1_300_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Upcell_1_600_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor(\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514a873",
   "metadata": {},
   "source": [
    "### Echem, Mn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb50e27",
   "metadata": {},
   "source": [
    "#### 匹配谱线的时间和电化学的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日志文件读取所有的时间和ID\n",
    "log_folder = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\"  # noqa: RUF001\n",
    ")\n",
    "results = []\n",
    "for file in log_folder.glob(\"*.txt\"):\n",
    "    results.extend(parse_log_file(file))\n",
    "exp_df = pd.DataFrame(results)\n",
    "exp_df[[\"Scan ID Start\", \"Scan ID End\"]] = exp_df[[\"Scan ID Start\", \"Scan ID End\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "exp_df[[\"Start Time\", 'End Time']] = exp_df[[\"Start Time\", 'End Time']].apply(\n",
    "    pd.to_datetime, format=\"mixed\", errors=\"coerce\"\n",
    "    )\n",
    "exp_df.to_csv(path_out.joinpath(r\"log_metadata.csv\"), index=False, header=True)  # noqa: ERA001\n",
    "\n",
    "# 对应的实验的时间和ID\n",
    "folder = r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\"  # noqa: E501, RUF001\n",
    "exp_df2 = extract_experiment_metadata(folder)\n",
    "exp_df2[[\"Energy\", \"ScanID\"]] = exp_df2[[\"Energy\", \"ScanID\"]].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")  # noqa: E501\n",
    "exp_df2[\"Time\"] = exp_df2[\"Time\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "exp_df2.to_csv(path_out.joinpath(r\"Time_Index_Spectrum.csv\"), index=False, header=True)  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对应实验上的电化学时间\n",
    "path_filelist = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\Echem\"  # noqa: E501, RUF001\n",
    "    ).glob(r\"*down*.txt\")\n",
    ")\n",
    "# 读取电化学数据\n",
    "echem = []\n",
    "for path_file in path_filelist:\n",
    "    with open(path_file, \"r\", encoding=\"latin_1\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Nb header lines\"):\n",
    "                line_skip = int(line.split(\":\")[1].strip())\n",
    "                break  # 发现后立即退出循环，提高效率\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path_file, sep=\"\\t\", comment=\"#\", skiprows=line_skip - 1, encoding=\"latin_1\", index_col=None, decimal=\".\"\n",
    "    ).dropna(axis=1, how=\"all\")  # noqa: E501\n",
    "    # # 转换数据格式\n",
    "    df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]] = df[[\"Ewe/V\", \"<I>/mA\", \"Capacity/mA.h\"]].apply(\n",
    "        pd.to_numeric, errors=\"coerce\"\n",
    "    )  # noqa: E501\n",
    "    df[\"time/s\"] = df[\"time/s\"].apply(pd.to_datetime, format=\"mixed\", errors=\"coerce\")\n",
    "    df[\"cycle number\"] = df[\"cycle number\"].astype(float).astype(np.int16)\n",
    "    echem.append(df)\n",
    "\n",
    "# 选取每个数据的第一到第二圈\n",
    "for i in range(len(echem)):\n",
    "    echem[i] = echem[i][echem[i].iloc[:, 0].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close(\"all\")\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "# 图\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.8)\n",
    "labels = [\n",
    "    [r\"$\\mathrm{1^{st}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{2^{nd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{3^{rd}}$\", None, None, None],\n",
    "    [r\"$\\mathrm{4^{th}}$\", None, None, None],\n",
    "]\n",
    "for i, data in enumerate(echem):\n",
    "    for j, idx in enumerate(data.iloc[:, 0].unique()):\n",
    "        temp = data[data.iloc[:, 0] == idx].reset_index(drop=True)\n",
    "        # 找到电压最小值的索引\n",
    "        idx_min = temp[\"Ewe/V\"].idxmin()\n",
    "        # 断开最小值前后的曲线\n",
    "        ax.plot(\n",
    "            temp.loc[:idx_min, \"Capacity/mA.h\"] * 1000 / 0.821,\n",
    "            temp.loc[:idx_min, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=labels[j][i],\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.plot(\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Capacity/mA.h\"] * 1000 / 0.821,\n",
    "            temp.loc[idx_min+5:temp.shape[0]-2, \"Ewe/V\"],\n",
    "            ls=\"-\",\n",
    "            lw=1.0,\n",
    "            c=colors[j],\n",
    "            label=None,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "# 设置刻度线等格式\n",
    "ax.set_xlabel(r\"$\\mathrm{Capacity \\ (mAh \\,g^{-1}_{MnO2})}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_xlim(0, 400)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(base=80, offset=0))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=40, offset=0))\n",
    "\n",
    "ax.set_ylabel(r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\", fontsize=11, labelpad=1.0)\n",
    "ax.set_ylim(0.8, 2.0)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.0))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.0))\n",
    "\n",
    "ax.tick_params(axis=\"both\", which='both', direction=\"out\", labelsize=9)\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 0.6), ncols=1, frameon=False, labelcolor=\"linecolor\", fontsize=9)\n",
    "ax.text(\n",
    "    0.05,\n",
    "    0.07,\n",
    "    r\"$\\mathrm{0.5M \\ ZnSO_4 + 0.2M \\ MnSO_4}$\",\n",
    "    ha=\"left\",\n",
    "    va=\"top\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=9,\n",
    "    c=\"k\",\n",
    ")\n",
    "\n",
    "# 保存图片\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Downcell_0_300.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Downcell_0_600.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([echem[1], echem[0]], ignore_index=True, axis=0)\n",
    "data.drop(columns=[\"Unnamed: 3\"], inplace=True, errors=\"ignore\")  # noqa: ERA001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb16a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 谱线上的时间\n",
    "path_file = Path(\n",
    "    r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Results\\V8\\case1_1stCharge_1stDischarge\"  # noqa: E501, RUF001\n",
    ")\n",
    "# 读取谱线的时间和ID\n",
    "time_spectrum = pd.read_csv(\n",
    "    Path.joinpath(path_file, r\"Time_Index_Spectrum.csv\"),\n",
    "    sep=\",\",\n",
    "    index_col=None,\n",
    "    header=0,\n",
    "    comment=\"#\",\n",
    "    date_format=\"%m/%d/%y %H:%M:%S.%f\",\n",
    "    parse_dates=[4],\n",
    ")\n",
    "time_spectrum[\"Time\"] = pd.to_datetime(time_spectrum[\"Time\"])\n",
    "time_spectrum[\"ScanID\"] = pd.to_numeric(time_spectrum[\"ScanID\"])\n",
    "# time_spectrum.info()  # noqa: ERA001\n",
    "\n",
    "# 匹配谱线和电化学上的时间\n",
    "echem_time = data[\"time/s\"].values\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "\n",
    "index_spectrum_Mn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "target_times = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    \"Time\"\n",
    "].values\n",
    "index_spectrum_Zn = [  # noqa: N816\n",
    "    np.abs(echem_time - t).argmin()\n",
    "    for t in target_times\n",
    "]\n",
    "\n",
    "# 提取对应的电位和电流数据，并按电位排序\n",
    "Mn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Mn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Mn_Voltage = data.loc[index_spectrum_Mn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Mn = pd.concat([Mn_Voltage, Mn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816\n",
    "\n",
    "Zn_info = time_spectrum.loc[\n",
    "    (time_spectrum[\"Element\"] == \"Zn\") &\n",
    "    (time_spectrum[\"Sample\"] == \"DownCell\"),\n",
    "    [\"Element\", \"Sample\", \"Energy\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "Zn_Voltage = data.loc[index_spectrum_Zn, [\"Ewe/V\", \"<I>/mA\"]].reset_index(drop=False)\n",
    "\n",
    "index_voltage_Zn = pd.concat([Zn_Voltage, Zn_info], axis=1).reset_index(drop=False, inplace=False).sort_values(by=\"level_0\")  # noqa: E501, N816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(7.0, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0])\n",
    "ax = subfig.add_axes((0, 0, 1, 1))\n",
    "ax.set_box_aspect(0.3)\n",
    "\n",
    "ax.plot(data[\"time/s\"], data[\"Ewe/V\"], ls=\"-\", lw=1.0, c=colors[0], label=r\"Voltage\", zorder=0)\n",
    "\n",
    "# Mn\n",
    "for i, j in enumerate(index_voltage_Mn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Mn.loc[index_voltage_Mn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Mn[\"index\"][index_voltage_Mn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", alpha=1.0, zorder=1)\n",
    "\n",
    "# 添加索引文本标注\n",
    "# 只标记一次，选取 r'6533' 的点\n",
    "Index_special = [0, 5, 9, 15, 19, 27, 34, 41]\n",
    "energy = index_voltage_Mn['Energy']\n",
    "for i in [energy.unique()[0],]:\n",
    "    row_index = np.array([\n",
    "        np.abs(index_voltage_Mn[energy == i].loc[:, \"level_0\"] - val).argmin()\n",
    "        for val in Index_special\n",
    "    ])\n",
    "    row_index = index_voltage_Mn[energy == i].iloc[row_index, 1]\n",
    "\n",
    "    for j, idx in enumerate(row_index):\n",
    "        ax.scatter(\n",
    "            data[\"time/s\"].iloc[idx], data[\"Ewe/V\"].iloc[idx], c=colors[0], edgecolors=\"face\", marker=\"o\", zorder=2\n",
    "        )\n",
    "        ax.text(\n",
    "            data[\"time/s\"].iloc[idx],\n",
    "            data[\"Ewe/V\"].iloc[idx] + 0.03,\n",
    "            str(Index_special[j]),\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"bottom\",\n",
    "            horizontalalignment=\"right\",\n",
    "        )\n",
    "\n",
    "# Zn\n",
    "for i, j in enumerate(index_voltage_Zn['Energy'].unique()):\n",
    "    selected_times = data[\"time/s\"].loc[index_voltage_Zn.loc[index_voltage_Zn[\"Energy\"] == j, \"index\"]]\n",
    "    selected_voltages = data[\"Ewe/V\"].loc[index_voltage_Zn[\"index\"][index_voltage_Zn[\"Energy\"] == j]]\n",
    "    ax.scatter(selected_times, selected_voltages, c=colors[i], edgecolors=\"face\", marker='*', alpha=1.0, zorder=1)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\n",
    "    r\"Voltage (V vs. Zn/Zn$\\mathrm{^{2\\!+}\\!)}$\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax.set_ylim(0.85, 1.85)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2, offset=0.05))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1, offset=0.05))\n",
    "\n",
    "# 确保时间刻度从数据最开始时间显示\n",
    "ax.set_xlim(data[\"time/s\"].min() - pd.Timedelta(minutes=20), data[\"time/s\"].max() + pd.Timedelta(minutes=20))\n",
    "ax.set_xlabel(r\"Duration Time (hour)\", fontsize=11, labelpad=5)\n",
    "# ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))  # 设定日期格式为小时:分钟  # noqa: ERA001\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))  # 设定日期格式为小时:分钟\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(byhour=range(0, 24, 1)))\n",
    "ax.xaxis.set_minor_locator(mdates.MinuteLocator(byminute=range(0, 60, 30)))\n",
    "plt.xticks(rotation=60, horizontalalignment=\"right\")  # 旋转刻度标签，防止重叠\n",
    "\n",
    "ax.tick_params(\n",
    "    axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, left=True, labelleft=True, top=False, labeltop=False\n",
    ")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(0.5, 1), frameon=False, fontsize=11)\n",
    "\n",
    "ax.text(\n",
    "    0.17,\n",
    "    0.95,\n",
    "    r\"$\\text{1.642 mg cm}^{-2}$\",\n",
    "    transform=ax.transAxes,\n",
    "    fontsize=12,\n",
    "    color=colors[3],\n",
    "    va=\"top\",\n",
    "    ha=\"right\",\n",
    "    fontfamily=\"Arial\",\n",
    ")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_position((0, 0, 1, 1))\n",
    "ax2.set_box_aspect(0.3)\n",
    "\n",
    "ax2.plot(data[\"time/s\"], data[\"<I>/mA\"], ls=\"--\", lw=1.0, c=colors[3], label=r\"Current\", zorder=0)\n",
    "\n",
    "ax2.set_ylabel(\n",
    "    r\"Current (mA)\",\n",
    "    fontsize=11,\n",
    ")\n",
    "ax2.set_ylim(-0.2, 0.2)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.1, offset=0))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.05, offset=0))\n",
    "ax2.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=9, right=True, labelright=True)\n",
    "\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(0.65, 1), frameon=False, fontsize=11)\n",
    "\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Downcell_1_300_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.savefig(\n",
    "    Path.joinpath(path_out, r\"OperandoMesh_case1_Downcell_1_600_echem.tif\"),\n",
    "    pad_inches=0.05,\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=600,\n",
    "    transparent=False,\n",
    "    pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    ")\n",
    "plt.gcf().set_facecolor(\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ff7e4",
   "metadata": {},
   "source": [
    "### Mn4, a+b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09977a48",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce94577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\UpCell_MnFree_2\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80962622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82241355",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6712ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88694db0",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants  # noqa: N806\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])  # type: ignore\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):  # type: ignore\n",
    "    temp = Mesh_data.iloc[i, 3:].values  # type: ignore\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff + Rb_Mn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb10c4e",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],  # noqa: E501\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c7cf5",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3915991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f1c98",
   "metadata": {},
   "source": [
    "### Mn3, a+b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261499b",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3651c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\DownCell_Mn_2\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8986e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306803d5",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a9e35",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e40d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants  # noqa: N806\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])  # type: ignore\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):  # type: ignore\n",
    "    temp = Mesh_data.iloc[i, 3:].values  # type: ignore\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff + Rb_Mn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adc00b",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8387db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],  # noqa: E501\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd99031",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de120c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc0eb4c",
   "metadata": {},
   "source": [
    "### Mn2, a+b=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f020a5",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\UpCell_MnFree\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d84869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040053c0",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a5e28",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53daf85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants  # noqa: N806\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])  # type: ignore\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):  # type: ignore\n",
    "    temp = Mesh_data.iloc[i, 3:].values  # type: ignore\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff + Rb_Mn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889a461",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd4b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],  # noqa: E501\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1da66",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b890781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff5a6f",
   "metadata": {},
   "source": [
    "### Mn1, a+b = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d214a66",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Results\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\DownCell_Mn\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1e51a",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db539d",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854a768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants  # noqa: N806\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])  # type: ignore\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "Mn2 = pd.DataFrame(index=Mesh_data.index, columns=[f\"Mn2+_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "MnO2 = pd.DataFrame(index=Mesh_data.index, columns=[f\"MnO2_{i}\" for i in range(Mesh_data.shape[1] - 3)])  # type: ignore\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):  # type: ignore\n",
    "    temp = Mesh_data.iloc[i, 3:].values  # type: ignore\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff + Rb_Mn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption\n",
    "        Mn2.loc[i] = deltamu * Ra_Mn * eff\n",
    "        MnO2.loc[i] = deltamu * Rb_Mn * (1 - eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae84fdd",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f906e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],  # noqa: E501\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f194d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, Mn2], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results_Mn2.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Mn_2_1\",\n",
    "        r\"Mn_2_2\",\n",
    "        r\"Mn_2_3\",\n",
    "        r\"Mn_2_4\",\n",
    "        r\"Mn_2_5\",\n",
    "    ],  # noqa: E501\n",
    ")\n",
    "# 保存数据\n",
    "pd.concat([Mesh_data, MnO2], axis=1, ignore_index=True).to_csv(  # type: ignore\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results_MnO2.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"MnO2_1\",\n",
    "        r\"MnO2_2\",\n",
    "        r\"MnO2_3\",\n",
    "        r\"MnO2_4\",\n",
    "        r\"MnO2_5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13915d00",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a065bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], Mn2], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results_Mn2\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], MnO2], axis=1, ignore_index=True)  # type: ignore\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results_MnO2\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c39afc",
   "metadata": {},
   "source": [
    "### Zn4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6c675",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb417d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\UpCell_MnFree_2\\Zn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a84da1",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"absorption1\", r\"absorption2\", r\"absorption3\", r\"absorption4\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14b454",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Zn = np.array([9651.4, 9669.4, 9674.6, 9703.9])\n",
    "Ra_Zn = np.array([0.01, 0.707741, 2.08340, 0.824950])  # Zn2+\n",
    "Rb_Zn = np.array([0.01, 0.963532, 1.71398, 0.824950])  # ZHS\n",
    "Ej_Zn = np.array([0.3860, 1.4200])  # edge jump of Ref. Zn2+, ZHS\n",
    "constants = [Ra_Zn, Rb_Zn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Zn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Zn * eff + Rb_Zn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446649aa",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8930a686",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f59deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd406417",
   "metadata": {},
   "source": [
    "### Zn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f6ec9",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\DownCell_Mn_2\\Zn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ed8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06453c03",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b58a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"absorption1\", r\"absorption2\", r\"absorption3\", r\"absorption4\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021aa23",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Zn = np.array([9651.4, 9669.4, 9674.6, 9703.9])\n",
    "Ra_Zn = np.array([0.01, 0.707741, 2.08340, 0.824950])  # Zn2+\n",
    "Rb_Zn = np.array([0.01, 0.963532, 1.71398, 0.824950])  # ZHS\n",
    "Ej_Zn = np.array([0.3860, 1.4200])  # edge jump of Ref. Zn2+, ZHS\n",
    "constants = [Ra_Zn, Rb_Zn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Zn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Zn * eff + Rb_Zn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe2e99",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d90112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207b0ad",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d99423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67dd2e",
   "metadata": {},
   "source": [
    "### Zn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53184554",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2523b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\UpCell_MnFree\\Zn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a3cbc",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"absorption1\", r\"absorption2\", r\"absorption3\", r\"absorption4\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39a0f6",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Zn = np.array([9651.4, 9669.4, 9674.6, 9703.9])\n",
    "Ra_Zn = np.array([0.01, 0.707741, 2.08340, 0.824950])  # Zn2+\n",
    "Rb_Zn = np.array([0.01, 0.963532, 1.71398, 0.824950])  # ZHS\n",
    "Ej_Zn = np.array([0.3860, 1.4200])  # edge jump of Ref. Zn2+, ZHS\n",
    "constants = [Ra_Zn, Rb_Zn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Zn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Zn * eff + Rb_Zn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7996d8",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a07c78",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ded753",
   "metadata": {},
   "source": [
    "### Zn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf42087",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e89096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\DownCell_Mn\\Zn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6490241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426ad8f",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f66b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"absorption1\", r\"absorption2\", r\"absorption3\", r\"absorption4\"],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52d648",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Zn = np.array([9651.4, 9669.4, 9674.6, 9703.9])\n",
    "Ra_Zn = np.array([0.01, 0.707741, 2.08340, 0.824950])  # Zn2+\n",
    "Rb_Zn = np.array([0.01, 0.963532, 1.71398, 0.824950])  # ZHS\n",
    "Ej_Zn = np.array([0.3860, 1.4200])  # edge jump of Ref. Zn2+, ZHS\n",
    "constants = [Ra_Zn, Rb_Zn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff + Rb * (1 - eff)) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "Zn2 = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "ZHS = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Zn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Zn * eff + Rb_Zn * (1 - eff))\n",
    "        absroption_result.loc[i] = fitted_absorption\n",
    "        Zn2.loc[i] = deltamu * Ra_Zn * eff\n",
    "        ZHS.loc[i] = deltamu * Rb_Zn * (1 - eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64854bbf",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f55271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6456148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, Zn2], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results_Zn2+.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"Zn2_1\",\n",
    "        r\"Zn2_2\",\n",
    "        r\"Zn2_3\",\n",
    "        r\"Zn2_4\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data, ZHS], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results_Zn2+.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"ZHS_1\",\n",
    "        r\"ZHS_2\",\n",
    "        r\"ZHS_3\",\n",
    "        r\"ZHS_4\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb496b",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9488d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], Zn2], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results_Zn2\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c373f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], ZHS], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results_ZHS\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de669461",
   "metadata": {},
   "source": [
    "### Mn4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9fc042",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\DownCell_Mn_2\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531c6a1",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f6a22",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfab657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff1, eff2, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff1 + Rb * eff2) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    eff1, eff2 = params[0], params[1]\n",
    "    penalty = 100 * (eff1 + eff2 - 1) ** 2\n",
    "    return mse + penalty\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff1\", \"eff2\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff1, eff2, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff1 + Rb_Mn * eff2)\n",
    "        absroption_result.loc[i] = fitted_absorption[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301e644",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf55aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff1\", r\"eff2\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91d2d4",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09df100",
   "metadata": {},
   "source": [
    "### Mn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a025c",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case2_1stDischarge\\UpCell_MnFree_2\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136b767",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7680c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8084e9fa",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff1, eff2, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff1 + Rb * eff2) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    eff1, eff2 = params[0], params[1]\n",
    "    penalty = 100 * (eff1 + eff2 - 1) ** 2\n",
    "    return mse + penalty\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff1\", \"eff2\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff1, eff2, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff1 + Rb_Mn * eff2)\n",
    "        absroption_result.loc[i] = fitted_absorption[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc43f9",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff1\", r\"eff2\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aeb999",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b69c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb0e21",
   "metadata": {},
   "source": [
    "### Mn2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a422831",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\UpCell_MnFree\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04faa70f",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 裁剪所有 absorption 列到最短长度\n",
    "min_len = min(len(df) for df in dfout)\n",
    "Mesh_data = np.array([df.iloc[:min_len, -1].values for df in dfout]).T\n",
    "\n",
    "# 裁剪前3列位置信息并合并\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:min_len, :3].reset_index(drop=True), pd.DataFrame(Mesh_data)], axis=1).copy()\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922d919",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a639597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff1, eff2, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff1 + Rb * eff2) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    eff1, eff2 = params[0], params[1]\n",
    "    penalty = 100 * (eff1 + eff2 - 1) ** 2\n",
    "    return mse + penalty\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff1\", \"eff2\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff1, eff2, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff1 + Rb_Mn * eff2)\n",
    "        absroption_result.loc[i] = fitted_absorption[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234c519",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff1\", r\"eff2\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598cc8ba",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de0042a",
   "metadata": {},
   "source": [
    "### Mn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470f913",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file = list(\n",
    "    Path(\n",
    "        r\"D:\\CHENG\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\PaperDos\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\DownCell_Mn\\Mn\"  # noqa: E501, RUF001\n",
    "    ).glob(\"*.dat\")\n",
    ")\n",
    "header = \"Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt\"  # noqa: E501\n",
    "headers = header.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff42426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder = create_folders(path_out, \"0_PureAbsorption\")\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    name_folder = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin = pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep=r\"\\s+\", comment=\"#\")\n",
    "\n",
    "    NaNindex = dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0 = dfin.loc[:, [\"a_i0_1\", \"a_i0_2\"]].sum(axis=1).values\n",
    "    i1 = dfin.loc[:, [\"a_i1_1\", \"a_i1_2\"]].sum(axis=1).values\n",
    "    dfin[\"absorption\"] = np.log(i0 / i1)  # type: ignore # natural base\n",
    "    df2out = dfin[columns := [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]].copy(deep=True)\n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(Path.joinpath(scan_folder, f\"{name_folder}_all.csv\"), sep=\",\", index=False)\n",
    "    dfout.append(df2out)\n",
    "\n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list = df2out[(df2out.loc[:, \"Pt_No\"] == df2out.loc[:, \"Pt_No\"].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()  # noqa: ERA001\n",
    "    # print(len(scancuttoff_index_list))  # noqa: ERA001\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:, \"absorption\"].min()\n",
    "    vmax = df2out.loc[:, \"absorption\"].max()\n",
    "    # print(vmin, vmax)  # noqa: ERA001\n",
    "\n",
    "    for i in trange(len(scancuttoff_index_list) - 1):\n",
    "        scan_name = f\"{name_folder}_{i + 1:04d}\"\n",
    "        path_file_folder = create_folders(scan_folder, name_folder)\n",
    "\n",
    "        a = scancuttoff_index_list[i]\n",
    "        b = scancuttoff_index_list[i + 1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True\n",
    "        )\n",
    "        slice_energy = df2out.iloc[a:b, :].pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        slice_energy.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        figure = data2map(slice_energy, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74dfb4",
   "metadata": {},
   "source": [
    "#### 数据的清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesh_data = np.asarray(list(dfout))[:, :, -1]\n",
    "Mesh_data = pd.concat([dfout[0].iloc[:, :3], pd.DataFrame(Mesh_data.T)], axis=1, ignore_index=True)\n",
    "Mesh_data.to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_data.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "    ],  # noqa: E501\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3985ce",
   "metadata": {},
   "source": [
    "#### PreEdge 和 PostEdge 的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 数据\n",
    "E_Mn = np.array([6533.0, 6553.2, 6557.5, 6561.5, 6610.8])\n",
    "Ra_Mn = np.array([0.01, 1.95670, 1.19821, 1.03919, 1.04312])\n",
    "Rb_Mn = np.array([0.01, 0.531024, 1.04128, 1.42149, 0.983545])\n",
    "constants = [Ra_Mn, Rb_Mn]\n",
    "\n",
    "\n",
    "# 拟合函数\n",
    "def model(params, energy, constants):\n",
    "    eff1, eff2, deltamu, pre_slope, pre_intercept = params\n",
    "    Ra, Rb = constants\n",
    "    return deltamu * (Ra * eff1 + Rb * eff2) + pre_slope * energy + pre_intercept\n",
    "\n",
    "\n",
    "# 目标函数\n",
    "def objective(params, energy, constants, data):\n",
    "    pred = model(params, energy, constants)\n",
    "    mse = np.mean((data - pred) ** 2)\n",
    "    eff1, eff2 = params[0], params[1]\n",
    "    penalty = 100 * (eff1 + eff2 - 1) ** 2\n",
    "    return mse + penalty\n",
    "\n",
    "\n",
    "# 初始化参数\n",
    "initial_guess = [0.5, 0.5, 1.0, 0.0, 0.0]\n",
    "bounds = [(0, 1), (0, 1), (0, np.inf), (-np.inf, np.inf), (-np.inf, np.inf)]\n",
    "\n",
    "# 初始化结果容器\n",
    "params_result = pd.DataFrame(index=Mesh_data.index, columns=[\"eff1\", \"eff2\", \"deltamu\", \"pre_slope\", \"pre_intercept\"])\n",
    "absroption_result = pd.DataFrame(index=Mesh_data.index, columns=[f\"Normal_{i}\" for i in range(Mesh_data.shape[1] - 3)])\n",
    "\n",
    "# 拟合过程\n",
    "for i in tqdm(Mesh_data.index):\n",
    "    temp = Mesh_data.iloc[i, 3:].values\n",
    "    result = minimize(\n",
    "        objective, initial_guess, args=(E_Mn, constants, temp), bounds=bounds, method=\"SLSQP\", options={\"maxiter\": 1000}\n",
    "    )\n",
    "\n",
    "    if result.success:\n",
    "        eff1, eff2, deltamu, pre_slope, pre_intercept = result.x\n",
    "        params_result.loc[i] = result.x\n",
    "        fitted_absorption = deltamu * (Ra_Mn * eff1 + Rb_Mn * eff2)\n",
    "        absroption_result.loc[i] = fitted_absorption[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc14b5",
   "metadata": {},
   "source": [
    "#### 验证结果的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "pd.concat([Mesh_data, absroption_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_results.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[\n",
    "        r\"Pt_No\",\n",
    "        r\"tripod_x\",\n",
    "        r\"tripod_z\",\n",
    "        r\"absorption1\",\n",
    "        r\"absorption2\",\n",
    "        r\"absorption3\",\n",
    "        r\"absorption4\",\n",
    "        r\"absorption5\",\n",
    "        r\"Normal1\",\n",
    "        r\"Normal2\",\n",
    "        r\"Normal3\",\n",
    "        r\"Normal4\",\n",
    "        r\"Normal5\",\n",
    "    ],\n",
    ")\n",
    "pd.concat([Mesh_data.iloc[:, :3], params_result], axis=1, ignore_index=True).to_csv(\n",
    "    Path.joinpath(path_out, \"Mesh_Absorption_params.csv\"),\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    "    header=[r\"Pt_No\", r\"tripod_x\", r\"tripod_z\", r\"eff1\", r\"eff2\", r\"deltamu\", r\"pre_slope\", r\"pre_intercept\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdf744",
   "metadata": {},
   "source": [
    "#### 保存成 tiff 图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb52464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "absroption_result_copy = pd.concat([Mesh_data.iloc[:, :3], absroption_result], axis=1, ignore_index=True)\n",
    "absroption_result_copy = absroption_result_copy.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# 每像素 0.5 μm -> 20,000 pixels per cm\n",
    "resolution = (20000 * 0.32, 10000 * 0.67)  # (x_res, y_res)\n",
    "\n",
    "scan_folder = create_folders(path_out, \"1_Results\")\n",
    "folder_names = [f.parts[-1][:-4] for f in path_master_file]\n",
    "\n",
    "for idx in trange(3, absroption_result_copy.shape[1]):\n",
    "    current_folder_name = folder_names[idx - 3]\n",
    "    path_file_folder = create_folders(scan_folder, current_folder_name)\n",
    "\n",
    "    columns = absroption_result_copy.columns\n",
    "    temp = absroption_result_copy.loc[:, [columns[0], columns[1], columns[2], columns[idx]]]\n",
    "    temp.columns = [\"Pt_No\", \"tripod_x\", \"tripod_z\", \"absorption\"]\n",
    "\n",
    "    scancutoff_indices = temp[temp[\"Pt_No\"] == temp[\"Pt_No\"].min()].index.tolist()\n",
    "\n",
    "    vmin = temp[\"absorption\"].min(skipna=True)\n",
    "    vmax = temp[\"absorption\"].max(skipna=True)\n",
    "    fig_list = []\n",
    "    for i in trange(len(scancutoff_indices) - 1):\n",
    "        scan_name = f\"{current_folder_name}_{i + 1:04d}\"\n",
    "        a, b = scancutoff_indices[i], scancutoff_indices[i + 1]\n",
    "\n",
    "        slice_df = temp.iloc[a:b, :]\n",
    "        slice_df.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}.csv\"), sep=\",\", index=True, header=True)\n",
    "\n",
    "        pivot = slice_df.pivot(index=\"tripod_z\", columns=\"tripod_x\", values=\"absorption\")\n",
    "        pivot.to_csv(Path.joinpath(path_file_folder, f\"{scan_name}_pivot.csv\"), sep=\",\", index=True, header=True)\n",
    "        fig_list.append(pivot.values)\n",
    "        fig = data2map(pivot, scan_name, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        fig.savefig(\n",
    "            Path.joinpath(path_file_folder, f\"{scan_name}.tif\"),\n",
    "            transparent=False,\n",
    "            pad_inches=0.05,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"},\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        tifffile.imwrite(\n",
    "            Path.joinpath(scan_folder, f\"{path_file_folder}.tiff\"),\n",
    "            np.stack(fig_list, axis=0),\n",
    "            photometric=\"minisblack\",\n",
    "            compression=\"lzw\",\n",
    "            resolution=resolution,\n",
    "            resolutionunit=\"CENTIMETER\",  # or \"INCH\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
