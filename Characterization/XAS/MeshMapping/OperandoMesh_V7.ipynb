{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649faac1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-25T10:09:25.774063Z",
     "iopub.status.busy": "2024-04-25T10:09:25.773011Z",
     "iopub.status.idle": "2024-04-25T10:09:26.077980Z",
     "shell.execute_reply": "2024-04-25T10:09:26.077980Z",
     "shell.execute_reply.started": "2024-04-25T10:09:25.774063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- conding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path as path\n",
    "import hyperspy.api as hs\n",
    "import sys\n",
    "import sympy as sy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121040b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "plt.style.use('default')\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333908d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(base_path: path, folder_name: str) -> path:\n",
    "    folder_path = path.joinpath(base_path, folder_name)\n",
    "    if not folder_path.exists():\n",
    "        folder_path.mkdir(parents=True, exist_ok=True)\n",
    "        # print(f\"Created folder: {folder_name}\")\n",
    "    return folder_path\n",
    "\n",
    "def data2map(df: pd.DataFrame, file_name: str, todisplay: bool =False, vmin: float =2, vmax: float =3.5):\n",
    "\n",
    "    fig = plt.figure(file_name, dpi=100)\n",
    "    ax = fig.add_subplot()\n",
    "    p1 = ax.matshow(df.iloc[:, :],\n",
    "                    cmap='jet',\n",
    "                    interpolation='nearest',\n",
    "                    interpolation_stage='rgba',\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax+1e-9,\n",
    "                    aspect=(0.067/0.032)\n",
    "                    )\n",
    "    cbar = plt.colorbar(p1, fraction=0.05, pad=0.01)\n",
    "    # cbar.ax.set_ylabel('Intensity')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    if todisplay:\n",
    "        display(df.head(5))\n",
    "        plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read all master files\n",
    "path_master_file=list(path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\Operando\\αMnO2\\MeshMapping\\2023-CLAESS\\Data\\case1_1stCharge_1stDischarge\\DownCell_Mn\\Mn').glob('*.dat'))\n",
    "header='Pt_No tripod_z tripod_x energyc a_i0i1_timer a_i0_1 a_i0_2 a_i1_1 a_i1_2 n_timer n_i0_1 n_i0_2 n_i1_1 n_i1_2 n_i2_1 n_i2_2 n_icr n_tcr n_sca1 n_sca2 n_sca3 n_sca4 sr_i_1 dt'\n",
    "headers=header.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff42426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 mesh 数据\n",
    "dfout = []\n",
    "scan_folder_A = create_folders(path_out, '0_PureAbsorption')\n",
    "# read data files and clean it\n",
    "for master_file_name in tqdm(path_master_file):\n",
    "    \n",
    "    name_folder_A = master_file_name.parts[-1][:-4]\n",
    "\n",
    "    dfin=pd.read_csv(master_file_name, index_col=None, header=None, names=headers, sep='\\s+', comment='#')\n",
    "\n",
    "    NaNindex=dfin.isnull().any(axis=1).to_numpy().nonzero()[0].tolist()\n",
    "    dfin.drop(NaNindex, axis=0, inplace=True)\n",
    "\n",
    "    # 计算 Absorption\n",
    "    i0=dfin.loc[:,['a_i0_1', 'a_i0_2']].sum(axis=1).values\n",
    "    i1=dfin.loc[:,['a_i1_1', 'a_i1_2']].sum(axis=1).values\n",
    "    dfin['absorption']=np.log(i0/i1) # natural base\n",
    "    df2out = dfin[columns:=['Pt_No','tripod_x','tripod_z','absorption']].copy(deep=True) \n",
    "\n",
    "    # 保存每个能量值下的数据\n",
    "    df2out.to_csv(path.joinpath(scan_folder_A, f\"{name_folder_A}_all.csv\"), sep=',', index=False)\n",
    "\n",
    "    dfout.append(df2out)\n",
    "    \n",
    "    # 新建对应的文件夹以及获取对应的位置\n",
    "    # 获取切片的引索序列\n",
    "    scancuttoff_index_list=df2out[(df2out.loc[:,'Pt_No']==df2out.loc[:,'Pt_No'].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()\n",
    "    # print(len(scancuttoff_index_list))\n",
    "    \n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = df2out.loc[:,'absorption'].values.min()\n",
    "    vmax = df2out.loc[:,'absorption'].values.max()\n",
    "    # print(vmin, vmax)\n",
    "    \n",
    "    for i in tqdm(range(len(scancuttoff_index_list)-1)):\n",
    "        \n",
    "        scan_name_A=f'{name_folder_A}_{i+1:04d}'\n",
    "        path_file_folder_A = create_folders(scan_folder_A, name_folder_A)\n",
    "\n",
    "        a=scancuttoff_index_list[i]\n",
    "        b=scancuttoff_index_list[i+1]\n",
    "\n",
    "        # 输出每个能量下的每次扫描数据，并画图\n",
    "        df2out.iloc[a:b, :].to_csv(path.joinpath(path_file_folder_A, f'{scan_name_A}.csv'), sep=',', index=True, header=True)    \n",
    "        slice_energy_A = df2out.iloc[a:b, :].pivot(index='tripod_z', columns='tripod_x', values='absorption')\n",
    "        slice_energy_A.to_csv(path.joinpath(path_file_folder_A,  f'{scan_name_A}_pivot.csv'), sep=',', index=True, header=True) \n",
    "        figure = data2map(slice_energy_A, scan_name_A, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(path.joinpath(path_file_folder_A, f'{scan_name_A}.tif'), transparent=False, pad_inches=0.05, bbox_inches='tight', dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee07fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 非线性最小二乘求解函数 -----------\n",
    "from scipy.optimize import least_squares\n",
    "def solve_by_nonlinear_least_squares(y_data, E, Ra, Rb):\n",
    "    def residual(x):\n",
    "        a, b, k, m, u = x\n",
    "        res = [a + b - 1, k * E[0] + m - y_data[0]]\n",
    "        for i in range(1, 5):\n",
    "            delta_E = E[i] - E[0]\n",
    "            lhs = a * Ra[i] + b * Rb[i]\n",
    "            rhs = (y_data[i] - k * delta_E - m) / u\n",
    "            res.append(lhs - rhs)\n",
    "        return res\n",
    "\n",
    "    x0 = [0.5, 0.5, 0.0, 0.0, 1.0]\n",
    "    bounds = ([0, 0, -np.inf, -np.inf, 1e-6], [1, 1, np.inf, np.inf, np.inf])\n",
    "    try:\n",
    "        result = least_squares(residual, x0, bounds=bounds)\n",
    "        return result.x.tolist() if result.success else None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6387c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mn 的结果计算\n",
    "# 文件夹和常量定义\n",
    "\n",
    "data_folder = create_folders(path_out, r'1_Normalization')\n",
    "\n",
    "a, b, k, m, u = sy.symbols('a, b, k, m, mu', real=True)\n",
    "E = [6533.0, 6553.2, 6557.5, 6561.5, 6610.8]\n",
    "Ra = [0.01, 1.95670, 1.19821, 1.03919, 1.04312]\n",
    "Rb = [0.01, 0.531024, 1.04128, 1.42149, 0.983545]\n",
    "Ej_Mn = [0.2265575, 0.5323902]\n",
    "\n",
    "# 获取子文件夹和 .csv 文件路径\n",
    "subfolders = sorted([f for f in scan_folder_A.iterdir() if f.is_dir()])\n",
    "datalist = [list(sub.glob('*[!_pivot].csv')) for sub in subfolders]\n",
    "\n",
    "# 符号变量定义\n",
    "a, b, k, m, u = sy.symbols('a b k m mu', real=True)\n",
    "variables = [a, b, k, m, u]\n",
    "\n",
    "# 常量\n",
    "E = [6533.0, 6553.2, 6557.5, 6561.5, 6610.8]\n",
    "Ra = [0.01, 1.95670, 1.19821, 1.03919, 1.04312]\n",
    "Rb = [0.01, 0.531024, 1.04128, 1.42149, 0.983545]\n",
    "\n",
    "sols = []\n",
    "\n",
    "for i in tqdm(range(len(datalist[0])-4), desc=\"Processing\"):\n",
    "    dfs = [pd.read_csv(datalist[j][i], sep=',', header=0, comment='#') for j in range(len(datalist))]\n",
    "    num_rows = len(dfs[0])\n",
    "\n",
    "    for j in tqdm(range(num_rows)):\n",
    "        y_data = [dfs[idx].iloc[j, 3] for idx in range(len(datalist))]\n",
    "\n",
    "        # --- 符号求解 ---\n",
    "        eqs = [\n",
    "            sy.Eq(a + b, 1),\n",
    "            sy.Eq(k * E[0] + m, y_data[0]),\n",
    "            sy.Eq(a * Ra[1] + b * Rb[1], (y_data[1] - k * (E[1] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[2] + b * Rb[2], (y_data[2] - k * (E[2] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[3] + b * Rb[3], (y_data[3] - k * (E[3] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[4] + b * Rb[4], (y_data[4] - k * (E[4] - E[0]) - m) / u),\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            sol = sy.solve(eqs, variables, dict=True)\n",
    "            if sol:\n",
    "                val = sol[0]\n",
    "                sols.append([val[a], val[b], val[k], val[m], val[u]])\n",
    "                continue  # 成功则跳过数值解\n",
    "        except:\n",
    "            # --- 非线性最小二乘解 ---\n",
    "            x_nls = solve_by_nonlinear_least_squares(y_data, E, Ra, Rb)\n",
    "            sols.append(x_nls if x_nls is not None else [0]*5)\n",
    "            continue\n",
    "    # 结果拼接\n",
    "    result = pd.concat([dfs[i].iloc[:, :3], pd.DataFrame(sols, columns=[r'C(Mn2+)', r'C(MnO2)', 'slope', 'intercept', 'DeltaU'])], axis=1)\n",
    "\n",
    "    # 标准化浓度\n",
    "    result[r'C(Mn2+)'] *= Ej_Mn[0]\n",
    "    result[r'C(MnO2)'] *= Ej_Mn[1]\n",
    "    result.to_csv(path.joinpath(data_folder, f'{i:04d}_EJ_ratio.csv'), sep=',', index=False, header=True)\n",
    "\n",
    "    # for ion, ej in zip(['Mn2+', 'MnO2'], Ej_Mn):\n",
    "    #     pivot_df = result.pivot(index='tripod_z', columns='tripod_x', values=f'C({ion})').astype(float)\n",
    "    #     pivot_df.to_csv(path.joinpath(data_folder, f'{i:04d}_NormalMn_{ion}_pivot.csv'), sep=',', index=True, header=True)\n",
    "    #     data2map(pivot_df.T, f'{i}_NormalMn_{ion}', todisplay=False, vmin=-0.03 * ej, vmax=ej)\n",
    "    #     plt.savefig(path.joinpath(data_folder, f'{i:04d}_NormalMn_{ion}.tif'), bbox_inches='tight', dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "    #     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba664e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mn 的结果计算\n",
    "# 文件夹和常量定义\n",
    "data_folder = create_folders(path_out, r'1_Normalization')\n",
    "\n",
    "a, b, k, m, u = sy.symbols('a, b, k, m, mu', real=True)\n",
    "E = [6533.0, 6553.2, 6557.5, 6561.5, 6610.8]\n",
    "Ra = [0.01, 1.95670, 1.19821, 1.03919, 1.04312]\n",
    "Rb = [0.01, 0.531024, 1.04128, 1.42149, 0.983545]\n",
    "Ej_Mn = [0.2265575, 0.5323902]\n",
    "\n",
    "# 获取子文件夹和 .csv 文件路径\n",
    "subfolders = sorted([f for f in scan_folder_A.iterdir() if f.is_dir()])\n",
    "datalist = [list(sub.glob('*[!_pivot].csv')) for sub in subfolders]\n",
    "\n",
    "# 主循环：每组数据文件\n",
    "for i in tqdm(range(len(datalist[0])), desc=\"Processing\"):\n",
    "    dfs = [pd.read_csv(datalist[j][i], sep=',', header=0, comment='#') for j in range(len(datalist))]\n",
    "    sols = []\n",
    "\n",
    "    # 遍历每个数据点进行符号计算\n",
    "    for j in range(len(dfs[0])):\n",
    "        eqs = [\n",
    "            sy.Eq(a + b, 1),\n",
    "            sy.Eq(k * E[0] + m, dfs[0].iloc[j, 3]),\n",
    "            sy.Eq(a * Ra[1] + b * Rb[1], (dfs[1].iloc[j, 3] - k * (E[1] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[2] + b * Rb[2], (dfs[2].iloc[j, 3] - k * (E[2] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[3] + b * Rb[3], (dfs[3].iloc[j, 3] - k * (E[3] - E[0]) - m) / u),\n",
    "            sy.Eq(a * Ra[4] + b * Rb[4], (dfs[4].iloc[j, 3] - k * (E[4] - E[0]) - m) / u),\n",
    "        ]\n",
    "        try:\n",
    "            sol = sy.solve(eqs, [a, b, k, u], dict=True)\n",
    "\n",
    "            if not sol:\n",
    "                continue\n",
    "            else:\n",
    "                sol = sol[0]  # 获取第一个解\n",
    "                diff = (sol[a] * Ra[3] + sol[b] * Rb[3]) - (dfs[3].iloc[j, 3] - dfs[0].iloc[j, 3] - sol[k] * (E[3] - E[0])) / sol[u]\n",
    "                sols.append([sol[a], sol[b], sol[k], sol[u], diff])\n",
    "\n",
    "        except Exception as e:\n",
    "            # 如果求解失败或无解，填入 NaN\n",
    "            sols.append([float('nan')] * len(dfs))\n",
    "\n",
    "    # 结果拼接\n",
    "    result = pd.concat([dfs[i].iloc[:, :3], pd.DataFrame(sols, columns=[r'C(Mn2+)', r'C(MnO2)', 'Background_Slope', 'DeltaU', 'Diff(a+b)'])], axis=1)\n",
    "    result.to_csv(path.joinpath(data_folder, f'{i:04d}_NormalMn_all_ratio.csv'), sep=',', index=False, header=True)\n",
    "\n",
    "    # 标准化浓度\n",
    "    result[r'C(Mn2+)'] *= Ej_Mn[0]\n",
    "    result[r'C(MnO2)'] *= Ej_Mn[1]\n",
    "\n",
    "    for ion, ej in zip(['Mn2+', 'MnO2'], Ej_Mn):\n",
    "        pivot_df = result.pivot(index='tripod_z', columns='tripod_x', values=f'C({ion})').astype(float)\n",
    "        pivot_df.to_csv(path.joinpath(data_folder, f'{i:04d}_NormalMn_{ion}_pivot.csv'), sep=',', index=True, header=True)\n",
    "        data2map(pivot_df.T, f'{i}_NormalMn_{ion}', todisplay=False, vmin=-0.03 * ej, vmax=ej)\n",
    "        plt.savefig(path.joinpath(data_folder, f'{i:04d}_NormalMn_{ion}.tif'), bbox_inches='tight', dpi=600, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "        plt.close()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1ca1b-a384-4fa4-a8ea-f163e411b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里只处理 <Mn - pre edge> 的形式\n",
    "dfout = dfout\n",
    "# display(dfout)\n",
    "pre_edge_folder = create_folders(path_out, 'post-pre')\n",
    "\n",
    "# caclulations of relative intensity comparing to (pre-edge)\n",
    "post_pre_Mn = dfout[4]['absorption'] - dfout[0]['absorption'] # post - pre_edge of Mn\n",
    "Mn2_pre_Mn = dfout[1]['absorption'] - dfout[0]['absorption'] # Mn(II) - pre_edge\n",
    "Mn3_pre_Mn = dfout[2]['absorption'] - dfout[0]['absorption'] # Mn(III) - pre_edge\n",
    "Mn4_pre_Mn = dfout[3]['absorption'] - dfout[0]['absorption'] # Mn(IV) - pre_edge\n",
    "\n",
    "post_pre_Zn = dfout[8]['absorption'] - dfout[5]['absorption'] # post - pre_edge of Zn\n",
    "ZHS_pre_Zn = dfout[6]['absorption'] - dfout[5]['absorption'] # ZHS - pre_edge\n",
    "Zn2_pre_Zn = dfout[7]['absorption'] - dfout[5]['absorption'] # Zn(II) - pre_edge\n",
    "\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Mn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'post_pre_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn2_pre_Mn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Mn2_pre_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn3_pre_Mn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Mn3_pre_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn4_pre_Mn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Mn4_pre_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Zn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'post_pre_Zn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], ZHS_pre_Zn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'ZHS_pre_Zn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Zn2_pre_Zn], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Zn2_pre_Zn_all.dat'),index=None, sep= ' ')\n",
    "\n",
    "Mn_III_IV = Mn3_pre_Mn/Mn4_pre_Mn\n",
    "Mn_L_S = (2*Mn2_pre_Mn)/(Mn3_pre_Mn+Mn4_pre_Mn)\n",
    "Zn_ZHS_II = ZHS_pre_Zn/Zn2_pre_Zn\n",
    "\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn_III_IV], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Mn_III_IV_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn_L_S], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Mn_L_S_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Zn_ZHS_II], axis = 1).dropna().to_csv(path.join(pre_edge_folder,'Zn_ZHS_II_all.dat'),index=None, sep= ' ')\n",
    "\n",
    "# 把每一个合并的文件读取当中的每一小部分，然后画图\n",
    "Datalist=glob.glob(path.join(pre_edge_folder,file_key))\n",
    "\n",
    "for Data_file in Datalist:\n",
    "    # building a folder for each energy file\n",
    "    name_folder_B =path.split(Data_file)[-1][:-8]\n",
    "    path_file_folder_B = create_folders(pre_edge_folder, name_folder_B)\n",
    "\n",
    "    # reading in file and splitting into scans\n",
    "    dfin2 = pd.read_csv(Data_file, engine = 'c', sep='\\s+', index_col = None, header = 0, comment=\"#\")\n",
    "    scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()\n",
    "    # print(dfin2)\n",
    "    print(len(scancuttoff_index_list))\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = dfin2.loc[:,'absorption'].values.min()\n",
    "    vmax = dfin2.loc[:,'absorption'].values.max()\n",
    "    print(vmin,vmax)\n",
    "\n",
    "    for i in range(len(scancuttoff_index_list)):\n",
    "        scan_name_B= name_folder_B+'_%s'%\"{:04d}\".format(i+1)\n",
    "\n",
    "        if i==0:\n",
    "            a=0\n",
    "            b=scancuttoff_index_list[i+1]\n",
    "        else:\n",
    "            a=scancuttoff_index_list[i-1]\n",
    "            b=scancuttoff_index_list[i]\n",
    "        # if i==0:\n",
    "        #     a=0\n",
    "        #     b=scancuttoff_index_list[i]  + 1\n",
    "        # else:\n",
    "        #     a=scancuttoff_index_list[i-1] + 1\n",
    "        #     b=scancuttoff_index_list[i] + 1\n",
    "\n",
    "        slice_energy_B = dfin2.iloc[a:b, :].pivot(index='tripod_z', columns='tripod_x', values='absorption')\n",
    "        slice_energy_B.to_csv(path.join(path_file_folder_B,  scan_name_B+'.dat'), sep=' ', index=True, header=True) \n",
    "        # slice_energy_B.to_csv(path.join(path_file_folder_B,  scan_name_B+'.dat'), sep=' ', index=None, header=None)\n",
    "        figure = data2map(slice_energy_B, scan_name_B, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(path.join(path_file_folder_B, scan_name_B+'.tif'), bbox_inches='tight', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3613a3-9669-4b47-b6c5-0606bc3958d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这里只处理 <Mn(II) - pre_edge / post - pre_edge> 的形式\n",
    "dfout = dfout\n",
    "# display(dfout)\n",
    "norm_pre_edge_folder = create_folders(path_out, 'norm_post-pre')\n",
    "\n",
    "# caclulations of relative intensity comparing to (pre-edge)\n",
    "post_pre_Mn = dfout[4]['absorption'] - dfout[0]['absorption'] # post - pre_edge of Mn\n",
    "\n",
    "Mn2_norm_Mn = (dfout[1]['absorption'] - dfout[0]['absorption'])/post_pre_Mn  # Mn(II) - pre_edge / post - pre_edge\n",
    "Mn3_norm_Mn = (dfout[2]['absorption'] - dfout[0]['absorption'])/post_pre_Mn  # Mn(III) - pre_edge / post - pre_edge\n",
    "Mn4_norm_Mn = (dfout[3]['absorption'] - dfout[0]['absorption'])/post_pre_Mn  # Mn(IV) - pre_edge / post - pre_edge\n",
    "\n",
    "post_pre_Zn = dfout[8]['absorption'] - dfout[5]['absorption']  # post - pre_edge of Zn\n",
    "\n",
    "ZHS_norm_Zn = (dfout[6]['absorption'] - dfout[5]['absorption'])/post_pre_Zn   # ZHS - pre_edge\n",
    "Zn2_norm_Zn = (dfout[7]['absorption'] - dfout[5]['absorption'])/post_pre_Zn   # Zn(II) - pre_edge\n",
    "\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Mn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'post_pre_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn2_norm_Mn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'Mn2_norm_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn3_norm_Mn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'Mn3_norm_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Mn4_norm_Mn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'Mn4_norm_Mn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Zn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'post_pre_Zn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], ZHS_norm_Zn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'ZHS_norm_Zn_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], Zn2_norm_Zn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'Zn2_norm_Zn_all.dat'),index=None, sep= ' ')\n",
    "\n",
    "norm_Mn_III_IV = Mn3_norm_Mn/Mn4_norm_Mn\n",
    "norm_Mn_L_S = (2*Mn2_norm_Mn)/(Mn3_norm_Mn+Mn4_norm_Mn)\n",
    "norm_Zn_ZHS_II = ZHS_norm_Zn/Zn2_norm_Zn\n",
    "\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Mn_III_IV], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'norm_Mn_III_IV_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Mn_L_S], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'norm_Mn_L_S_all.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Zn_ZHS_II], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder,'norm_Zn_ZHS_II_all.dat'),index=None, sep= ' ')\n",
    "\n",
    "# 把每一个合并的文件读取当中的每一小部分，然后画图\n",
    "\n",
    "Datalist=glob.glob(path.join(norm_pre_edge_folder,file_key))\n",
    "\n",
    "for Data_file in Datalist:\n",
    "    # building a folder for each energy file\n",
    "    name_folder_D =path.split(Data_file)[-1][:-8]\n",
    "    path_file_folder_D = create_folders(norm_pre_edge_folder, name_folder_D)\n",
    "\n",
    "    # reading in file and splitting into scans\n",
    "    dfin2 = pd.read_csv(Data_file, engine = 'c', sep='\\s+', index_col = None, header = 0, comment=\"#\")\n",
    "    scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()\n",
    "    # print(dfin2)\n",
    "    print(len(scancuttoff_index_list))\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = dfin2.loc[:,'absorption'].values.min()\n",
    "    vmax = dfin2.loc[:,'absorption'].values.max()\n",
    "    print(vmin,vmax)\n",
    "\n",
    "    for i in range(len(scancuttoff_index_list)):\n",
    "        scan_name_D= name_folder_D+'_%s'%\"{:04d}\".format(i+1)\n",
    "\n",
    "        if i==0:\n",
    "            a=0\n",
    "            b=scancuttoff_index_list[i+1]\n",
    "        else:\n",
    "            a=scancuttoff_index_list[i-1]\n",
    "            b=scancuttoff_index_list[i]\n",
    "        # if i==0:\n",
    "        #     a=0\n",
    "        #     b=scancuttoff_index_list[i]  + 1\n",
    "        # else:\n",
    "        #     a=scancuttoff_index_list[i-1] + 1\n",
    "        #     b=scancuttoff_index_list[i] + 1\n",
    "\n",
    "        slice_energy_D = dfin2.iloc[a:b, :].pivot(index='tripod_z', columns='tripod_x', values='absorption')\n",
    "        slice_energy_D.to_csv(path.join(path_file_folder_D,  scan_name_D+'.dat'), sep=' ', index=True, header=True) \n",
    "        # slice_energy_B.to_csv(path.join(path_file_folder_D,  scan_name_D+'.dat'), sep=' ', index=None, header=None)\n",
    "        figure = data2map(slice_energy_D, scan_name_D, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(path.join(path_file_folder_D, scan_name_D+'.tif'), bbox_inches='tight', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f65f8c-2e30-4d6e-b03e-db528af9d879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这里只处理 <Mn(II) - pre_edge / post - pre_edge> 的形式，而且扣除掉一些极端点\n",
    "dfout = dfout\n",
    "# display(dfout)\n",
    "norm_pre_edge_folder_E = create_folders(path_out, 'norm_post-pre_E')\n",
    "\n",
    "# caclulations of relative intensity comparing to (post-edge - pre-edge)\n",
    "post_pre_Mn = dfout[4]['absorption'] - dfout[0]['absorption']  # post - pre_edge of Mn\n",
    "Mn2_pre_Mn = dfout[1]['absorption'] - dfout[0]['absorption']   # Mn(II) - pre_edge\n",
    "Mn3_pre_Mn = dfout[2]['absorption'] - dfout[0]['absorption']   # Mn(III) - pre_edge\n",
    "Mn4_pre_Mn = dfout[3]['absorption'] - dfout[0]['absorption']   # Mn(IV) - pre_edge\n",
    "\n",
    "post_pre_Zn = dfout[8]['absorption'] - dfout[5]['absorption']  # post - pre_edge of Zn\n",
    "ZHS_pre_Zn = dfout[6]['absorption'] - dfout[5]['absorption']   # ZHS - pre_edge\n",
    "Zn2_pre_Zn = dfout[7]['absorption'] - dfout[5]['absorption']   # Zn(II) - pre_edge\n",
    "\n",
    "norm_Mn_III_IV = Mn3_norm_Mn/Mn4_norm_Mn\n",
    "norm_Mn_L_S = (2*Mn2_norm_Mn)/(Mn3_norm_Mn+Mn4_norm_Mn)\n",
    "norm_Zn_ZHS_II = ZHS_norm_Zn/Zn2_norm_Zn\n",
    "\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Mn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder_E,'post_pre_Mn_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], post_pre_Zn], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder_E,'post_pre_Zn_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Mn_III_IV], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder_E,'norm_Mn_III_IV_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Mn_L_S], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder_E,'norm_Mn_L_S_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([dfout[0][columns:=['Pt_No','tripod_x','tripod_z']], norm_Zn_ZHS_II], axis = 1).dropna().to_csv(path.join(norm_pre_edge_folder_E,'norm_Zn_ZHS_II_all_E.dat'),index=None, sep= ' ')\n",
    "\n",
    "# 筛选出那些奇怪的点\n",
    "invalidindex = post_pre_Mn.index.where((post_pre_Mn < -0.05)|(post_pre_Mn > 0.05)).dropna() # True vaule\n",
    "post_pre_Mn = post_pre_Mn.iloc[post_pre_Mn.index.isin(invalidindex)]\n",
    "Mn2_pre_Mn = Mn2_pre_Mn.iloc[Mn2_pre_Mn.index.isin(invalidindex)]\n",
    "Mn3_pre_Mn = Mn3_pre_Mn.iloc[Mn3_pre_Mn.index.isin(invalidindex)]\n",
    "Mn4_pre_Mn = Mn4_pre_Mn.iloc[Mn4_pre_Mn.index.isin(invalidindex)]\n",
    "\n",
    "Mn_II = Mn2_pre_Mn/post_pre_Mn\n",
    "Mn_III = Mn3_pre_Mn/post_pre_Mn\n",
    "Mn_IV = Mn4_pre_Mn/post_pre_Mn\n",
    "\n",
    "# Mn_III_IV = Mn3_pre_Mn/Mn4_pre_Mn\n",
    "# Mn_L_S = (2*Mn2_pre_Mn)/(Mn3_pre_Mn+Mn4_pre_Mn)\n",
    "\n",
    "\n",
    "invalidindex_Zn = post_pre_Zn.index.where(post_pre_Zn > 0.02).dropna() # True vaule\n",
    "post_pre_Zn  = post_pre_Zn.iloc[post_pre_Zn.index.isin(invalidindex_Zn)]\n",
    "ZHS_pre_Zn = ZHS_pre_Zn.iloc[ZHS_pre_Zn.index.isin(invalidindex_Zn)]\n",
    "Zn2_pre_Zn = Zn2_pre_Zn.iloc[Zn2_pre_Zn.index.isin(invalidindex_Zn)]\n",
    "\n",
    "ZHS = ZHS_pre_Zn/post_pre_Zn\n",
    "Zn_II = Zn2_pre_Zn/post_pre_Zn\n",
    "\n",
    "# Zn_ZHS_II = ZHS/Zn_II\n",
    "\n",
    "# position\n",
    "pos_Mn = dfout[0].iloc[dfout[0].index.isin(invalidindex)][columns:=['Pt_No','tripod_x','tripod_z']]\n",
    "pos_Zn = dfout[5].iloc[dfout[5].index.isin(invalidindex)][columns:=['Pt_No','tripod_x','tripod_z']]\n",
    "\n",
    "pd.concat([pos_Mn,Mn_II], axis = 1, ignore_index = False).dropna().to_csv(path.join(norm_pre_edge_folder_E,'Mn_II_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([pos_Mn,Mn_III], axis = 1, ignore_index = False).dropna().to_csv(path.join(norm_pre_edge_folder_E,'Mn_III_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([pos_Mn,Mn_IV], axis = 1, ignore_index = False).dropna().to_csv(path.join(norm_pre_edge_folder_E,'Mn_IV_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([pos_Zn,Zn_II], axis = 1, ignore_index = False).dropna().to_csv(path.join(norm_pre_edge_folder_E,'Zn_II_all_E.dat'),index=None, sep= ' ')\n",
    "pd.concat([pos_Zn,ZHS], axis = 1, ignore_index = False).dropna().to_csv(path.join(norm_pre_edge_folder_E,'ZHS_all_E.dat'),index=None, sep= ' ')\n",
    "\n",
    "# 把每一个合并的文件读取当中的每一小部分，然后画图\n",
    "Datalist=glob.glob(path.join(norm_pre_edge_folder_E,file_key))\n",
    "\n",
    "for Data_file in Datalist:\n",
    "    # building a folder for each energy file\n",
    "    name_folder_E =path.split(Data_file)[-1][:-10]\n",
    "    path_file_folder_E = create_folders(norm_pre_edge_folder_E, name_folder_E)\n",
    "\n",
    "    # reading in file and splitting into scans\n",
    "    dfin2 = pd.read_csv(Data_file, engine = 'c', sep='\\s+', index_col = None, header = 0, comment=\"#\")\n",
    "    scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].min())].index.tolist()\n",
    "    # scancuttoff_index_list=dfin2[(dfin2.loc[:,'Pt_No']==dfin2.loc[:,'Pt_No'].max())].index.tolist()\n",
    "    # print(dfin2)\n",
    "    print(scancuttoff_index_list)\n",
    "\n",
    "    # finding global min and max intensity cheapo way for transmission\n",
    "    vmin = dfin2.loc[:,'absorption'].values.min()\n",
    "    vmax = dfin2.loc[:,'absorption'].values.max()\n",
    "    print(vmin,vmax)\n",
    "\n",
    "    for i in range(len(scancuttoff_index_list)):\n",
    "        scan_name_E= name_folder_E+'_%s'%\"{:04d}\".format(i+1)\n",
    "\n",
    "        if i==0:\n",
    "            a=0\n",
    "            b=scancuttoff_index_list[i+1]\n",
    "        else:\n",
    "            a=scancuttoff_index_list[i-1]\n",
    "            b=scancuttoff_index_list[i]\n",
    "        # if i==0:\n",
    "        #     a=0\n",
    "        #     b=scancuttoff_index_list[i]  + 1\n",
    "        # else:\n",
    "        #     a=scancuttoff_index_list[i-1] + 1\n",
    "        #     b=scancuttoff_index_list[i] + 1\n",
    "\n",
    "        slice_energy_E = dfin2.iloc[a:b, :].pivot(index='tripod_z', columns='tripod_x', values='absorption')\n",
    "        slice_energy_E.to_csv(path.join(path_file_folder_E,  scan_name_E+'.dat'), sep=' ', index=True, header=True) \n",
    "        # slice_energy_E.to_csv(path.join(path_file_folder_E,  scan_name_E+'.dat'), sep=' ', index=None, header=None)\n",
    "        figure = data2map(slice_energy_E, scan_name_E, todisplay=False, vmin=vmin, vmax=vmax)\n",
    "        figure.savefig(path.join(path_file_folder_E, scan_name_E+'.tif'), bbox_inches='tight', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d95f1c-a286-45b6-80ce-07d468d38bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
