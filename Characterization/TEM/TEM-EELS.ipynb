{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0964033d-0672-495d-8840-ba3777149993",
   "metadata": {},
   "source": [
    "## TEM-EELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671d575-84ba-493a-b2a1-16595024baee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import hyperspy.api as hs\n",
    "from pathlib import Path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135da17-ebe9-4a11-92d0-405a47084c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset # type: ignore\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4ce28-1c24-47fd-8d4a-c927dcdc3802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "def add_sizebar(ax, size, bardata, color, barunits=None):\n",
    "    if isinstance(bardata, float):\n",
    "        if  not isinstance(barunits, str):\n",
    "            raise ValueError(\"barunits must be provided if bardata is a float.\")\n",
    "        asb = AnchoredSizeBar(ax.transData,\n",
    "                        size / bardata,\n",
    "                        '{} {}'.format(size, barunits),\n",
    "                        loc='lower left',\n",
    "                        pad=0.1, borderpad=0.5, sep=1,\n",
    "                        frameon=False,\n",
    "                        color=color,\n",
    "                        label_top=True,\n",
    "                        fontproperties={'size':9})\n",
    "        ax.add_artist(asb)\n",
    "    else:\n",
    "        if len(bardata.axes_manager.navigation_shape) == 2:\n",
    "            barsize = bardata.axes_manager.navigation_axes[0].scale\n",
    "            unit = bardata.axes_manager.navigation_axes[0].units\n",
    "        elif len(bardata.axes_manager.signal_shape) == 2:\n",
    "            barsize = bardata.axes_manager.signal_axes[0].scale\n",
    "            unit = bardata.axes_manager.signal_axes[0].units\n",
    "        asb = AnchoredSizeBar(ax.transData,\n",
    "                            size / barsize,  # type: ignore\n",
    "                            '{} {}'.format(size, unit),  # type: ignore\n",
    "                            loc='lower left',\n",
    "                            pad=0.1, borderpad=0.5, sep=1,\n",
    "                            frameon=False,\n",
    "                            color=color,\n",
    "                            label_top=True,\n",
    "                            fontproperties={'size':9})\n",
    "        ax.add_artist(asb)\n",
    "    return asb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3211b-3d48-45cb-9392-7806a6cc72b7",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c256df-ee15-46f0-a74f-b33c2189e6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_file = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\TEM\\ExSitu\\αMnO2\\Charge\\1st0.9V\\αMnO2 + PVDF + SP\\1M ZnSO4 + 1M MnSO4\\2024-EMCA\\EELS\\Data')\n",
    "file = path.joinpath(path_file, r'SI1_80pA_10ms', r'STEM SI.dm4')\n",
    "eels_list = hs.load(file) # type: ignore\n",
    "eels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f45c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in eels_list:\n",
    "    if len(file.axes_manager.shape) >= 2:\n",
    "        if len(file.axes_manager.navigation_shape) == 2:\n",
    "            if file.axes_manager.navigation_axes[0].units == r'µm':\n",
    "                file.axes_manager.convert_units(axes=\"navigation\", units='nm', same_units=True, factor=1000)\n",
    "        elif len(file.axes_manager.signal_shape) == 2:\n",
    "            if file.axes_manager.signal_axes[0].units == r'µm':\n",
    "                file.axes_manager.convert_units(axes=\"signal\", units='nm', same_units=True, factor=1000)\n",
    "\n",
    "    if len(file.axes_manager.shape) ==3:\n",
    "        if len(file.axes_manager.navigation_shape) == 2:\n",
    "            for axis in file.axes_manager.navigation_axes:\n",
    "                axis.offset = 0\n",
    "        elif len(file.axes_manager.signal_shape) == 2:\n",
    "            for axis in file.axes_manager.signal_axes:\n",
    "                axis.offset = 0\n",
    "\n",
    "eels_list[-1].axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c04487-7d96-4f7f-99ca-fbc1dce4cbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HADDF 图\n",
    "%matplotlib inline\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig.add_subplot()\n",
    "ax.set_position((0, 0, 1.0, 1.0))\n",
    "\n",
    "ax.imshow(eels_list[1].data, cmap='gray', aspect=1.0)\n",
    "add_sizebar(ax, 20, eels_list[1], 'w')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, r'1_TEM_EELS_HAADF_300.tif'), pad_inches=0.01, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1357755-3877-47b6-af38-21d8f4c36f2a",
   "metadata": {},
   "source": [
    "### ZLP 校准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f9b3e-43d7-423c-834f-28035e694726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eels_list[-2].align_zero_loss_peak(subpixel=True, also_align=[eels_list[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a5dd8-2379-4cde-ac9a-e36d5ff1dc48",
   "metadata": {},
   "source": [
    "### 确定样品厚度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed9eb2-f101-414d-b9be-878cfba359bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "th = eels_list[-2].estimate_elastic_scattering_threshold(window=30)\n",
    "# th.T.plot()\n",
    "s_thickness = eels_list[-2].estimate_thickness(threshold=th,)  # MnO2 5.03\n",
    "s_thickness.plot()\n",
    "\n",
    "# 保存数据\n",
    "s_thickness.save(path.joinpath(path_out, r'1-sample_thickness.hspy'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd152d6-6fb2-4be4-9ef4-0fbaaeff1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thickness 图 横向图\n",
    "%matplotlib inline\n",
    "vmax = s_thickness.nanmax().data[0].round(2)-0.01  # 需要做调整\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig.add_subplot()\n",
    "ax.set_position((0, 0, 1.0, 1.0))\n",
    "im = ax.imshow(s_thickness.data, cmap='gray', aspect=1.0, vmin=0.0, vmax=vmax)\n",
    "add_sizebar(ax, 20, s_thickness, 'w')\n",
    "ax.set_axis_off()\n",
    "\n",
    "cax = subfig.add_subplot()\n",
    "cax.set_position((0.0, 0.1, 0.4, 0.05))\n",
    "subfig.colorbar(mappable=im, cax=cax, ticks=np.linspace(0, vmax, 5), format='{x:.1f}', location='bottom', orientation='horizontal')\n",
    "cax.tick_params(axis='x', direction='out')\n",
    "\n",
    "cax.text(1.1, 0.35, r'Tickness ($\\frac{t}{\\lambda}$)', horizontalalignment='left', verticalalignment='center', transform=cax.transAxes, fontsize=11, c='k')\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, r'1-sample_thickness_300.tif'), pad_inches=0.1, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee928c31-95cf-4dd1-865f-f5dc831c31f1",
   "metadata": {},
   "source": [
    "### PCA 降噪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "ps = eels_list[-1].deepcopy()\n",
    "ps.decomposition(algorithm=\"SVD\", navigation_mask=None, centre='signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "# ps.plot_explained_variance_ratio(n=20, threshold=3, vline=True)\n",
    "num_components = ps.estimate_elbow_position()  # component number =  num_components + 1 \n",
    "# ps.plot_decomposition_results()\n",
    "# ps.plot_decomposition_loadings(comp_ids=num_components+1, axes_decor=\"off\", with_factors=True, per_row=(num_components+1)//2,)\n",
    "# # reconstruct data\n",
    "ps_recon = ps.get_decomposition_model(components=2*(num_components+1))\n",
    "ps_recon.save(path.joinpath(path_out, r'1-data_pca.hspy'), overwrite=True)\n",
    "ps_recon.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f7862-c78f-47ca-866d-3424b2367708",
   "metadata": {},
   "source": [
    "#### 除去 offset 背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义元素特征峰能量范围（可扩展）\n",
    "element_lines = {\n",
    "    'O':   (480.0, 600.0),   # O-K\n",
    "    'Mn':  (600.0, 700.0),   # Mn-L\n",
    "    'Zn':  (980.0, 1180.0), # Zn-L\n",
    "    'S':   (2430.0, 2550.0), # S-K\n",
    "}\n",
    "\n",
    "fit_ranges = {\n",
    "    'O':   (480.0, 520.0),   # O-K\n",
    "    'Mn':  (600.0, 623.0),   # Mn-L\n",
    "    'Zn':  (980.0, 1010.0), # Zn-L\n",
    "    'S':   (2430.0, 2450.0), # S-K\n",
    "}\n",
    "\n",
    "data_ranges = {\n",
    "    'O':   (480.0, 600.0),   # O-K\n",
    "    'Mn':  (600.0, 700.0),   # Mn-L\n",
    "    'Zn':  (980.0, 1280.0), # Zn-L\n",
    "    'S':   (2430.0, 2550.0), # S-K\n",
    "}\n",
    "\n",
    "def get_elements(data, element_lines: dict[str, tuple[float, float]]) -> tuple[str, ...]:\n",
    "    \"\"\"根据谱图能量范围，确定包含的元素。\"\"\"\n",
    "    elements = tuple(\n",
    "        element for element, (lowenergy, highenergy) in element_lines.items()\n",
    "        if data.axes_manager['Energy loss'].high_value >= highenergy -20 and data.axes_manager['Energy loss'].low_value <= lowenergy + 20\n",
    "    )\n",
    "    return elements\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "def remove_bkg(\n",
    "    data,\n",
    "    lowloss =None,\n",
    "    element_lines: dict = element_lines,\n",
    "    data_ranges: dict | None = data_ranges,\n",
    "    fit_ranges: dict = fit_ranges,\n",
    "    mask=None,\n",
    "    component_name: str = 'PowerLaw', # type: ignore\n",
    "    plot_fig: bool = False,\n",
    "    save_data: bool = True,\n",
    "    path_out: path = path_out,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    自动分段处理谱图并移除背景。\n",
    "    返回每个元素对应的去背景数据段组成的字典。\n",
    "    \"\"\"\n",
    "    hs.set_log_level('ERROR')\n",
    "\n",
    "    elements = get_elements(data, element_lines)\n",
    "    if not elements:\n",
    "        raise ValueError(\"No recognizable elements found in the data's energy range.\")\n",
    "\n",
    "    # 添加元素（避免重复）\n",
    "    data.add_elements(set(elements))\n",
    "    if len(elements) >=2:\n",
    "            elements += ('all',)\n",
    "\n",
    "    result: dict = {}\n",
    "\n",
    "    for element in tqdm.tqdm(elements):\n",
    "        \n",
    "        # 取出能量段与拟合范围\n",
    "        if element == 'all':\n",
    "            result[element] = data\n",
    "        else:\n",
    "            if data_ranges is not None:\n",
    "                start, end = data_ranges[element]\n",
    "                # 提取该段信号\n",
    "                sig = data.isig[start:end]\n",
    "            else:\n",
    "                sig = data\n",
    "\n",
    "            fit_start, fit_end = fit_ranges[element]\n",
    "\n",
    "            component_list: dict = {\n",
    "                'PowerLaw': hs.model.components1D.PowerLaw(),\n",
    "                'Offset': hs.model.components1D.Offset(),\n",
    "            }\n",
    "\n",
    "            # 创建模型并拟合背景\n",
    "            model = sig.create_model(low_loss=lowloss, auto_add_edges=False, auto_background=False)\n",
    "            model.append(component_list[component_name])\n",
    "            model.fit_component(\n",
    "                component = component_list[component_name],\n",
    "                signal_range=(fit_start, fit_end),\n",
    "                mask=mask,\n",
    "                fit_independent=True,\n",
    "                only_current=False\n",
    "            )\n",
    "\n",
    "            if plot_fig:\n",
    "                print(f\"Plotting background fit for {element}\")\n",
    "                model.plot(plot_components=True)\n",
    "\n",
    "            # 减去背景并保存\n",
    "            result[element] = (sig - model.as_signal(component_list=[component_name])).deepcopy()\n",
    "            if save_data:\n",
    "                result[element].save(path.joinpath(path_out, f'2-ps_{element}_rebgk.hspy'), overwrite=True)\n",
    "            \n",
    "    return result\n",
    "\n",
    "results_rebgk = remove_bkg(\n",
    "    ps_recon,\n",
    "    lowloss=eels_list[-2],\n",
    "    element_lines=element_lines,\n",
    "    data_ranges=data_ranges,\n",
    "    fit_ranges=fit_ranges,\n",
    "    mask=None,\n",
    "    plot_fig=False,\n",
    "    save_data=True,\n",
    "    path_out=path_out,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d394760-d6f5-4b04-82c4-ca409708ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "results_rebgk['Mn'].plot()\n",
    "results_rebgk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e435325e-aab5-43ac-abb3-3e5f56bc6d3b",
   "metadata": {},
   "source": [
    "### Mask 的选择，EELS Mappings 的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "roi_definitions = {\n",
    "    'Mn': (651.0, 655.0),\n",
    "    'O':  (520.0, 550.0),\n",
    "    'Zn': (1025.0, 1165.0),\n",
    "    'S':  (2467.0, 2478.0)\n",
    "}\n",
    "\n",
    "mask_ranges: dict[str, tuple[float, float] | None] = {\n",
    "    'Mn': None, # (6.0, 123.0),\n",
    "    'O':   (50.0, 574.0), \n",
    "    'Zn': None, # (80.0, 148.0), \n",
    "    'S':   None, # (2.0, 20.0),\n",
    "}\n",
    "\n",
    "# 存放映射结果\n",
    "ps_mappings = {}\n",
    "ps_masks = {}\n",
    "for element, (start, end) in roi_definitions.items():\n",
    "    if element in results_rebgk.keys():\n",
    "        if element == 'all':\n",
    "            ps_mappings[element] = None\n",
    "        else:\n",
    "            signal = results_rebgk[element]\n",
    "            roi = hs.roi.SpanROI(start, end)\n",
    "            _, map_img = hs.plot.plot_roi_map(signal, rois=[roi])\n",
    "            if mask_ranges[element] is not None:\n",
    "                ps_mappings[element] = map_img[0]\n",
    "                mask = (ps_mappings[element] < mask_ranges[element][0]) | (ps_mappings[element] > mask_ranges[element][1])  # type: ignore\n",
    "                ps_masks[element] = mask\n",
    "                # ps_mappings[element].data[mask.data] = np.nan\n",
    "\n",
    "            if mask_ranges[element] is None:\n",
    "                q_min, q_max = np.nanpercentile(map_img[0].data, [0, 100])\n",
    "                print(f\"Element: {element}, Q_min: {q_min}, Q_max: {q_max}\")\n",
    "                ps_mappings[element] = map_img[0]\n",
    "                mask = (ps_mappings[element] < q_min) | (ps_mappings[element] > q_max)\n",
    "                ps_masks[element] = mask\n",
    "                # ps_mappings[element].data[mask.data] = np.nan\n",
    "\n",
    "            # 保存映射结果\n",
    "            ps_mappings[element].save(path.joinpath(path_out, f'3-ps_{element}_mapping.hspy'), overwrite=True)\n",
    "            ps_masks[element].save(path.joinpath(path_out, f'3-ps_{element}_mask.hspy'), overwrite=True)\n",
    "    else:\n",
    "        print(f\"Element '{element}' not found. Skipping.\")\n",
    "\n",
    "\n",
    "# 关闭所有图窗口\n",
    "plt.close('all')\n",
    "element = 'O'\n",
    "# 创建一个横向的子图布局\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3), gridspec_kw={'width_ratios': [2, 1]}) # type: ignore\n",
    "element_mapping = ps_mappings.get(element).data # type: ignore\n",
    "element_mask = ps_masks.get(element).data # type: ignore\n",
    "file = np.where(element_mask, np.nan, element_mapping) # type: ignore\n",
    "# 画直方图\n",
    "ax1.hist(file.flatten(), bins=30, color='steelblue', edgecolor='black')\n",
    "# 去除上右边框\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "# 画灰度图像\n",
    "im = ax2.imshow(file, cmap='Spectral', aspect=1.0)\n",
    "ax2.axis('off')\n",
    "ax2.set_title(f'{element} Mapping')\n",
    "add_sizebar(ax2, 20, ps_mappings[element], 'k') \n",
    "# 自动紧凑布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "%matplotlib widget\n",
    "def EELSMappings(\n",
    "    data: dict,\n",
    "    colors_map: Optional[dict[str, np.ndarray]] = None,\n",
    "    selected_elements: tuple[str, ...] = (r'Mn', r'Zn'),\n",
    "    mask_mapping: dict | None = None,\n",
    "    fig_plot: bool = False,\n",
    "    path_out: Optional[path] = None,\n",
    "    save_data: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    读取 EDS 中的元素（如 Mn, Zn）数据，生成 RGB 合成图，保留原始 NaN 区域。\n",
    "\n",
    "    参数:\n",
    "        data (dict): 包含元素映射的输入字典。\n",
    "        colors_map (dict, optional): 每个元素对应的 RGB 颜色。\n",
    "        selected_elements (tuple[str]): 要可视化的元素。\n",
    "        fig_plot (bool): 是否绘图。\n",
    "        path_out (Path, optional): 图像/数据保存路径。\n",
    "        save_data (bool): 是否保存 npz 文件。\n",
    "    \"\"\"\n",
    "    images: dict[str, np.ndarray] = {}\n",
    "    eelsmappings_out: dict[str, np.ndarray] = {}\n",
    "\n",
    "    if mask_mapping is not None:\n",
    "        if len(mask_mapping) == 1:\n",
    "            mask: np.ndarray = mask_mapping.data # type: ignore\n",
    "        else:\n",
    "            mask: np.ndarray = np.any([mask_mapping[key].data for key in mask_mapping], axis=0)\n",
    "    else:\n",
    "        print(\"No mask provided, provide the mask.\")\n",
    "        \n",
    "    for key, file in data.items():\n",
    "        if key in selected_elements and getattr(file.data, \"ndim\", 0) == 2:\n",
    "            img = file.data\n",
    "            img = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "            images[key] = img\n",
    "\n",
    "    if colors_map is None:\n",
    "        colors_map = {\n",
    "            'Mn': np.array([236, 236, 0]) / 255,\n",
    "            'Zn': np.array([252, 0, 252]) / 255,\n",
    "            'S':  np.array([0, 252, 252]) / 255,\n",
    "            'O':  np.array([0, 0, 252]) / 255,\n",
    "        }\n",
    "\n",
    "    shape = next(iter(images.values())).shape\n",
    "    eels_mapping = np.zeros((*shape, 3), dtype=np.float32)\n",
    "\n",
    "    for element in selected_elements:\n",
    "        img = images[element]\n",
    "        eels_mapping += img[..., None] * colors_map[element]\n",
    "\n",
    "    eels_mapping = np.clip(eels_mapping, 0, 1)\n",
    "    eels_mapping[mask] = np.nan # type: ignore\n",
    "\n",
    "    if fig_plot:\n",
    "        plt.close('all')\n",
    "        fig, ax = plt.subplots(figsize=(3.3, 2.5))\n",
    "        im = ax.imshow(eels_mapping)\n",
    "        ax.axis('off')\n",
    "        add_sizebar(ax, 20, data[selected_elements[0]], 'k')\n",
    "\n",
    "        for idx, element in enumerate(selected_elements):\n",
    "            if element not in colors_map:\n",
    "                continue\n",
    "            ax.text(\n",
    "                0.02 + 0.09 * idx, 0.98, element, color='k' if element == 'Mn' else 'w',\n",
    "                bbox=dict(ec=None, fc=colors_map[element], alpha=1.0, boxstyle='Square, pad=0.3'),\n",
    "                transform=ax.transAxes, fontsize=9, va='top', ha='left',\n",
    "                fontfamily='Arial', fontweight='bold'\n",
    "            )\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        if path_out:\n",
    "            tif_path = path_out.joinpath('3-ps_eels_mapping_300.tif')\n",
    "            npz_path = path_out.joinpath('3-ps_eels_mapping.npz')\n",
    "            fig.savefig(\n",
    "                tif_path,\n",
    "                pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False,\n",
    "                pil_kwargs={\"compression\": \"tiff_lzw\"}\n",
    "            )\n",
    "            if save_data:\n",
    "                np.savez(npz_path, eels_mapping=eels_mapping)\n",
    "\n",
    "        plt.show()\n",
    "        final_mask = ps_mappings['Mn'].deepcopy()\n",
    "        final_mask.data = mask\n",
    "        final_mask.save(path_out.joinpath('3-ps_Zn_Mn_mask.hspy'), overwrite=True)\n",
    "        eelsmappings_out['mask'] = final_mask\n",
    "        eelsmappings_out['eels_mapping'] = eels_mapping\n",
    "    return eelsmappings_out\n",
    "\n",
    "eelsmappings = EELSMappings(ps_mappings, selected_elements=(r'Mn', r'Zn'), mask_mapping=ps_masks['O'], fig_plot=True, path_out=path_out)\n",
    "ps_masks['Zn_Mn'] = eelsmappings['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad171a",
   "metadata": {},
   "source": [
    "#### 计算 Mn 和 Zn 的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from PIL import Image\n",
    "plt.close('all')\n",
    "def generate_distribution_phase_mapping(\n",
    "    mapping_Mn: np.ndarray,\n",
    "    mapping_Zn: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    k_min: float | None = None,\n",
    "    k_max: float | None = None,\n",
    "    k_step: float = 0.2,\n",
    "    gif_path: path = path_out,\n",
    "    figsize: tuple = (12, 2.5),\n",
    "    dpi: int = 100,\n",
    "    bins: int = 100,\n",
    ") -> None:\n",
    "    assert mapping_Mn.shape == mapping_Zn.shape == mask.shape, \"All input arrays must have the same shape.\"\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        K_map = np.where((mapping_Zn != 0) & (~mask), mapping_Mn / mapping_Zn, np.nan)\n",
    "\n",
    "    mapping_Mn_A = mapping_Mn[~mask]\n",
    "    mapping_Zn_A = mapping_Zn[~mask]\n",
    "    K_flat = K_map[~mask]\n",
    "    valid = np.isfinite(K_flat)\n",
    "    mapping_Mn_A_K = mapping_Mn_A[valid]\n",
    "    mapping_Zn_A_K = mapping_Zn_A[valid]\n",
    "    K_flat = K_flat[valid]\n",
    "\n",
    "    if k_min is None:\n",
    "        k_min = float(np.nanmin(K_flat))\n",
    "    if k_max is None:\n",
    "        k_max = float(np.nanmax(K_flat))\n",
    "    k_ranges = np.arange(k_min, k_max, k_step)\n",
    "\n",
    "    cmap_base = plt.cm.hot_r(np.linspace(0.2, 0.8, 256))\n",
    "    cmap = LinearSegmentedColormap.from_list('cmap', cmap_base)\n",
    "    cmap.set_over('white')\n",
    "    cmap.set_under('black')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, gridspec_kw={'wspace': 0.05}, constrained_layout=True)\n",
    "    ax_overlay, ax_map = axes\n",
    "\n",
    "    ax_overlay.set_position([0.1, 0.18, 0.3, 0.7])\n",
    "    ax_overlay.set_box_aspect(1.0)\n",
    "    ax_overlay.hist2d(mapping_Mn_A_K, mapping_Zn_A_K, cmap=cmap, cmin=1, bins=bins)\n",
    "    sc2 = ax_overlay.scatter([], [], s=2, c='magenta', alpha=0.1)\n",
    "    legend_text2 = ax_overlay.text(0.95, 0.95, '', ha='right', va='top', transform=ax_overlay.transAxes, fontsize=8)\n",
    "    ax_overlay.set_title(\"After Masking\", fontsize=12, loc='left')\n",
    "    ax_overlay.set_xlabel(\"Mn\")\n",
    "    ax_overlay.set_ylabel(\"Zn\")\n",
    "\n",
    "    ax_map.set_position([0.4, 0.17, 0.3, 0.7])\n",
    "    masked_map = np.where(mask, np.nan, mapping_Mn)\n",
    "    img_map = ax_map.imshow(masked_map, cmap='gray')\n",
    "    ax_map.set_title(\"Distribution of Mn and Zn\", fontsize=12, loc='left')\n",
    "    ax_map.axis('off')\n",
    "    mask_overlay = ax_map.imshow(np.zeros_like(mapping_Mn), cmap='hot', alpha=0.7, vmin=0, vmax=1)\n",
    "\n",
    "    tiff_stack = []\n",
    "    for frame_index in range(len(k_ranges)):\n",
    "        k_start = k_ranges[frame_index]\n",
    "        k_end = k_start + k_step\n",
    "\n",
    "        range_mask_flat = (K_flat > k_start) & (K_flat <= k_end)\n",
    "        Mn_filtered = mapping_Mn_A_K[range_mask_flat]\n",
    "        Zn_filtered = mapping_Zn_A_K[range_mask_flat]\n",
    "        sc2.set_offsets(np.column_stack((Mn_filtered, Zn_filtered)))\n",
    "        legend_text2.set_text(f'{k_start:.2f} < K ≤ {k_end:.2f}')\n",
    "\n",
    "        range_mask_2d = (K_map > k_start) & (K_map <= k_end)\n",
    "        mask_overlay.set_data(range_mask_2d.astype(float))\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        img_array = np.asarray(fig.canvas.buffer_rgba())[:, :, :3]\n",
    "        pil_img = Image.fromarray(img_array)\n",
    "        tiff_stack.append(pil_img.convert(\"RGB\"))\n",
    "\n",
    "    # 保存 TIFF stack\n",
    "    tiff_output_path = gif_path.joinpath('3-distribution_phase_mapping.tif')\n",
    "    tiff_stack[0].save(\n",
    "        tiff_output_path,\n",
    "        save_all=True,\n",
    "        append_images=tiff_stack[1:],\n",
    "        compression=\"tiff_deflate\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    print(f\"[✔] TIFF stack saved to: {tiff_output_path.resolve()}\")\n",
    "\n",
    "generate_distribution_phase_mapping(\n",
    "    ps_mappings['Mn'].data,\n",
    "    ps_mappings['Zn'].data,\n",
    "    ps_masks['Zn_Mn'].data,\n",
    "    k_min=-0.2,\n",
    "    k_max=6.0,\n",
    "    k_step=0.2,\n",
    "    gif_path=path_out,\n",
    "    figsize=(7.0, 2.5),\n",
    "    dpi=80,\n",
    "    bins=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5f93b-513f-4f19-9e97-6f7a78054914",
   "metadata": {},
   "source": [
    "### Onset energy of L3 of Mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 Energy Axis 进行插值修改\n",
    "\n",
    "hs.set_log_level('ERROR')\n",
    "from hyperspy.axes import UniformDataAxis\n",
    "def interpolate_axis(data, new_scale:float = 0.1):\n",
    "    if r'Energy loss' in [axes.name for axes in data.axes_manager.signal_axes]:\n",
    "        axis_new = UniformDataAxis(offset=data.axes_manager['Energy loss'].offset, scale=new_scale, size=((data.axes_manager['Energy loss'].high_value - data.axes_manager['Energy loss'].low_value)//new_scale+2), name=\"Energy loss\", units='eV', navigate=False, is_binned=True)\n",
    "        data = data.interpolate_on_axis(axis_new, 2, inplace=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85171a1-ee8e-4870-8da5-e62136750b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ps_Mn_L = results_rebgk['Mn'].deepcopy()\n",
    "ps_Mn_L = interpolate_axis(ps_Mn_L, new_scale=0.1)\n",
    "ps_onset_intensity_L3 = np.multiply(0.1, ps_Mn_L.max('Energy loss'))\n",
    "ps_onset_energy_Mn_L3 = ps_onset_intensity_L3.deepcopy()\n",
    "ps_onset_energy_Mn_L3.data = np.where(ps_masks['Zn_Mn'].data, np.nan, np.abs(ps_Mn_L.isig[:644.0] - ps_onset_intensity_L3).valuemin('Energy loss')) \n",
    "%matplotlib ipympl\n",
    "ps_onset_energy_Mn_L3.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28542c",
   "metadata": {},
   "source": [
    "#### 优化 onset_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "def optimize_onset_energy(onset_energy_data, energy_range: tuple = (636.0, 638.0), save_path: path = path_out, fig_plot: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    绘制 Onset Energy 分布图，展示 mask 之前与之后的对比。\n",
    "    \n",
    "    参数：\n",
    "    - onset_energy_data: Hyperspy 信号对象, Onset Energy 图像\n",
    "    - energy_range: tuple, 限定的 (min, max) 范围\n",
    "    - save_path: Path 对象或字符串，图像保存路径（不保存则为 None）\n",
    "    \"\"\"\n",
    "    from matplotlib import ticker\n",
    "    onset_energy:dict = {}\n",
    "    # 创建 mask 和被 mask 后的新图像\n",
    "    mask = (onset_energy_data < energy_range[0]) & (onset_energy_data > energy_range[1])\n",
    "    onset_energy_filtered = onset_energy_data.deepcopy()\n",
    "    onset_energy_filtered.data = np.where(mask.data, np.nan, onset_energy_data.data)\n",
    "\n",
    "    # 扁平化数据用于排序可视化\n",
    "    data_all = onset_energy_data.data.flatten()\n",
    "    data_masked = onset_energy_filtered.data.flatten()\n",
    "    data_all = data_all[~np.isnan(data_all)]\n",
    "    data_masked = data_masked[~np.isnan(data_masked)]\n",
    "\n",
    "    # 画图\n",
    "    if fig_plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(7.0, 2.5), gridspec_kw=dict(wspace=0.05))\n",
    "    \n",
    "        ax0 = axes[0] # type: ignore\n",
    "        ax0.plot(np.sort(data_all), label='Raw', color=colors[1])\n",
    "        ax0.plot(np.sort(data_masked), label='Masked', color=colors[4], ls='--')\n",
    "        ax0.set_xlabel(r'Number (N)', fontsize=11)\n",
    "        ax0.set_ylabel(r'Onset Energy (eV)', fontsize=11, labelpad=7)\n",
    "        ax0.set_ylim(energy_range[0]-2, energy_range[1]+2)\n",
    "        ax0.yaxis.set_major_locator(ticker.MultipleLocator(base=1, offset=0))\n",
    "        ax0.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.5, offset=0))\n",
    "        ax0.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "        ax0.axhline(y=energy_range[0], ls='--', c='k')\n",
    "        ax0.axhline(y=energy_range[1], ls='--', c='k')\n",
    "        ax0.legend(loc='lower right', fontsize=8, frameon=False)\n",
    "\n",
    "        ax1 = axes[1]  # type: ignore\n",
    "        vmin_L3 = energy_range[0]\n",
    "        vmax_L3 = energy_range[1]\n",
    "        N_color = 5\n",
    "        # 创建 colormap 并设置 over/under 颜色\n",
    "        cmap = plt.cm.hot_r(np.linspace(0.2, 0.8, 256))\n",
    "        cmap = LinearSegmentedColormap.from_list('cmap', cmap)\n",
    "        cmap.set_over('white')        # 超出 vmax 显示白色\n",
    "        cmap.set_under('black')       # 低于 vmin 显示黑色\n",
    "\n",
    "        onset_energy_filtered_a = np.nan_to_num(onset_energy_filtered.data, copy=True, nan=0)\n",
    "        # 设置 norm\n",
    "        norm = Normalize(vmin=vmin_L3, vmax=vmax_L3)\n",
    "        im = ax1.imshow(onset_energy_filtered_a, cmap=cmap, norm=norm)\n",
    "        add_sizebar(ax1, 20, onset_energy_filtered, 'w')\n",
    "        ax1.axis('off')\n",
    "\n",
    "        cax = fig.add_subplot()\n",
    "        cax.set_position((1.03, 0.1, 0.03, 0.8))\n",
    "        fig.colorbar(mappable=im, cax=cax, ticks=np.linspace(vmin_L3, vmax_L3, N_color), format='{x:.1f}', location='right', orientation='vertical')\n",
    "        cax.tick_params(axis='x', direction='out')\n",
    "        cax.text(4.0, 0.5, r'Onset Energy (eV)', rotation=90, horizontalalignment='left', verticalalignment='center', transform=cax.transAxes, fontsize=11, c='k')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')\n",
    "            \n",
    "    # 保存\n",
    "    if save_path:\n",
    "        plt.savefig(save_path.joinpath(r'4-TEM_sTXM_L3_OnsetEnergy_300.tif'), pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False,\n",
    "                        pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "        onset_energy_filtered.save(save_path.joinpath(r'4-TEM_sTXM_L3_OnsetEnergy.hspy'), overwrite=True)\n",
    "\n",
    "    onset_energy['onset_energy'] = onset_energy_filtered\n",
    "    onset_energy['mask'] = np.isnan(onset_energy_filtered)\n",
    "    return onset_energy\n",
    "\n",
    "%matplotlib inline\n",
    "onset_energy = optimize_onset_energy(ps_onset_energy_Mn_L3, energy_range=(634.0, 636.0), save_path=path_out, fig_plot=True)\n",
    "ps_masks['onsetenergy'] = onset_energy['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2dd271-215a-459b-99eb-6fdecff2ac3f",
   "metadata": {},
   "source": [
    "### 不同区域的信号，以及全局"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "eels_list[1].plot()\n",
    "rectangular_roi = hs.roi.RectangularROI(left=0.0, right=10.0, top=0.0, bottom=10.0)\n",
    "roi2D = rectangular_roi.interactive(eels_list[1], color=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_definition = {\n",
    "   # 'Bulk': (50.0,85.0,12.0,65.0),\n",
    "   # 'Surface': (12.0,30.0,23.0,68.0),\n",
    "   'all': (eels_list[-1].axes_manager[0].low_value, eels_list[-1].axes_manager[0].high_value, eels_list[-1].axes_manager[1].low_value, eels_list[-1].axes_manager[1].high_value),\n",
    "}\n",
    "rois: dict = {}\n",
    "for key, value in rois_definition.items():\n",
    "        rois[key] = hs.roi.RectangularROI(left=value[0], right=value[1], top=value[2], bottom=value[3]) # 需要保证是 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a85808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "def draw_roi_rectangles(ax, roi_dict, color_dict, scale_x, scale_y, zorder=5):\n",
    "    \"\"\"\n",
    "    在指定的 matplotlib 坐标轴上绘制矩形 ROI。\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): 目标坐标轴。\n",
    "        roi_dict (dict): 包含 ROI 名称和 hs.roi.RectangularROI 对象的字典。\n",
    "        color_dict (dict): ROI 名称对应的颜色字典（例如 {'Surface': 'y'}）。\n",
    "        scale_x (float): X轴像素大小（通常为 `ps_recon.axes_manager[0].scale`）。\n",
    "        scale_y (float): Y轴像素大小（通常为 `ps_recon.axes_manager[1].scale`）。\n",
    "        zorder (int): matplotlib 中图层的层级（默认 5）。\n",
    "    \"\"\"\n",
    "    for name, roi in roi_dict.items():\n",
    "        color = color_dict.get(name, 'k')  # 默认颜色为红色\n",
    "        x0 = int(roi.x / scale_x)\n",
    "        y0 = int(roi.y / scale_y)\n",
    "        w = int(roi.width / scale_x)\n",
    "        h = int(roi.height / scale_y)\n",
    "\n",
    "        rect = patches.Rectangle((x0, y0), w, h, linewidth=1.5,\n",
    "                                 edgecolor=color, facecolor='none',\n",
    "                                 transform=ax.transData, zorder=zorder)\n",
    "        ax.add_patch(rect)\n",
    "        # 添加文字标签在左上角\n",
    "        ax.text(x0+w, y0+h, name, color='k', fontsize=9,\n",
    "                ha='left', va='center', zorder=zorder+1)\n",
    "        \n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "# 图\n",
    "subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig.add_subplot()\n",
    "ax.set_position((0.0, 0, 1.0, 1.0))\n",
    "ax.set_axis_off()\n",
    "file = np.where(ps_masks['Zn_Mn'], np.nan, ps_recon.sum(-1))\n",
    "ax.imshow(file.data, cmap='gray',aspect=1.0)\n",
    "sizebar = add_sizebar(ax, 20, ps_recon, 'k')\n",
    "sizebar.set_bbox_to_anchor(Bbox.from_bounds(0.0, 0.0, 0.0, 0.0), transform=ax.transAxes)\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, labelbottom=False, labelleft=False,)\n",
    "\n",
    "draw_roi_rectangles(\n",
    "    ax, \n",
    "    rois, \n",
    "    color_dict={'Surface': 'y', 'Bulk': 'y', 'all': 'y'}, \n",
    "    scale_x=ps_recon.axes_manager[0].scale, \n",
    "    scale_y=ps_recon.axes_manager[1].scale\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, r'5-TEM_EELS_Selected_Regions_300.tif'), pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5b7b2",
   "metadata": {},
   "source": [
    "#### Cluster 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_roi(eels_list: dict, rois: dict, selected_elements: tuple[str, ...] = (r'Mn', r'O', r'Zn'), num_clusters: int | None =None, mask = ps_masks['Zn_Mn'], save_path: path=path_out, plt_plot:bool =False, sizebarA=50) -> None:\n",
    "  \n",
    "    for element in selected_elements:\n",
    "        if element in eels_list:\n",
    "            for roi_name, roi in rois.items():\n",
    "                roi_signal = roi(eels_list[element])\n",
    "                mask_signal = np.isnan(roi(mask))\n",
    "                roi_signal.save(path.joinpath(path_out, f'5-Clusters_{element}_{roi_name}_data.hspy'), overwrite=True)\n",
    "                mask_signal.save(path.joinpath(path_out, f'5-Clusters_{element}_{roi_name}_mask.hspy'), overwrite=True)\n",
    "                roi_signal.data = np.nan_to_num(roi_signal, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                cluster_analysis_A(data=roi_signal, clusters_mask=mask_signal, num_clusters=num_clusters, plt_plot=plt_plot, save_data=True, save_path=save_path, roi_name=roi_name, sizebar=sizebarA)\n",
    "\n",
    "def cluster_analysis_A(data, clusters_mask, sizebar, num_clusters: int | None = 3, plt_plot: bool = False, save_data: bool = True, save_path: path = path_out, roi_name:int | str | None = None) -> None:\n",
    "\n",
    "    # cluster 分析\n",
    "    data.decomposition(algorithm=\"SVD\", centre=\"signal\", navigation_mask=clusters_mask.T, print_info=False)\n",
    "    num_clusters = data.estimate_number_of_clusters(cluster_source=\"decomposition\", max_clusters=8, preprocessing=\"standard\", navigation_mask=clusters_mask.data) if num_clusters is None else num_clusters\n",
    "\n",
    "    data.cluster_analysis(cluster_source=\"decomposition\", n_clusters=num_clusters, preprocessing=\"standard\", algorithm=\"kmeans\", n_init=8, navigation_mask=clusters_mask.data)\n",
    "    \n",
    "    cluster_signals = data.get_cluster_signals(signal='mean')\n",
    "    cluster_signals.metadata.add_dictionary(data.metadata.as_dictionary())\n",
    "    # 添加元素（避免重复）\n",
    "    elements = get_elements(cluster_signals, element_lines)\n",
    "    cluster_signals.add_elements(set(elements))\n",
    "    cluster_labels = data.get_cluster_labels()\n",
    "\n",
    "    cluster_data: dict = {\n",
    "        'data': data,\n",
    "        'signals': cluster_signals,\n",
    "        'labels': cluster_labels\n",
    "    }\n",
    "\n",
    "    if save_data:\n",
    "        plot_cluster_result(cluster_data, elements=elements, plt_plot=plt_plot, save_path=save_path, roi_name=roi_name, sizebar=sizebar)\n",
    "        prefix = f\"5-Clusters_{elements[0] if len(elements)==1 else 'all'}_{roi_name}_N{cluster_signals.axes_manager.navigation_size}\"\n",
    "        cluster_signals.save(save_path.joinpath(f\"{prefix}_signals.hspy\"), overwrite=True)\n",
    "        cluster_labels.save(save_path.joinpath(f\"{prefix}_labels.hspy\"), overwrite=True)\n",
    "\n",
    "\n",
    "def plot_cluster_result(cluster_data, elements: tuple, plt_plot:bool = False, save_path: path = path_out, roi_name: int | str | None = None, sizebar=sizebar) -> None:\n",
    "\n",
    "    # cluster 分布\n",
    "    data = cluster_data['data']\n",
    "    labels = cluster_data['labels']\n",
    "    signals = cluster_data['signals']\n",
    "\n",
    "    fig = plt.figure(figsize=(7.0, 2.5))\n",
    "    gs = gridspec.GridSpec(1, 3, width_ratios=[1,1,1], height_ratios=None,\n",
    "                            wspace=0.01, hspace=0, figure=fig)\n",
    "    \n",
    "    # 图 A\n",
    "    subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "    ax = subfig.add_subplot()\n",
    "    ax.set_position((0, 0, 1.0, 1.0))\n",
    "    ax.set_box_aspect(0.8)\n",
    "\n",
    "    for i in range(signals.axes_manager.navigation_size):\n",
    "        ax.plot(signals.axes_manager['Energy loss'].axis, signals.inav[i].data, c=colors[i], ls='-',lw=1.0, label=f'#{i}', zorder=i)\n",
    "    ax.set_xlabel(r'Energy (eV)', fontsize=13)\n",
    "    ax.set_ylabel(r'Intensity', fontsize=13)\n",
    "    configure_axes_for_element(ax=ax, elements=elements)\n",
    "    title = f\"{elements[0] if len(elements)==1 else 'all'}, {roi_name}, Raw\"\n",
    "    plt.title(title, fontsize=13, loc='left', pad=0.5)\n",
    "    ax.legend(loc='best', ncols=1, frameon=False, fontsize=11, labelcolor='linecolor', columnspacing=0.4)\n",
    "  \n",
    "    # 图 B\n",
    "    subfig = fig.add_subfigure(gs[0, 1], zorder=0)\n",
    "    ax = subfig.add_subplot()\n",
    "    ax.set_position((0.25, 0, 1.0, 1.0))\n",
    "    if labels.axes_manager.navigation_shape == 2:\n",
    "        labels = labels.T\n",
    "    for i in range(labels.axes_manager.navigation_size):\n",
    "        cmapping = LinearSegmentedColormap.from_list(name=r'cmapping', colors=['w', colors[i]], N=2)\n",
    "        im = ax.imshow(labels.inav[i].data, cmap=cmapping, alpha=0.8, zorder=i+2, aspect=1)\n",
    "    #     cax = subfig.add_subplot(zorder=10-i)\n",
    "    #     cax.set_position((0.1+0.125*i, 0.05, 0.25, 0.06))\n",
    "    #     subfig.colorbar(mappable=im, cax=cax, ticks=[], location='bottom', orientation='horizontal',)\n",
    "    #     cax.tick_params(axis='x', direction='out')\n",
    "    # for spine in ax.spines.values():\n",
    "    #     spine.set_color('black')\n",
    "    add_sizebar(ax, sizebar, labels, 'black')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # 图 C\n",
    "    subfig = fig.add_subfigure(gs[0, 2], zorder=0)\n",
    "    ax = subfig.add_subplot()\n",
    "    ax.set_position((0.45, 0, 1.0, 1.0))\n",
    "    im = ax.imshow(data.sum(-1).data, cmap='grey', alpha=1.0, zorder=1, aspect=1)\n",
    "    add_sizebar(ax, sizebar, data, 'black')\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        prefix = f\"5-Clusters_{elements[0] if len(elements)==1 else 'all'}_{roi_name}_N{signals.axes_manager.navigation_size}\"\n",
    "        plt.savefig(save_path.joinpath(f'{prefix}_300.tif'), pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "    if plt_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')\n",
    "\n",
    "def configure_axes_for_element(ax, elements: tuple):\n",
    "    if len(elements) >= 2:\n",
    "        ax.set_xlim(300.0, 3000.0)\n",
    "        # ax.set_ylim(-0.03, 1.5)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(500))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(250))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and 'Mn' in elements:\n",
    "        ax.set_xlim(600.0, 700.0)\n",
    "        # ax.set_ylim(-0.03, 1.5)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(10))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and 'Zn' in elements:\n",
    "        ax.set_xlim(980.0, 1280.0)\n",
    "        # ax.set_ylim(-0.03, 1.2)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(60))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(30))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and  'O' in elements:\n",
    "        ax.set_xlim(500.0, 600.0)\n",
    "        # ax.set_ylim(-0.05, 1.3)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(10))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "\n",
    "for number in [None, 3, 4]:\n",
    "    select_roi(results_rebgk, rois, selected_elements=(r'Mn', r'Zn', r'O'), num_clusters=number, mask=ps_masks['Zn_Mn'], save_path=path_out, plt_plot=False, sizebarA=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2f999",
   "metadata": {},
   "source": [
    "#### 纯相梯度分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_roi2(eels_list: dict, rois: dict, selected_elements: tuple[str, ...] = (r'Mn', r'O'), mask=ps_masks['Zn_Mn'], save_path: path=path_out, plt_plot:bool =False, sizebarA=50) -> None:\n",
    "    for element in selected_elements:\n",
    "        if element in eels_list:\n",
    "            for roi_name, roi in rois.items():\n",
    "                if roi_name != 'all':\n",
    "                    roi_signal = roi(eels_list[element])\n",
    "                    mask_signal = np.isnan(roi(mask).data)\n",
    "                    roi_signal.data[mask_signal, :] = np.nan\n",
    "                    roi_signal_line = roi_signal.nanmean(axis=0)\n",
    "                    roi_signal_line.save(path.joinpath(path_out, f'6-line_{element}_{roi_name}.hspy'), overwrite=True)\n",
    "\n",
    "                    plot_line_result(roi_signal, roi_signal_line, elements=(element,), plt_plot=plt_plot, save_path=save_path, roi_name=roi_name, sizebarA=sizebarA)\n",
    "\n",
    "\n",
    "def plot_line_result(roi_signal, roi_signal_line, sizebarA, elements: tuple, plt_plot:bool = False, save_path: path = path_out, roi_name: int | str | None = None) -> None:\n",
    "\n",
    "    roi_signal.data = np.nan_to_num(roi_signal.data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    roi_signal_line.data = np.nan_to_num(roi_signal_line.data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(7.0, 2.5))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1,1], height_ratios=None,\n",
    "                            wspace=0.01, hspace=0, figure=fig)\n",
    "    \n",
    "    # 图 A\n",
    "    subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "    ax = subfig.add_subplot()\n",
    "    ax.set_position((0, 0, 1.0, 1.0))\n",
    "    ax.set_box_aspect(0.8)\n",
    "\n",
    "    ax.imshow(roi_signal_line.data, cmap='Spectral', alpha=1.0, zorder=1, aspect=1)\n",
    "    configure_axes_for_element2(ax=ax, elements=elements)\n",
    "\n",
    "    title = f\"{elements[0] if len(elements)==1 else 'all'}, {roi_name}, line\"\n",
    "    plt.title(title, fontsize=13, loc='left', pad=0.5)\n",
    "\n",
    "#     # 图 A\n",
    "#     subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "#     ax = subfig.add_subplot()\n",
    "#     ax.set_position((0, 0, 1.0, 1.0))\n",
    "#     ax.set_box_aspect(0.8)\n",
    "\n",
    "#     cmapcolors = ListedColormap(mpl.colormaps['sunset'](np.linspace(1.0, 0.5, roi_signal.data.shape[1])), name='cmapcolors')\n",
    "\n",
    "#     for i in range(roi_signal_line.axes_manager.navigation_size):\n",
    "#         ax.plot(roi_signal_line.axes_manager['Energy loss'].axis, roi_signal_line.inav[i].data, c=cmapcolors(i), ls='-',lw=1.0, label=None, zorder=i)\n",
    "#     ax.set_xlabel(r'Energy (eV)', fontsize=13)\n",
    "#     ax.set_ylabel(r'Intensity', fontsize=13)\n",
    "#     configure_axes_for_element(ax=ax, elements=elements)\n",
    "#     title = f\"{elements[0] if len(elements)==1 else 'all'}, {roi_name}, line\"\n",
    "#     plt.title(title, fontsize=13, loc='left', pad=0.5)\n",
    "#     ax.legend(loc='best', ncols=1, frameon=False, fontsize=11, labelcolor='linecolor', columnspacing=0.4)\n",
    "  \n",
    "    # 图 B\n",
    "    subfig = fig.add_subfigure(gs[0, 1], zorder=0)\n",
    "    ax = subfig.add_subplot()\n",
    "    ax.set_position((-0.4, 0, 1.0, 1.0))\n",
    "    im = ax.imshow(roi_signal.nansum(-1).data, cmap='grey', alpha=1.0, zorder=2, aspect=1)\n",
    "    add_sizebar(ax, sizebarA, roi_signal, 'k')\n",
    "    ax.set_axis_off()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        prefix = f\"6-line_{elements[0] if len(elements)==1 else 'all'}_{roi_name}\"\n",
    "        plt.savefig(save_path.joinpath(f'{prefix}_300.tif'), pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "\n",
    "    if plt_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')\n",
    "\n",
    "def configure_axes_for_element2(ax, elements: tuple):\n",
    "    if len(elements) >= 2:\n",
    "        # ax.set_xlim(300.0, 3000.0)\n",
    "        # ax.set_ylim(-0.03, 1.5)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(500))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(250))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and 'Mn' in elements:\n",
    "        # ax.set_xlim(600.0, 700.0)\n",
    "        # ax.set_ylim(-0.03, 1.5)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(10))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and 'Zn' in elements:\n",
    "        # ax.set_xlim(980.0, 1180.0)\n",
    "        # ax.set_ylim(-0.03, 1.2)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(60))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(30))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "    elif len(elements) == 1 and  'O' in elements:\n",
    "        # ax.set_xlim(500.0, 600.0)\n",
    "        # ax.set_ylim(-0.05, 1.3)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(10))\n",
    "        # ax.yaxis.set_major_locator(ticker.MultipleLocator(0.3))\n",
    "        # ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.15))\n",
    "\n",
    "select_roi2(results_rebgk, rois, selected_elements=(r'Mn', r'O'), mask=ps_masks['Zn_Mn'], save_path=path_out, plt_plot=True, sizebarA=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5627f2b",
   "metadata": {},
   "source": [
    "#### 对应的 L3 L2 比例，对应的 signals Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28df830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import LinearModel, StepModel\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "def index_of(arr, threshold):\n",
    "    \"\"\"返回数组中第一个大于 threshold 的索引。\"\"\"\n",
    "    return np.argmax(arr > threshold)\n",
    "\n",
    "def auto_select_two_largest_peaks(data, distance=10):\n",
    "    \"\"\"自动选择两个主峰\"\"\"\n",
    "    peaks, _ = find_peaks(data, distance=distance)\n",
    "    if len(peaks) < 2:\n",
    "        raise ValueError(\"找不到两个峰\")\n",
    "    peak_values = data[peaks]\n",
    "    top_peaks = peaks[np.argsort(peak_values)[-2:]]\n",
    "    return np.sort(top_peaks)\n",
    "\n",
    "def find_onset_energy(energy, data, thread=0.1):\n",
    "    imax = auto_select_two_largest_peaks(data)\n",
    "    imin = find_peaks(-data, distance=10)[0]\n",
    "    imin = [next((v for v in imin if v > peak), None) for peak in imax]\n",
    "    # print(f\"峰位置: {energy[imax]}, 谷位置: {energy[imin]}\")\n",
    "    if None in imin:\n",
    "        raise ValueError(\"未能找到合适的峰后谷\")\n",
    "\n",
    "    ionset = [\n",
    "        index_of(data[:imax[0]], thread * data[imax[0]]),\n",
    "        index_of(data[imin[0]:imax[1]], data[imin[0]] + thread * data[imax[1]]) + imin[0] # type: ignore\n",
    "    ]\n",
    "\n",
    "    return ionset, imin, imax\n",
    "\n",
    "def baseline(energy, data, ionset, imax, imin):\n",
    "    if None in imin or len(imin) < 2:\n",
    "        raise ValueError(\"找不到两个有效的主谷 imin\")\n",
    "\n",
    "    height = [data[i] for i in imin if i is not None]\n",
    "\n",
    "    # 安全截取前段和后段数据\n",
    "    pre_range = slice(max(0, ionset[0]-10), ionset[0])\n",
    "    post_range = slice(max(0, imin[1]-5), min(len(data), imin[1]+5))\n",
    "\n",
    "    if pre_range.stop - pre_range.start < 3 or post_range.stop - post_range.start < 3:\n",
    "        raise ValueError(\"用于拟合的区域太窄，无法安全拟合\")\n",
    "\n",
    "    xdat = np.concatenate((energy[pre_range], energy[post_range]))\n",
    "    ydat = np.concatenate((data[pre_range], data[post_range]))\n",
    "\n",
    "    line_mod = LinearModel(prefix='line_')\n",
    "    step_mod1 = StepModel(form='arctan', prefix='step1_')\n",
    "    step_mod2 = StepModel(form='arctan', prefix='step2_')\n",
    "\n",
    "    params = line_mod.make_params(intercept=np.mean(data[:ionset[0]-10]), slope=dict(value=0)) # vary=False\n",
    "    params.update(step_mod1.make_params(\n",
    "        center=dict(value=energy[ionset[0]], vary=False),\n",
    "        sigma=dict(value=0.5, expr='1*step2_sigma'),\n",
    "        amplitude=dict(expr='2*step2_amplitude')\n",
    "    ))\n",
    "    params.update(step_mod2.make_params(\n",
    "        center=dict(value=energy[ionset[1]], vary=False),\n",
    "        sigma=dict(value=0.5, min=0.1, max=1.0),\n",
    "        amplitude=dict(value=height[1]/3, vary=True, expr=f'({height[1]}-line_slope*step2_center-line_intercept)/3')\n",
    "    ))\n",
    "\n",
    "    model = line_mod + step_mod1 + step_mod2\n",
    "    result = model.fit(ydat, params, x=xdat)\n",
    "    baseline = result.eval(result.params, x=energy)\n",
    "    peaks = data - baseline\n",
    "    peak_intensities = [simpson(y=peaks[pid-2:pid+2], x=energy[pid-2:pid+2]) for pid in imax]\n",
    "    ratio = peak_intensities[0] / peak_intensities[1]\n",
    "    return baseline, peaks, peak_intensities, ratio, result\n",
    "\n",
    "def plot_fit(energy, data, baseline, peaks, ratio, ionset, name, path_out):\n",
    "    fig = plt.figure(figsize=(3.3, 2.5))\n",
    "    gs = gridspec.GridSpec(1, 1, figure=fig)   \n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    ax.set_position((0.0, 0, 1.0, 1.0))\n",
    "    ax.set_box_aspect(0.8)\n",
    "    ax.plot(energy, data, ls='-', label='data')\n",
    "    ax.plot(energy, baseline, ls='--', label='bkg')\n",
    "    ax.plot(energy, peaks, ls='--', label='fit')\n",
    "    ax.set_ylabel(r'Intensity (count)', fontsize=11)\n",
    "    ax.set_xlabel(r'Energy (eV)', fontsize=11)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=20))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=10))\n",
    "    ax.text(0.95, 0.90, f'L3/2 ratio: {ratio:.2f}', transform=ax.transAxes,\n",
    "            ha='right', va='top', fontsize=10)\n",
    "    energy_str = \", \".join(f\"{e:.2f}\" for e in energy[ionset])\n",
    "    ax.text(0.95, 0.80, f'{energy_str}', transform=ax.transAxes,\n",
    "            ha='right', va='top', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "            path_out.joinpath(f\"7_{name}.tif\"),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=600,\n",
    "            transparent=False,\n",
    "            pil_kwargs={\"compression\": \"tiff_lzw\"}\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "def process_one_spectrum(name, energy, data, threshold, plot_each, path_out):\n",
    "    try:\n",
    "        ionset, imin, imax = find_onset_energy(energy, data, thread=threshold)\n",
    "        if len(imax) != 2:\n",
    "            raise ValueError(\"检测到的主峰数不为2\")\n",
    "        baseline_fit, bkg_removed, peak_intensities, ratio, _ = baseline(energy, data, ionset, imax, imin)\n",
    "\n",
    "        if plot_each:\n",
    "            plot_fit(energy, data, baseline_fit, bkg_removed, ratio, ionset, name, path_out)\n",
    "        else:\n",
    "            plt.close('all')\n",
    "\n",
    "        return name, {\n",
    "            'original': data,\n",
    "            'baseline': baseline_fit,\n",
    "            'bkg_removed': bkg_removed,\n",
    "            'intensity_L3': peak_intensities[0],\n",
    "            'intensity_L2': peak_intensities[1],\n",
    "            'L3_L2_ratio': ratio,\n",
    "            'L3_energy': energy[ionset[0]],\n",
    "            'L2_energy': energy[ionset[1]],\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] {name} 出错: {e}\")\n",
    "        return name, None\n",
    "\n",
    "def process_dataframe(df: pd.DataFrame, energy_column='energy', threshold=0.1, plot_each=False, path_out=path_out):\n",
    "    energy = df[energy_column].values\n",
    "    spectra_names = df.columns.drop(energy_column)\n",
    "\n",
    "    results = {}\n",
    "    failure_log = []\n",
    "\n",
    "    for name in spectra_names:\n",
    "        spectrum = df[name].values\n",
    "        try:\n",
    "            result = process_one_spectrum(name, energy, spectrum, threshold, plot_each, path_out)\n",
    "            if result and isinstance(result, tuple) and result[1] is not None:\n",
    "                _, data = result\n",
    "                results[name] = data\n",
    "            else:\n",
    "                failure_log.append((name, \"结果为空或处理失败\"))\n",
    "        except Exception as e:\n",
    "            failure_log.append((name, str(e)))\n",
    "\n",
    "    # 写入失败日志\n",
    "    if failure_log:\n",
    "        log_file = path_out / \"log_failed_spectra.txt\"\n",
    "        with open(log_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"以下谱线在处理过程中出错：\\n\")\n",
    "            for name, reason in failure_log:\n",
    "                f.write(f\"{name}: {reason}\\n\")\n",
    "        print(f\"⚠️ 失败日志已保存到: {log_file}\")\n",
    "\n",
    "    print(f\"✅ 成功处理 {len(results)} 条谱线；❌ 失败 {len(failure_log)} 条谱线\")\n",
    "\n",
    "    if not results:\n",
    "        raise ValueError(\"所有谱线均处理失败。\")\n",
    "\n",
    "    # 创建 xarray Dataset\n",
    "    dataset = xr.Dataset(\n",
    "        data_vars={\n",
    "            'data': (['spectrum', 'energy'], np.array([v['original'] for v in results.values()])),\n",
    "            'baseline': (['spectrum', 'energy'], np.array([v['baseline'] for v in results.values()])),\n",
    "            'bkg_removed': (['spectrum', 'energy'], np.array([v['bkg_removed'] for v in results.values()])),\n",
    "            'intensity_L3': (['spectrum'], [v['intensity_L3'] for v in results.values()]),\n",
    "            'intensity_L2': (['spectrum'], [v['intensity_L2'] for v in results.values()]),\n",
    "            'L3_L2_ratio': (['spectrum'], [v['L3_L2_ratio'] for v in results.values()]),\n",
    "            'L3_energy': (['spectrum'], [v['L3_energy'] for v in results.values()]),\n",
    "            'L2_energy': (['spectrum'], [v['L2_energy'] for v in results.values()])\n",
    "        },\n",
    "        coords={\n",
    "            'spectrum': list(results.keys()),\n",
    "            'energy': energy\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "file_path = list(path_out.glob(r'5-Clusters_Mn_*_Signals.hspy'))\n",
    "signals = hs.load(file_path) # type: ignore\n",
    "signals = hs.stack(signals, axis=0) # type: ignore\n",
    "energy_axis = signals.axes_manager[\"Energy loss\"].axis.reshape(1, -1) # type: ignore\n",
    "data = np.concatenate([energy_axis, signals.data], axis=0)\n",
    "df = pd.DataFrame(data.T)\n",
    "df.columns = ['energy'] + list(str(i) for i in range(1, df.shape[1]))\n",
    "# df.iloc[:20, 1:] = df.iloc[:20, 1:].where(lambda x: (x > -5)&(x < 100), 0) \n",
    "xr_result = process_dataframe(df[df['energy'] < 680.0], plot_each=False, path_out=path_out, threshold=0.1)\n",
    "xr_result.to_netcdf(path_out.joinpath(f\"7_TEM_EELS_Cluster.NETCDF4\"), engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0c350",
   "metadata": {},
   "source": [
    "#### 对应的 L3/L2 maapings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a81727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "from lmfit.models import LinearModel, StepModel\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "def index_of(arr, threshold):\n",
    "    \"\"\"返回数组中第一个大于 threshold 的索引。\"\"\"\n",
    "    return np.argmax(arr > threshold)\n",
    "\n",
    "def auto_select_two_largest_peaks(data, distance=10):\n",
    "    \"\"\"自动选择两个主峰\"\"\"\n",
    "    peaks, _ = find_peaks(data, distance=distance)\n",
    "    if len(peaks) < 2:\n",
    "        raise ValueError(\"找不到两个峰\")\n",
    "    peak_values = data[peaks]\n",
    "    top_peaks = peaks[np.argsort(peak_values)[-2:]]\n",
    "    return np.sort(top_peaks)\n",
    "\n",
    "def find_onset_energy(energy, data, thread):\n",
    "    imax = auto_select_two_largest_peaks(data)\n",
    "    imin = find_peaks(-data, distance=10)[0]\n",
    "    imin = [next((v for v in imin if v > peak), None) for peak in imax]\n",
    "    # print(f\"峰位置: {energy[imax]}, 谷位置: {energy[imin]}\")\n",
    "    if None in imin:\n",
    "        raise ValueError(\"未能找到合适的峰后谷\")\n",
    "\n",
    "    ionset = [\n",
    "        index_of(data[:imax[0]], thread * data[imax[0]]),\n",
    "        index_of(data[imin[0]:imax[1]], data[imin[0]] + thread * data[imax[1]]) + imin[0] # type: ignore\n",
    "    ]\n",
    "\n",
    "    return ionset, imin, imax\n",
    "\n",
    "def baseline(energy, data, ionset, imax, imin):\n",
    "\n",
    "    height = [data for data in data[imin]]\n",
    "    xdat = np.concatenate((energy[:ionset[0]-10], energy[imin[1]-5:imin[1]+5]))\n",
    "    ydat = np.concatenate((data[:ionset[0]-10], data[imin[1]-5:imin[1]+5]))\n",
    "\n",
    "    line_mod = LinearModel(prefix='line_')\n",
    "    step_mod1 = StepModel(form='arctan', prefix='step1_')\n",
    "    step_mod2 = StepModel(form='arctan', prefix='step2_')\n",
    "\n",
    "    params = line_mod.make_params(intercept=np.mean(data[:ionset[0]-10]), slope=dict(value=0)) # vary=False\n",
    "    params.update(step_mod1.make_params(\n",
    "        center=dict(value=energy[ionset[0]], vary=False),\n",
    "        sigma=dict(value=0.5, expr='1*step2_sigma'),\n",
    "        amplitude=dict(expr='2*step2_amplitude')\n",
    "    ))\n",
    "    params.update(step_mod2.make_params(\n",
    "        center=dict(value=energy[ionset[1]], vary=False),\n",
    "        sigma=dict(value=0.5, min=0.1, max=1.0),\n",
    "        amplitude=dict(value=height[1]/3, vary=True, expr=f'({height[1]}-line_slope*step2_center-line_intercept)/3')\n",
    "    ))\n",
    "\n",
    "    model = line_mod + step_mod1 + step_mod2\n",
    "    result = model.fit(ydat, params, x=xdat)\n",
    "    baseline = result.eval(result.params, x=energy)\n",
    "    peaks = data - baseline\n",
    "    area_L3 = energy_window_integral(energy, peaks, energy[imax[0]], width_ev=2.0)\n",
    "    area_L2 = energy_window_integral(energy, peaks, energy[imax[1]], width_ev=2.0)\n",
    "    peak_intensities = [area_L3, area_L2]\n",
    "    # peak_intensities = [simpson(y=peaks[pid-5:pid+5], x=energy[pid-5:pid+5]) for pid in imax]\n",
    "    ratio = peak_intensities[0] / peak_intensities[1]\n",
    "    return baseline, peaks, peak_intensities, ratio, result\n",
    "\n",
    "def energy_window_integral(energy, data, peak, width_ev):\n",
    "    mask = (energy >= peak - width_ev / 2) & (energy <= peak + width_ev / 2)\n",
    "    if not np.any(mask):\n",
    "        raise ValueError(f\"在能量 {peak:.2f} 附近找不到足够点进行积分\")\n",
    "    return simpson(y=data[mask], x=energy[mask])\n",
    "\n",
    "def process_one_spectrum(name, energy, data, threshold):\n",
    "    try:\n",
    "        ionset, imin, imax = find_onset_energy(energy, data, thread=threshold)\n",
    "        baseline_fit, bkg_removed, peak_intensities, ratio, _ = baseline(energy, data, ionset, imax, imin)\n",
    "\n",
    "        return name, {\n",
    "            'original': data,\n",
    "            'baseline': baseline_fit,\n",
    "            'bkg_removed': bkg_removed,\n",
    "            'intensity_L3': peak_intensities[0],\n",
    "            'intensity_L2': peak_intensities[1],\n",
    "            'L3_L2_ratio': ratio,\n",
    "            'L3_energy': energy[ionset[0]],\n",
    "            'L2_energy': energy[ionset[1]],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"[!] {name} 出错: {e}\")\n",
    "        return name, None\n",
    "\n",
    "def select_roi3(eels_list: dict, rois: dict, elements: tuple[str, ...] = (r'Mn', r'O'), threshold=0.1, mask=eelsmappings['mask'], save_path: path=path_out, plt_plot=True) -> None:\n",
    "    for element in elements:\n",
    "        if element == 'Mn' and element in eels_list:\n",
    "            for roi_name, roi in rois.items():\n",
    "                if roi_name in ['all', 'Bulk', 'Surface']:\n",
    "                    roi_signal = roi(eels_list[element]) \n",
    "                    mask_signal = np.isnan(roi(mask))\n",
    "                    process_dataframe(data=roi_signal, mask=mask_signal, path_out=save_path, threshold=threshold, roi_name=roi_name, element=element, plt_plot=plt_plot)\n",
    "\n",
    "def process_dataframe(data, mask, threshold, path_out, roi_name, element, plt_plot) -> None:\n",
    "    energy = data.axes_manager['Energy loss'].axis\n",
    "    results = {}\n",
    "\n",
    "    if mask is not None and mask.axes_manager.navigation_shape != data.axes_manager.navigation_shape:\n",
    "        mask = mask.T.deepcopy()\n",
    "\n",
    "    for i in tqdm.tqdm(range(data.axes_manager.navigation_shape[0])):\n",
    "        for j in range(data.axes_manager.navigation_shape[1]):\n",
    "            name = f\"{i}_{j}\"\n",
    "            try:\n",
    "                if mask is not None and mask.inav[i, j].data:\n",
    "                    results[name] = None\n",
    "                    continue\n",
    "\n",
    "                spectrum = data.inav[i, j].data\n",
    "                _, result_data = process_one_spectrum(name, energy, spectrum, threshold)\n",
    "                results[name] = result_data  # 可为 None，也可为 dict\n",
    "            except Exception as e:\n",
    "                print(f\"[X] {name} -> 处理出错: {e}\")\n",
    "                results[name] = None\n",
    "\n",
    "    # 初始化矩阵\n",
    "    result_keys = ['original', 'baseline', 'bkg_removed', 'intensity_L3', 'intensity_L2', 'L3_L2_ratio', 'L3_energy', 'L2_energy']\n",
    "    spectra_shape = (data.axes_manager.navigation_shape[0], data.axes_manager.navigation_shape[1], len(energy))\n",
    "\n",
    "    spectra_data = {k: np.full(spectra_shape, np.nan, dtype=np.float32) for k in ['original', 'baseline', 'bkg_removed']}\n",
    "    scalar_data = {k: np.full(data.axes_manager.navigation_shape, np.nan, dtype=np.float32) for k in result_keys[3:]}\n",
    "\n",
    "    for name, res in results.items():\n",
    "        if res is None:\n",
    "            continue\n",
    "        i, j = map(int, name.split('_'))\n",
    "        for k in spectra_data:\n",
    "            spectra_data[k][i, j, :] = res[k]\n",
    "        for k in scalar_data:\n",
    "            scalar_data[k][i, j] = res[k]\n",
    "\n",
    "    dataset = xr.Dataset(\n",
    "        data_vars={\n",
    "            **{k: (['x', 'y', 'energy'], spectra_data[k]) for k in spectra_data},\n",
    "            **{k: (['x', 'y'], scalar_data[k]) for k in scalar_data},\n",
    "        },\n",
    "        coords={\n",
    "            'x': np.arange(data.axes_manager.navigation_shape[0]),\n",
    "            'y': np.arange(data.axes_manager.navigation_shape[1]),\n",
    "            'energy': energy,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if path_out:\n",
    "        dataset.to_netcdf(path_out.joinpath(f\"7_TEM_EELS_{element}_{roi_name}.NETCDF4\"), engine=\"h5netcdf\")\n",
    "        dataset['L3_L2_ratio'].to_dataframe().to_csv(path_out.joinpath(f\"7_TEM_EELS_{element}_{roi_name}_L3_L2_ratio.csv\"), index=True)\n",
    "\n",
    "    if plt_plot:\n",
    "        plt.close('all')\n",
    "        fig = plt.figure(figsize=(3.3, 2.5))\n",
    "        ax = fig.add_subplot()\n",
    "        im = ax.imshow(dataset['L3_L2_ratio'].values, cmap='gray', aspect='equal')\n",
    "        add_sizebar(ax, 10, mask, color='k')\n",
    "        ax.axis('off')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')\n",
    "\n",
    "select_roi3(results_rebgk, rois, elements=(r'Mn', r'O'), mask=ps_masks['Zn_Mn'], save_path=path_out, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2890ae78",
   "metadata": {},
   "source": [
    "##### 画出上述的 L2 和 L3 峰的变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(path_out.joinpath(r\"7_TEM_EELS_Mn_all.NETCDF4\"), engine=\"h5netcdf\")\n",
    "mask_cluster = hs.load(path_out.joinpath(r\"5-Clusters_Mn_all_mask.hspy\")) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63404cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "plt.close('all')\n",
    "def generate_distribution_phase_mapping(\n",
    "    mapping_L3: np.ndarray,\n",
    "    mapping_L2: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    k_min: float | None = None,\n",
    "    k_max: float | None = None,\n",
    "    k_step: float = 0.2,\n",
    "    gif_path: path = path_out,\n",
    "    figsize: tuple = (12, 2.5),\n",
    "    dpi: int = 100,\n",
    "    bins: int = 100,\n",
    ") -> None:\n",
    "    assert mapping_L3.shape == mapping_L2.shape == mask.shape, \"All input arrays must have the same shape.\"\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        K_map = np.where((mapping_L2 != 0) & (~mask), mapping_L3 / mapping_L2, np.nan)\n",
    "\n",
    "    mapping_L3_A = mapping_L3[~mask]\n",
    "    mapping_L2_A = mapping_L2[~mask]\n",
    "    K_flat = K_map[~mask]\n",
    "    valid = np.isfinite(K_flat)\n",
    "    mapping_L3_A_K = mapping_L3_A[valid]\n",
    "    mapping_L2_A_K = mapping_L2_A[valid]\n",
    "    K_flat = K_flat[valid]\n",
    "\n",
    "    if k_min is None:\n",
    "        k_min = float(np.nanmin(K_flat))\n",
    "    if k_max is None:\n",
    "        k_max = float(np.nanmax(K_flat))\n",
    "    k_ranges = np.arange(k_min, k_max, k_step)\n",
    "\n",
    "    cmap_base = plt.cm.hot_r(np.linspace(0.2, 0.8, 256))\n",
    "    cmap = LinearSegmentedColormap.from_list('cmap', cmap_base)\n",
    "    cmap.set_over('white')\n",
    "    cmap.set_under('black')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize, gridspec_kw={'wspace': 0.05}, constrained_layout=True)\n",
    "    ax_overlay, ax_map = axes\n",
    "\n",
    "    ax_overlay.set_position([0.1, 0.18, 0.3, 0.7])\n",
    "    ax_overlay.set_box_aspect(1.0)\n",
    "    ax_overlay.hist2d(mapping_L3_A_K, mapping_L2_A_K, cmap=cmap, cmin=1, bins=bins)\n",
    "    sc2 = ax_overlay.scatter([], [], s=2, c='magenta', alpha=0.1)\n",
    "    legend_text2 = ax_overlay.text(0.95, 0.95, '', ha='right', va='top', transform=ax_overlay.transAxes, fontsize=8)\n",
    "    ax_overlay.set_title(\"After Masking\", fontsize=12, loc='left')\n",
    "    ax_overlay.set_xlabel(\"L3\")\n",
    "    ax_overlay.set_ylabel(\"L2\")\n",
    "\n",
    "    ax_map.set_position([0.4, 0.2, 0.3, 0.7])\n",
    "    masked_map = np.where(mask, np.nan, mapping_L3)\n",
    "    img_map = ax_map.imshow(masked_map, cmap='gray')\n",
    "    ax_map.set_title(\"Distribution of L3\", fontsize=12, loc='left')\n",
    "    ax_map.axis('off')\n",
    "    mask_overlay = ax_map.imshow(np.zeros_like(mapping_L3), cmap='hot', alpha=0.7, vmin=0, vmax=1)\n",
    "\n",
    "    tiff_stack = []\n",
    "    for frame_index in range(len(k_ranges)):\n",
    "        k_start = k_ranges[frame_index]\n",
    "        k_end = k_start + k_step\n",
    "\n",
    "        range_mask_flat = (K_flat > k_start) & (K_flat <= k_end)\n",
    "        Mn_filtered = mapping_L3_A_K[range_mask_flat]\n",
    "        Zn_filtered = mapping_L2_A_K[range_mask_flat]\n",
    "        sc2.set_offsets(np.column_stack((Mn_filtered, Zn_filtered)))\n",
    "        legend_text2.set_text(f'{k_start:.2f} < K ≤ {k_end:.2f}')\n",
    "\n",
    "        range_mask_2d = (K_map > k_start) & (K_map <= k_end)\n",
    "        mask_overlay.set_data(range_mask_2d.astype(float))\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        img_array = np.asarray(fig.canvas.buffer_rgba())[:, :, :3]\n",
    "        pil_img = Image.fromarray(img_array)\n",
    "        tiff_stack.append(pil_img.convert(\"RGB\"))\n",
    "\n",
    "    # 保存 TIFF stack\n",
    "    tiff_output_path = gif_path.joinpath('7-distribution_L3_L2.tif')\n",
    "    tiff_stack[0].save(\n",
    "        tiff_output_path,\n",
    "        save_all=True,\n",
    "        append_images=tiff_stack[1:],\n",
    "        compression=\"tiff_deflate\"\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    print(f\"[✔] TIFF stack saved to: {tiff_output_path.resolve()}\")\n",
    "\n",
    "generate_distribution_phase_mapping(\n",
    "    dataset['intensity_L3'].values,\n",
    "    dataset['intensity_L2'].values,\n",
    "    mask_cluster.data.T,\n",
    "    k_min=-0.2,\n",
    "    k_max=4.0,\n",
    "    k_step=0.2,\n",
    "    gif_path=path_out,\n",
    "    figsize=(7.0, 2.5),\n",
    "    dpi=80,\n",
    "    bins=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae020e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "131f3c05",
   "metadata": {},
   "source": [
    "### 拟合，在原始数据上，=== 结果并不是很喜欢，放弃 ===="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9db0aa",
   "metadata": {},
   "source": [
    "#### 提取不同的片段数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34acfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义元素特征峰能量范围（可扩展）\n",
    "# element_lines = {\n",
    "#     'O':   (480.0, 600.0),   # O-K\n",
    "#     'Mn':  (600.0, 700.0),   # Mn-L\n",
    "#     'Zn':  (980.0, 1180.0), # Zn-L\n",
    "#     'S':   (2430.0, 2550.0), # S-K\n",
    "# }\n",
    "\n",
    "# fit_ranges = {\n",
    "#     'O':   (480.0, 520.0),   # O-K\n",
    "#     'Mn':  (600.0, 623.0),   # Mn-L\n",
    "#     'Zn':  (980.0, 1010.0), # Zn-L\n",
    "#     'S':   (2430.0, 2450.0), # S-K\n",
    "# }\n",
    "\n",
    "# data_ranges = {\n",
    "#     'O':   (480.0, 600.0),   # O-K\n",
    "#     'Mn':  (600.0, 700.0),   # Mn-L\n",
    "#     'Zn':  (980.0, 1280.0), # Zn-L\n",
    "#     'S':   (2430.0, 2550.0), # S-K\n",
    "# }\n",
    "\n",
    "# def get_elements(data, element_lines: dict[str, tuple[float, float]]) -> tuple[str, ...]:\n",
    "#     \"\"\"根据谱图能量范围，确定包含的元素。\"\"\"\n",
    "#     elements = tuple(\n",
    "#         element for element, (lowenergy, highenergy) in element_lines.items()\n",
    "#         if data.axes_manager['Energy loss'].high_value >= highenergy -20 and data.axes_manager['Energy loss'].low_value <= lowenergy + 20\n",
    "#     )\n",
    "#     return elements\n",
    "\n",
    "# import tqdm.notebook as tqdm\n",
    "# def Clip_data(\n",
    "#     data,\n",
    "#     element_lines: dict = element_lines,\n",
    "#     data_ranges: dict | None = data_ranges,\n",
    "#     save_data: bool = True,\n",
    "#     path_out: path = path_out,\n",
    "# ) -> dict:\n",
    "#     \"\"\"\n",
    "#     自动分段处理谱图并移除背景。\n",
    "#     返回每个元素对应的去背景数据段组成的字典。\n",
    "#     \"\"\"\n",
    "#     hs.set_log_level('ERROR')\n",
    "\n",
    "#     elements = get_elements(data, element_lines)\n",
    "#     if not elements:\n",
    "#         raise ValueError(\"No recognizable elements found in the data's energy range.\")\n",
    "\n",
    "#     # 添加元素（避免重复）\n",
    "#     data.add_elements(set(elements))\n",
    "#     if len(elements) >=2:\n",
    "#             elements += ('all',)\n",
    "\n",
    "#     result: dict = {}\n",
    "\n",
    "#     for element in tqdm.tqdm(elements):\n",
    "        \n",
    "#         # 取出能量段与拟合范围\n",
    "#         if element == 'all':\n",
    "#             result[element] = data\n",
    "#         else:\n",
    "#             if data_ranges is not None:\n",
    "#                 start, end = data_ranges[element]\n",
    "#                 # 提取该段信号\n",
    "#                 sig = data.isig[start:end]\n",
    "#             else:\n",
    "#                 sig = data\n",
    "\n",
    "#             # 保存\n",
    "#             result[element] = sig\n",
    "#             if save_data:\n",
    "#                 result[element].save(path.joinpath(path_out, f'2-ps_{element}.hspy'), overwrite=True)\n",
    "            \n",
    "#     return result\n",
    "\n",
    "# results_clip = Clip_data(\n",
    "#     ps_recon,\n",
    "#     element_lines=element_lines,\n",
    "#     data_ranges=data_ranges,\n",
    "#     save_data=True,\n",
    "#     path_out=path_out,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl\n",
    "# data_ranges = {\n",
    "#     'O':   (490.0, 580.0),   # O-K\n",
    "#     'Mn':  (620.0, 670.0),   # Mn-L\n",
    "#     }\n",
    "\n",
    "# def select_roi3(\n",
    "#     eels_list: dict,\n",
    "#     rois: dict,\n",
    "#     selected_elements: tuple[str, ...] = (r'Mn', r'O'),\n",
    "#     mask=None,\n",
    "#     save_path: path = path_out,\n",
    "#     plt_plot: bool = False,\n",
    "#     lowloss=None\n",
    "# ) -> None:\n",
    "#     # 自动过滤不合法元素\n",
    "#     valid_elements = []\n",
    "\n",
    "#     for element in selected_elements:\n",
    "#         if element not in eels_list:\n",
    "#             continue\n",
    "\n",
    "#         data = eels_list[element]\n",
    "#         start, end = data_ranges.get(element, (None, None))\n",
    "#         if start is None or end is None:\n",
    "#             print(f\"Skipping '{element}': no data range defined.\")\n",
    "#             continue\n",
    "\n",
    "#         energy_min = data.axes_manager['Energy loss'].low_value\n",
    "#         energy_max = data.axes_manager['Energy loss'].high_value\n",
    "\n",
    "#         if start >= energy_min and end <= energy_max:\n",
    "#             valid_elements.append(element)\n",
    "#             # print(f\"Processing, Data Range of '{element}' is invalid.\")\n",
    "\n",
    "#     # 主循环：只处理有效元素\n",
    "#     for element in valid_elements:\n",
    "#         for roi_name, roi in rois.items():\n",
    "#             roi_signal = roi(eels_list[element])\n",
    "#             lowloss_roi = roi(lowloss) if lowloss is not None else None\n",
    "#             mask_signal = np.isnan(roi(mask).data) if mask is not None else None\n",
    "#             if mask_signal is not None:\n",
    "#                 roi_signal.data[mask_signal, :] = np.nan\n",
    "\n",
    "#             EELSfitting(\n",
    "#                 data=roi_signal,\n",
    "#                 lowloss=lowloss_roi,\n",
    "#                 element=element,\n",
    "#                 mask=mask_signal,\n",
    "#                 data_ranges=data_ranges,\n",
    "#                 plot_fig=plt_plot,\n",
    "#                 save_data=True,\n",
    "#                 path_out=save_path,\n",
    "#                 roi_name=roi_name\n",
    "#                 )\n",
    "\n",
    "\n",
    "# def EELSfitting(\n",
    "#     data,\n",
    "#     element,\n",
    "#     lowloss = None,\n",
    "#     data_ranges: dict = data_ranges,\n",
    "#     mask: np.ndarray | None = None,\n",
    "#     plot_fig: bool = False,\n",
    "#     save_data: bool = True,\n",
    "#     path_out: path = path_out,\n",
    "#     roi_name: int | str | None = None\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     对 EELS 数据进行背景去除和拟合。\n",
    "\n",
    "#     参数:\n",
    "#         data (Signal1D): 输入的 EELS 数据。\n",
    "#         lowloss (Signal1D): 低损耗数据。\n",
    "#         element: 元素名称。\n",
    "#         data_ranges (dict): 数据范围。\n",
    "#         mask (np.ndarray): 掩膜。\n",
    "#         plot_fig (bool): 是否绘图。\n",
    "#         save_data (bool): 是否保存数据。\n",
    "#         path_out (Path): 输出路径。\n",
    "#     \"\"\"\n",
    "    \n",
    "#     import pooch\n",
    "#     GOSH10 = pooch.retrieve(\n",
    "#         url=\"https://zenodo.org/records/7645765/files/Segger_Guzzinati_Kohl_1.5.0.gosh\",\n",
    "#         known_hash=\"md5:7fee8891c147a4f769668403b54c529b\",\n",
    "#     )\n",
    "#     GOSDIRAC = pooch.retrieve(\n",
    "#         url=\"https://zenodo.org/records/12800856/files/Dirac_GOS.gosh\",\n",
    "#         known_hash=\"md5:02fb22ab55e39e51eb03c08dbf699545\",\n",
    "#     )\n",
    "\n",
    "#     if element == r'Mn':\n",
    "            \n",
    "#             if data_ranges is not None:\n",
    "#                 start, end = data_ranges[element]\n",
    "#                 # 提取该段信号\n",
    "#                 data = data.isig[start:end]\n",
    "#             else:\n",
    "#                 data = data\n",
    "\n",
    "#             # 拟合\n",
    "#             model = data.create_model(low_loss=lowloss, auto_add_edges=True, auto_background=True, gos_file_path=GOSDIRAC)\n",
    "#             model.reset_signal_range()\n",
    "#             model.fit_background(start_energy=data_ranges[element][0]+2, only_current=False, mask=mask)\n",
    "#             model.components.PowerLaw.set_parameters_not_free()\n",
    "#             model.enable_fine_structure()\n",
    "#             model.enable_free_onset_energy()\n",
    "#             model.set_all_edges_intensities_positive()\n",
    "#             model.resolve_fine_structure()\n",
    "#             model.multifit(mask=mask, optimizer='lm', loss_function='ls')\n",
    "\n",
    "#             if plot_fig:\n",
    "#                   model.plot(plot_components=True)\n",
    "#             else:\n",
    "#                 plt.close('all')\n",
    "#             if save_data:\n",
    "#                 model.save(path_out.joinpath(f'7-{element}_{roi_name}_results.hspy'), overwrite=True)\n",
    "#                 model.save_parameters2file(path_out.joinpath(f'7-{element}_{roi_name}_model_parameters'))\n",
    "#                 model_residual = data.data - model.as_signal().data\n",
    "#                 xr.Dataset(\n",
    "#                         data_vars=dict(data = (['y', 'x','energy_loss'], data.data),\n",
    "#                                      fit = (['y', 'x','energy_loss'], model.as_signal().data),\n",
    "#                                      fit_Mn_II = (['y', 'x','energy_loss'], model.as_signal(component_list=['Mn_L2']).data),\n",
    "#                                      fit_Mn_III = (['y', 'x','energy_loss'], model.as_signal(component_list=['Mn_L3']).data),\n",
    "#                                      fit_residual = (['y', 'x','energy_loss'], model_residual),\n",
    "#                                      fit_Mn_L3_intensity = (['y', 'x'], model.components.Mn_L3.intensity.as_signal().data),\n",
    "#                                      fit_Mn_L3_onset_energy = (['y', 'x'], model.components.Mn_L3.onset_energy.as_signal().data),\n",
    "#                                      fit_Mn_L2_intensity = (['y', 'x'], model.components.Mn_L2.intensity.as_signal().data),\n",
    "#                                      fit_Mn_L2_onset_energy = (['y', 'x'], model.components.Mn_L2.onset_energy.as_signal().data),\n",
    "#                                      ),\n",
    "#                         coords=dict(\n",
    "#                                     energy_loss = data.axes_manager['Energy loss'].axis,\n",
    "#                                     x= data.axes_manager['x'].axis,\n",
    "#                                     y= data.axes_manager['y'].axis,\n",
    "#                                     ),\n",
    "#                         attrs=dict(\n",
    "#                                     chisq = model.chisq.data[0],\n",
    "#                                     red_chisq = model.red_chisq.data[0],\n",
    "#                                     ),\n",
    "#                             ).to_netcdf(path_out.joinpath(f'7-{element}_{roi_name}_results.NETCDF4'), engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_roi3(results_clip, rois, selected_elements=(r'Mn', r'O'), mask=onset_energy['onset_energy'], save_path=path_out, plt_plot=False,lowloss=eels_list[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9a37c",
   "metadata": {},
   "source": [
    "### 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482f348",
   "metadata": {},
   "source": [
    "#### 其他来源数据的汇总去除背景2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199fcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import xarray as xr\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import ticker, gridspec\n",
    "# from lmfit.models import LinearModel, StepModel\n",
    "# from scipy.signal import find_peaks\n",
    "# from scipy.integrate import simpson\n",
    "\n",
    "# def index_of(arr, threshold):\n",
    "#     \"\"\"返回数组中第一个大于 threshold 的索引。\"\"\"\n",
    "#     return np.argmax(arr > threshold)\n",
    "\n",
    "# def auto_select_two_largest_peaks(data, distance=10):\n",
    "#     \"\"\"自动选择两个主峰\"\"\"\n",
    "#     peaks, _ = find_peaks(data, distance=distance)\n",
    "#     if len(peaks) < 2:\n",
    "#         raise ValueError(\"找不到两个峰\")\n",
    "#     peak_values = data[peaks]\n",
    "#     top_peaks = peaks[np.argsort(peak_values)[-2:]]\n",
    "#     return np.sort(top_peaks)\n",
    "\n",
    "# def find_onset_energy(energy, data, thread=0.3):\n",
    "#     imax = auto_select_two_largest_peaks(data)\n",
    "#     imin = find_peaks(-data, distance=10)[0]\n",
    "#     imin = [next((v for v in imin if v > peak), None) for peak in imax]\n",
    "#     if None in imin:\n",
    "#         raise ValueError(\"未能找到合适的峰后谷\")\n",
    "\n",
    "#     ionset = [\n",
    "#         index_of(data[:imax[0]], thread * data[imax[0]]),\n",
    "#         index_of(data[imin[0]:imax[1]], data[imin[0]] + thread * data[imax[1]]) + imin[0]\n",
    "#     ]\n",
    "#     height = [data[i] for i in imin]\n",
    "#     return ionset, imin, imax, height\n",
    "\n",
    "# def baseline(energy, data, ionset, imax, imin, height):\n",
    "#     xdat = np.concatenate((energy[:ionset[0]-10], energy[imin[1]-5:imin[1]+5]))\n",
    "#     ydat = np.concatenate((data[:ionset[0]-10], data[imin[1]-5:imin[1]+5]))\n",
    "\n",
    "#     line_mod = LinearModel(prefix='line_')\n",
    "#     step_mod1 = StepModel(form='arctan', prefix='step1_')\n",
    "#     step_mod2 = StepModel(form='arctan', prefix='step2_')\n",
    "\n",
    "#     params = line_mod.make_params(intercept=np.mean(data[:ionset[0]-10]), slope=dict(value=0, vary=False))\n",
    "#     params.update(step_mod1.make_params(\n",
    "#         center=dict(value=energy[ionset[0]], vary=False),\n",
    "#         sigma=dict(value=0.5, expr='1*step2_sigma'),\n",
    "#         amplitude=dict(expr='2*step2_amplitude')\n",
    "#     ))\n",
    "#     params.update(step_mod2.make_params(\n",
    "#         center=dict(value=energy[ionset[1]], vary=False),\n",
    "#         sigma=dict(value=0.5, min=0.1, max=1.0),\n",
    "#         amplitude=dict(value=height[1]/3, vary=True, expr=f'({height[1]}-line_intercept)/3')\n",
    "#     ))\n",
    "\n",
    "#     model = line_mod + step_mod1 + step_mod2\n",
    "#     result = model.fit(ydat, params, x=xdat)\n",
    "\n",
    "#     baseline = result.eval(result.params, x=energy)\n",
    "#     peaks = data - baseline\n",
    "#     peak_intensities = [simpson(y=peaks[pid-5:pid+5], x=energy[pid-5:pid+5]) for pid in imax]\n",
    "#     ratio = peak_intensities[0] / peak_intensities[1]\n",
    "#     return baseline, peaks, peak_intensities, ratio, result\n",
    "\n",
    "# def plot_fit(energy, data, baseline, peaks, ratio, ionset, name, path_out):\n",
    "#     fig = plt.figure(figsize=(3.3, 2.5))\n",
    "#     gs = gridspec.GridSpec(1, 1, figure=fig)   \n",
    "#     ax = fig.add_subplot(gs[0])\n",
    "#     ax.set_position((0.0, 0, 1.0, 1.0))\n",
    "#     ax.set_box_aspect(0.8)\n",
    "#     ax.plot(energy, data, ls='-', label='data')\n",
    "#     ax.plot(energy, baseline, ls='--', label='bkg')\n",
    "#     ax.plot(energy, peaks, ls='--', label='fit')\n",
    "#     ax.set_ylabel(r'Intensity (count)', fontsize=11)\n",
    "#     ax.set_xlabel(r'Energy (eV)', fontsize=11)\n",
    "#     ax.xaxis.set_major_locator(ticker.MultipleLocator(base=20))\n",
    "#     ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=10))\n",
    "#     ax.text(0.95, 0.90, f'L3/2 ratio: {ratio:.2f}', transform=ax.transAxes,\n",
    "#             ha='right', va='top', fontsize=10)\n",
    "#     energy_str = \", \".join(f\"{e:.2f}\" for e in energy[ionset])\n",
    "#     ax.text(0.95, 0.80, f'{energy_str}', transform=ax.transAxes,\n",
    "#             ha='right', va='top', fontsize=10)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(\n",
    "#             path_out.joinpath(f\"{name}.tif\"),\n",
    "#             bbox_inches=\"tight\",\n",
    "#             dpi=600,\n",
    "#             transparent=False,\n",
    "#             pil_kwargs={\"compression\": \"tiff_lzw\"}\n",
    "#         )\n",
    "#     plt.show()\n",
    "\n",
    "# def process_one_spectrum(name, energy, data, threshold, plot_each, path_out):\n",
    "#     try:\n",
    "#         ionset, imin, imax, height = find_onset_energy(energy, data, thread=threshold)\n",
    "#         baseline_fit, bkg_removed, peak_intensities, ratio, _ = baseline(energy, data, ionset, imax, imin, height)\n",
    "\n",
    "#         if plot_each:\n",
    "#             plot_fit(energy, data, baseline_fit, bkg_removed, ratio, ionset, name, path_out)\n",
    "#         else:\n",
    "#             plt.close('all')\n",
    "\n",
    "#         return name, {\n",
    "#             'original': data,\n",
    "#             'baseline': baseline_fit,\n",
    "#             'bkg_removed': bkg_removed,\n",
    "#             'intensity_L3': peak_intensities[0],\n",
    "#             'intensity_L2': peak_intensities[1],\n",
    "#             'L3_L2_ratio': ratio,\n",
    "#             'L3_energy': energy[ionset[0]],\n",
    "#             'L2_energy': energy[ionset[1]],\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(f\"[!] {name} 出错: {e}\")\n",
    "#         return name, None\n",
    "\n",
    "# def process_dataframe(df: pd.DataFrame, energy_column='energy', threshold=0.1, plot_each=False, path_out=path_out):\n",
    "#     energy = df[energy_column].values\n",
    "#     spectra_names = df.columns.drop(energy_column)\n",
    "\n",
    "#     results = {}\n",
    "\n",
    "#     for name in spectra_names:\n",
    "#         spectrum = df[name].values\n",
    "#         try:\n",
    "#             result = process_one_spectrum(name, energy, spectrum, threshold, plot_each, path_out)\n",
    "#             if result and isinstance(result, tuple) and len(result) == 2:\n",
    "#                 _, data = result\n",
    "#                 results[name] = data\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {name}: {e}\")\n",
    "\n",
    "#     if not results:\n",
    "#         raise ValueError(\"No valid spectra processed.\")\n",
    "\n",
    "#     dataset = xr.Dataset(\n",
    "#         data_vars={\n",
    "#             'data': (['spectrum', 'energy'], np.array([v['original'] for v in results.values()])),\n",
    "#             'baseline': (['spectrum', 'energy'], np.array([v['baseline'] for v in results.values()])),\n",
    "#             'bkg_removed': (['spectrum', 'energy'], np.array([v['bkg_removed'] for v in results.values()])),\n",
    "#             'intensity_L3': (['spectrum'], [v['intensity_L3'] for v in results.values()]),\n",
    "#             'intensity_L2': (['spectrum'], [v['intensity_L2'] for v in results.values()]),\n",
    "#             'L3_L2_ratio': (['spectrum'], [v['L3_L2_ratio'] for v in results.values()]),\n",
    "#             'L3_energy': (['spectrum'], [v['L3_energy'] for v in results.values()]),\n",
    "#             'L2_energy': (['spectrum'], [v['L2_energy'] for v in results.values()])\n",
    "#         },\n",
    "#         coords={\n",
    "#             'spectrum': list(results.keys()),\n",
    "#             'energy': energy\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f471c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\\EELS_Mn_raw.csv\")\n",
    "# df = pd.read_csv(file_path, sep=',', header=0)\n",
    "# df.iloc[:20, 1:] = df.iloc[:20, 1:].where(lambda x: (x > -5)&(x < 100), 0) \n",
    "# xr_result = process_dataframe(df[df['energy'] < 680.0], plot_each=True, path_out=path_out, threshold=0.1)\n",
    "# xr_result.to_netcdf(path_out.joinpath(f\"TEM_EELS_Fit.NETCDF4\"), engine=\"h5netcdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c940a1",
   "metadata": {},
   "source": [
    "#### 单独画 两个之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d511f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_mappings_Mn = hs.load(r\"C:\\Users\\chengliu\\Desktop\\Figure\\3-ps_Mn_mapping.hspy\")\n",
    "# ps_mappings_Zn = hs.load(r\"C:\\Users\\chengliu\\Desktop\\Figure\\3-ps_Zn_mapping.hspy\")\n",
    "# ps_mappings_mask = hs.load(r\"C:\\Users\\chengliu\\Desktop\\Figure\\3-ps_Zn_Mn_mask.hspy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ca651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "# from PIL import Image\n",
    "\n",
    "# def generate_distribution_phase_mapping(\n",
    "#     mapping_Mn: np.ndarray,\n",
    "#     mapping_Zn: np.ndarray,\n",
    "#     mask: np.ndarray,\n",
    "#     k_min: float | None = None,\n",
    "#     k_max: float | None = None,\n",
    "#     k_step: float = 0.2,\n",
    "#     gif_path: path = None,\n",
    "#     figsize: tuple = (12, 2.5),\n",
    "#     dpi: int = 100,\n",
    "#     bins: int = 100,\n",
    "# ) -> None:\n",
    "#     assert mapping_Mn.shape == mapping_Zn.shape == mask.shape, \"All input arrays must have the same shape.\"\n",
    "\n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#         K_all = np.where(mapping_Zn != 0, mapping_Mn / mapping_Zn, np.nan)\n",
    "#         K_map = np.where((mapping_Zn != 0) & (~mask), mapping_Mn / mapping_Zn, np.nan)\n",
    "\n",
    "#     Mn_all = mapping_Mn.flatten()\n",
    "#     Zn_all = mapping_Zn.flatten()\n",
    "#     K_all_flat = K_all.flatten()\n",
    "#     valid_all = np.isfinite(K_all_flat)\n",
    "#     Mn_all = Mn_all[valid_all]\n",
    "#     Zn_all = Zn_all[valid_all]\n",
    "#     K_all_flat = K_all_flat[valid_all]\n",
    "\n",
    "#     mapping_Mn_A = mapping_Mn[~mask]\n",
    "#     mapping_Zn_A = mapping_Zn[~mask]\n",
    "#     K_flat = K_map[~mask]\n",
    "#     valid = np.isfinite(K_flat)\n",
    "#     mapping_Mn_A_K = mapping_Mn_A[valid]\n",
    "#     mapping_Zn_A_K = mapping_Zn_A[valid]\n",
    "#     K_flat = K_flat[valid]\n",
    "\n",
    "#     if k_min is None:\n",
    "#         k_min = float(np.nanmin(K_flat))\n",
    "#     if k_max is None:\n",
    "#         k_max = float(np.nanmax(K_flat))\n",
    "#     k_ranges = np.arange(k_min, k_max, k_step)\n",
    "\n",
    "#     cmap_base = plt.cm.hot_r(np.linspace(0.2, 0.8, 256))\n",
    "#     cmap = LinearSegmentedColormap.from_list('cmap', cmap_base)\n",
    "#     cmap.set_over('white')\n",
    "#     cmap.set_under('black')\n",
    "\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=figsize, gridspec_kw={'wspace': 0.05}, constrained_layout=True)\n",
    "#     ax_hist, ax_overlay, ax_map = axes\n",
    "\n",
    "#     ax_hist.set_position([0.05, 0.18, 0.3, 0.7])\n",
    "#     ax_overlay.set_position([0.3, 0.18, 0.3, 0.7])\n",
    "#     ax_map.set_position([0.55, 0.35, 0.4, 0.7])\n",
    "\n",
    "#     ax_hist.set_box_aspect(1.0)\n",
    "#     ax_hist.hist2d(Mn_all, Zn_all, cmap=cmap, cmin=1, bins=bins)\n",
    "#     sc1 = ax_hist.scatter([], [], s=2, c='magenta', alpha=0.1)\n",
    "#     legend_text1 = ax_hist.text(0.95, 0.95, '', ha='right', va='top', transform=ax_hist.transAxes, fontsize=8)\n",
    "#     ax_hist.set_title(\"Before Masking\", fontsize=12, loc='left')\n",
    "#     ax_hist.set_xlabel(\"Mn\")\n",
    "#     ax_hist.set_ylabel(\"Zn\")\n",
    "\n",
    "#     ax_overlay.set_box_aspect(1.0)\n",
    "#     ax_overlay.hist2d(mapping_Mn_A_K, mapping_Zn_A_K, cmap=cmap, cmin=1, bins=bins)\n",
    "#     sc2 = ax_overlay.scatter([], [], s=2, c='magenta', alpha=0.1)\n",
    "#     legend_text2 = ax_overlay.text(0.95, 0.95, '', ha='right', va='top', transform=ax_overlay.transAxes, fontsize=8)\n",
    "#     ax_overlay.set_title(\"After Masking\", fontsize=12, loc='left')\n",
    "#     ax_overlay.set_xlabel(\"Mn\")\n",
    "#     ax_overlay.set_ylabel(\"Zn\")\n",
    "\n",
    "#     masked_map = np.where(mask, np.nan, mapping_Mn)\n",
    "#     img_map = ax_map.imshow(masked_map, cmap='gray')\n",
    "#     ax_map.set_title(\"Distribution of Mn\", fontsize=12, loc='left')\n",
    "#     ax_map.axis('off')\n",
    "\n",
    "#     mask_overlay = ax_map.imshow(np.zeros_like(mapping_Mn), cmap='hot', alpha=0.7, vmin=0, vmax=1)\n",
    "\n",
    "#     tiff_stack = []\n",
    "\n",
    "#     for frame_index in range(len(k_ranges)):\n",
    "#         k_start = k_ranges[frame_index]\n",
    "#         k_end = k_start + k_step\n",
    "\n",
    "#         range_mask_all = (K_all_flat > k_start) & (K_all_flat <= k_end)\n",
    "#         Mn_all_selected = Mn_all[range_mask_all]\n",
    "#         Zn_all_selected = Zn_all[range_mask_all]\n",
    "#         sc1.set_offsets(np.column_stack((Mn_all_selected, Zn_all_selected)))\n",
    "#         legend_text1.set_text(f'{k_start:.2f} < K ≤ {k_end:.2f}')\n",
    "\n",
    "#         range_mask_flat = (K_flat > k_start) & (K_flat <= k_end)\n",
    "#         Mn_filtered = mapping_Mn_A_K[range_mask_flat]\n",
    "#         Zn_filtered = mapping_Zn_A_K[range_mask_flat]\n",
    "#         sc2.set_offsets(np.column_stack((Mn_filtered, Zn_filtered)))\n",
    "#         legend_text2.set_text(f'{k_start:.2f} < K ≤ {k_end:.2f}')\n",
    "\n",
    "#         range_mask_2d = (K_map > k_start) & (K_map <= k_end)\n",
    "#         mask_overlay.set_data(range_mask_2d.astype(float))\n",
    "\n",
    "#         fig.canvas.draw()\n",
    "#         img_array = np.asarray(fig.canvas.buffer_rgba())[:, :, :3]\n",
    "#         pil_img = Image.fromarray(img_array)\n",
    "#         tiff_stack.append(pil_img.convert(\"RGB\"))\n",
    "\n",
    "#     # 保存 TIFF stack\n",
    "#     tiff_output_path = gif_path.joinpath('K_distribution_with_kmask_stack.tif')\n",
    "#     tiff_stack[0].save(\n",
    "#         tiff_output_path,\n",
    "#         save_all=True,\n",
    "#         append_images=tiff_stack[1:],\n",
    "#         compression=\"tiff_deflate\"\n",
    "#     )\n",
    "\n",
    "#     plt.close(fig)\n",
    "#     print(f\"[✔] TIFF stack saved to: {tiff_output_path.resolve()}\")\n",
    "\n",
    "# generate_distribution_phase_mapping(\n",
    "#     ps_mappings_Mn.data,\n",
    "#     ps_mappings_Zn.data,\n",
    "#     ps_mappings_mask.data,\n",
    "#     k_min=-0.2,\n",
    "#     k_max=5.0,\n",
    "#     k_step=0.1,\n",
    "#     gif_path=path_out,\n",
    "#     figsize=(10, 2.5),\n",
    "#     dpi=80,\n",
    "#     bins=60\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
