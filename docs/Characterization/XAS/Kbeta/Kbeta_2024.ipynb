{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb01150c-ebaa-40ef-87fd-9aa8e9d1987f",
   "metadata": {},
   "source": [
    "## Kbeta -CLAESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7de14c-6167-4801-9711-76863bc1e742",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Version-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75867bf-b685-4330-9258-f91ab7614462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "import sys\n",
    "from IPython.display import display\n",
    "import spectrochempy as scp\n",
    "from spectrochempy import Coord, CoordSet, NDDataset, ur\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path as path\n",
    "import scipy \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colorbar import Colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d443ba-fcc0-40c9-be50-f60a7d3cf4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d6af3-5087-4487-96a9-98fd57716151",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 读取数据并 denoise, 得到平均化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83eb15e-9a04-4d0c-96d4-6abdb5b473ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹\n",
    "path_data_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Data')\n",
    "path_out_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Results\\Version-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209bbdb-1e78-480b-a876-7aa0e4ac52fa",
   "metadata": {},
   "source": [
    "#### 寻找平均谱线以及峰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0492e-7412-4068-bac9-ce38161e656f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_filelist = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        path_filelist.append(file_dir)\n",
    "display(path_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3ac2b-6d23-4d20-b168-285aa155a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基线校准\n",
    "blc = scp.Baseline(\n",
    "    log_level=\"INFO\",\n",
    "    model=\"polynomial\",  # use a polynomial model\n",
    "    order='linear',  # with linear method\n",
    "    ranges=([6462., 6463.], [6510., 6511.]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e265eb-7165-43af-81bf-2a7ad55e70db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data_mean_corrected_normal = pd.DataFrame()\n",
    "for path_ref in path_filelist:\n",
    "    \n",
    "    path_out_ref = path.joinpath(path_out_folder, f'{path_ref.parts[-2]}')\n",
    "    path_out_ref.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    ref_txt_data_merge = []\n",
    "    for filetxt in path_ref.glob(r'*.txt'):\n",
    "        ref_txt_data = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        ref_txt_data_merge.append(ref_txt_data)     \n",
    "    ref_txt_data_merge = pd.concat(ref_txt_data_merge, axis=1, ignore_index=True,)\n",
    "    ref_txt_data_merge.to_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_Raw_All.csv'), index=None, header=True)\n",
    "    \n",
    "    ref_data_scp = NDDataset(data=ref_txt_data_merge.iloc[:, 1::2].T.values,\n",
    "                             author=\"Cheng Liu\",\n",
    "                             description=\"Kbeta of Mn, ALBA\",\n",
    "                             history=\"creation\",\n",
    "                             )\n",
    "    ref_data_scp.x = Coord(ref_txt_data_merge.iloc[:, 0].values, name='Energy', units=ur.eV,)\n",
    "    ref_data_scp.y = Coord(np.arange((ref_txt_data_merge.shape[1]//2)), name='numbers',)\n",
    "    \n",
    "    # PCA 重构数据\n",
    "    recon_scp_data = scp.denoise(ref_data_scp, ratio=99.8,)\n",
    "    recon_scp_data.plot(clear=True)\n",
    "    \n",
    "    # 基线校准\n",
    "    _ = blc.fit(recon_scp_data)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # _ = scp_corrected.plot(clear=True)\n",
    "    \n",
    "    # 平均化\n",
    "    recon_ref_data_mean = scp_corrected.mean(dim='y', keepdim=True)\n",
    "    # recon_ref_data_mean.plot(clear=True)\n",
    "    \n",
    "    # 归一化\n",
    "    inttrapz_area = scipy.integrate.trapezoid(y=recon_ref_data_mean.data, x=recon_ref_data_mean.x.data)\n",
    "    recon_ref_data_mean_corrected_normal = np.divide(recon_ref_data_mean, inttrapz_area)\n",
    "    recon_ref_data_mean_corrected_normal.plot(clear=True)\n",
    "    recon_ref_data_mean_corrected_normal.write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_mean_normal.csv'),)\n",
    "    data_mean_corrected_normal = pd.concat([data_mean_corrected_normal, pd.DataFrame(recon_ref_data_mean_corrected_normal.data.T)], ignore_index=True, axis=1) \n",
    "        \n",
    "pd.concat([pd.DataFrame(recon_ref_data_mean.x.data), data_mean_corrected_normal], ignore_index=True, axis=1).to_csv(path.joinpath(path_out_folder, r'all_mean_normal.csv'), header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e3939-a848-44ae-8856-6c2cd65593e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# syntax for parameters definition :\n",
    "# name : value, low_bound,  high_bound\n",
    "#  * for fixed parameters\n",
    "#  $ for variable parameters\n",
    "#  > for reference to a parameter in the COMMON block\n",
    "#    (> is forbidden in the COMMON block)\n",
    "# common block parameters should not have a _ in their names\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "COMMON:\n",
    "# common parameters ex.\n",
    "# $ gwidth: 1.0, 0.0, none\n",
    "# $ gratio: 0.5, 0.0, 1.0\n",
    "# $ gasym: 0.3, 0.0, 1.0\n",
    "\n",
    "MODEL: LINE_1\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.12, 0.10, 0.16\n",
    "    $ pos:   6492.6, 6491.3, 9494.6\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "MODEL: LINE_2\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.03, 0.01, 0.05\n",
    "    $ pos:   6477.0, 6470.0, 6480.0\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# script = \"\"\"\n",
    "\n",
    "# #-----------------------------------------------------------\n",
    "# # syntax for parameters definition :\n",
    "# # name : value, low_bound,  high_bound\n",
    "# #  * for fixed parameters\n",
    "# #  $ for variable parameters\n",
    "# #  > for reference to a parameter in the COMMON block\n",
    "# #    (> is forbidden in the COMMON block)\n",
    "# # common block parameters should not have a _ in their names\n",
    "# #-----------------------------------------------------------\n",
    "# #\n",
    "# COMMON:\n",
    "# # common parameters ex.\n",
    "\n",
    "# MODEL: linez\n",
    "# shape: asymmetricvoigtmodel\n",
    "# $ ampl: 0.12, 0.10, 0.16\n",
    "# $ width: 0.5, 0.0, 10\n",
    "# $ pos: 6492.6, 6492.4,  9493.5\n",
    "# $ ratio: 0.5, 0.0, 1.0\n",
    "# $ asym: 0.3, 0.0, 1.0\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2804344-196a-4660-a70c-4752492ad134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取 Peaks 的 STD 和 面积的 STD\n",
    "path_filelist = []\n",
    "for item in path_out_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        path_filelist.append(item)\n",
    "# display(path_filelist)\n",
    "\n",
    "# MnO2 作为标样\n",
    "data = pd.read_csv(path.joinpath(path_filelist[4], f'{path_filelist[4].parts[-1]}_mean_normal.csv'), comment='#', sep=r',', header=0, index_col=None).to_numpy()\n",
    "ref = NDDataset(data=data[:, 1], title=r'Absorption', name=f'{path_filelist[4].parts[-1]}',)\n",
    "ref.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "# ref.plot()\n",
    "\n",
    "std_out = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(path.joinpath(file, f'{file.parts[-1]}_Raw_All.csv'), sep=',', header=0, index_col=None, comment=\"#\")\n",
    "    scp_data = NDDataset(data=data.iloc[:, 1::2].values.T,\n",
    "                         author=\"Cheng Liu\",\n",
    "                         description=\"Kbeta of Mn, ALBA\",\n",
    "                         history=\"creation\",\n",
    "                         )\n",
    "    scp_data.x = Coord(data.iloc[:, 0].values, name='Energy', units=ur.eV,)\n",
    "    scp_data.y = Coord(np.arange((data.iloc[:, 1::2].shape[1])), name='numbers', )\n",
    "    # scp_data.plot()\n",
    "\n",
    "    # PCA 重构数据\n",
    "    recon_scp_data = scp.denoise(scp_data, ratio=99.8,)\n",
    "    # print(recon_scp_data.shape)\n",
    "    # _ = recon_scp_data.plot(clear=True)\n",
    "    \n",
    "    # 基线校准\n",
    "    _ = blc.fit(recon_scp_data)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # _ = scp_corrected.plot(clear=True)\n",
    "    # _ = scp_baseline.plot(clear=True)\n",
    "    \n",
    "    # 归一化\n",
    "    inttrapz_area = scipy.integrate.trapezoid(y=scp_corrected.data, x=scp_corrected.x.data)\n",
    "    for i in range(scp_corrected.shape[0]):\n",
    "        scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "    \n",
    "    # 寻峰，以及 std 分布\n",
    "    peakslist = [s.find_peaks(distance=10)[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "    peakslist = pd.DataFrame(peakslist)\n",
    "\n",
    "#     # 寻峰，以及 std 分布，fitting 的办法\n",
    "#     peakslist = []\n",
    "#     for i in range(scp_corrected.shape[0]):\n",
    "#         f1 = scp.Optimize(log_level=\"WARNING\",)\n",
    "#         f1.script = script\n",
    "#         f1.max_iter = 2000\n",
    "#         f1.fit(scp_corrected[i, :])\n",
    "\n",
    "#         # # Show the result\n",
    "#         # scp_corrected[i, :].plot()\n",
    "#         # ax = (f1.components[:]).plot(clear=False)\n",
    "#         # ax.autoscale(enable=True, axis=\"y\")\n",
    "\n",
    "#         # # plotmerit\n",
    "#         # som = f1.inverse_transform()\n",
    "#         # f1.plotmerit(offset=0, kind=\"scatter\")\n",
    "#         recon_scp_corrected = f1.inverse_transform()\n",
    "#         display(recon_scp_corrected)\n",
    "#         peaks = recon_scp_corrected[6490.0:6500.0].find_peaks(distance=10)[0].x.data\n",
    "#         peakslist.append(peaks)\n",
    "#     _ = pd.DataFrame(peakslist).plot()\n",
    "    # peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "\n",
    "    peakstd = peakslist.std(ddof=0)\n",
    "    peakmean = peakslist.mean()\n",
    "    # _ = peakslist.plot()\n",
    "\n",
    "    # IDA 面积，以及 std 分布\n",
    "    diff = scp_corrected - ref\n",
    "    # diff.plot(clear=True)\n",
    "    arealist = scipy.integrate.trapezoid(y=np.abs(diff.data), x=diff.x.data)\n",
    "    arealist = pd.DataFrame(arealist)\n",
    "    arealist_std = arealist.std(ddof=0)\n",
    "    arealist_mean = arealist.mean()\n",
    "    # _ = inttrapz_area.plot()\n",
    "    errorbar = pd.concat([pd.Series(f'{file.parts[-1]}'), peakmean, peakstd, arealist_mean, arealist_std], axis=1, ignore_index=True,)    \n",
    "    std_out = pd.concat([std_out, errorbar], axis=0, ignore_index=True,)\n",
    "\n",
    "    # 保存数据\n",
    "    (pd.concat([pd.Series(scp_corrected.x.data), pd.DataFrame(scp_corrected.data).T], axis=1, ignore_index=True,).\n",
    "     to_csv(path.joinpath(file, f'{file.parts[-1]}_spectrum_list.csv'), index=None, header=True,))\n",
    "    (pd.concat([peakslist, arealist], axis=1, ignore_index=True,)\n",
    "     .to_csv(path.joinpath(file, f'{file.parts[-1]}_peak_area_list.csv'), index=None, header=[r'peaklist', r'arealist']))\n",
    "    (pd.concat([pd.Series(diff.x.data), pd.DataFrame(diff.data).T], axis=1, ignore_index=True,).\n",
    "     to_csv(path.joinpath(file, f'{file.parts[-1]}_diff_list.csv'), index=None, header=True,))\n",
    "std_out.to_csv(path.joinpath(path_out_folder, r'peak_area_std.csv'), index=False, header=[r'Samples', r'peak_mean', r'peak_std', r'area_mean', r'area_std'])\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae047e-1da8-4ac0-af6c-020535e67e5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Peak + std, area + std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb008a3-62c2-4209-b4bb-3d7ddae6efef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "data_merge = pd.read_csv(path.joinpath(path_out_folder, r'peak_area_std1.csv'), comment='#', sep=r',', header=0, index_col=None)\n",
    "spectrum = pd.read_csv(path.joinpath(path_out_folder, r'all_mean_normal.csv'), comment='#', sep=r',', header=0, index_col=None)\n",
    "display(data_merge.head(2))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(10.5, 3.3))\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1], height_ratios=[1],\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'R3_MnO', r'R4_Mn2O3', r'R5_MnO2', r'S1_pristine', r'S2_1stDisch',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "# 图 A: energy peak + std\n",
    "energy = data_merge.iloc[:, 1:3].copy().dropna()\n",
    "subfig_a = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_a.add_axes((0, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot(energy.iloc[:, 0], lw=1, ls='-', marker='o', zorder=5, color=colors[0])\n",
    "ax.fill_between(x=np.arange(energy.shape[0]), y1=(energy.iloc[:, 0] + energy.iloc[:, 1]),\n",
    "                y2=(energy.iloc[:, 0] - energy.iloc[:, 1]), color=colors[2], alpha=0.3)\n",
    "\n",
    "# ax.set_ylim(6492.4, 6493.3)  # ax.set_ylim(6492.1, 6493.7)\n",
    "ax.set_xticks(np.arange(energy.shape[0]), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'Energy (eV)', fontsize=11)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=6492.0, ymax=6493.9, linestyles='dashed', alpha=0.8)\n",
    "# ax.text(0.02, 0.98, r'1$^{st}$ moment $\\mathit{K \\beta _{1,3}}$', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.3, 1.0, r'A', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 B: area + std\n",
    "area = data_merge.iloc[:, 4:6].copy().dropna()\n",
    "subfig_b = fig.add_subfigure(gs[0, 1], zorder=0)\n",
    "ax = subfig_b.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot((area.iloc[:, 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3, linewidth=1, linestyle='-', marker='o', zorder=5, color=colors[0])\n",
    "y1 = (area.iloc[:, 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y2 = (area.iloc[:, 0]-area.iloc[4, 0] - area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "# display(y1, y2)\n",
    "ax.fill_between(x=np.arange(area.shape[0]), y1=y1, y2=y2, color=colors[2], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "# ax.set_ylim(2.7, 5.1)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.4))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.2))\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=1.7, ymax=5.3, linestyles='dashed')\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.22, 1.0, r'B', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 C: Spectrum\n",
    "subfig_c = fig.add_subfigure(gs[0, 2], zorder=0)\n",
    "ax = subfig_c.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0, 1.0, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_out_folder, r'aa.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f504fc-4b19-4f2d-b2d7-5f6042de8bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "filetype = r'mean'\n",
    "path_file = path.joinpath(path_out_folder, filetype)\n",
    "path_file.mkdir(parents=True, exist_ok=True,)\n",
    "path_filelist = list(path_file.glob(f'all_*_{filetype}.csv'))\n",
    "path_filelist = path_filelist[0:]\n",
    "display(path_filelist)\n",
    "\n",
    "data_merge = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(file, comment='#', sep=r',', header=0, index_col=None)\n",
    "    data_merge = pd.concat([data_merge, data], axis=1, ignore_index=True,)\n",
    "# display(data_merge.head(13))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None,\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'$\\mathrm{Ref.MnO}$', r'$\\mathrm{Ref.Mn_2O_3}$', r'$\\mathrm{Ref.MnO_2}$', r'Pristine', r'Discharge',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "\n",
    "# 图 C: Spectrum\n",
    "spectrum = data_merge.iloc[:, 4:].copy().dropna()\n",
    "subfig_c = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_c.add_axes((0, 0, 1.0, 1.0), zorder=0)\n",
    "ax.set_box_aspect(0.8)\n",
    "\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0.0, 0.5, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "# ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, f'all_{filetype}abaa.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfac2c3-458e-418b-8878-83139286b067",
   "metadata": {},
   "source": [
    "#### 单张图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e8b46-6e02-4acc-b817-745eea9054bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [r'Pristine', r'$1^{st}$ Discharge', r'$1^{st}$ Charge', r'$2^{nd}$ Discharge']\n",
    "\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "ax = fig.add_subplot()\n",
    "area = data_merge.iloc[:, 2:4].copy().dropna()\n",
    "\n",
    "y= (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = y1.dropna()\n",
    "yerror = y-y1\n",
    "\n",
    "ax.errorbar(x=np.arange(y.shape[0]), y=y.dropna().values, yerr=yerror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "ax.set_ylim(2.4, 3.6)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.3))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.15))\n",
    "\n",
    "ax.text(0.02, 0.07, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "d = (area.iloc[[5,6,9,11], 0]-area.iloc[2, 0])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "d1 =(area.iloc[[5,6,9,11], 0]-area.iloc[2, 0] + area.iloc[:, 1])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "derror = (d1-d).dropna()\n",
    "ax2.errorbar(x=np.arange(derror.shape[0]), y=d.dropna().values, yerr=derror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax2.tick_params(axis='x', labelsize=9) \n",
    "ax2.tick_params(axis='y', labelsize=9, labelcolor='k')\n",
    "\n",
    "ax2.set_ylim(4.6, 3.4)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "ax2.set_ylabel(r'Average Mn Oxidation State', fontsize=11, color='k')  # Total Magnetization\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(path.joinpath(path_out, r'Kbeta_3.tif'), transparent=False,\n",
    "            pad_inches=0.05, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801009cd-bb01-420a-af03-7b8e4a62d768",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Version-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1eb37-3244-4760-921b-565ed269da29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "import sys\n",
    "from IPython.display import display\n",
    "import spectrochempy as scp\n",
    "from spectrochempy import Coord, CoordSet, NDDataset, ur\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path as path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colorbar import Colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541010fc-8d09-4264-8adb-3d7cb5bfc229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccb8df-b72d-4aa1-83dd-b41420fb2583",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 读取数据并 denoise, 得到平均化，NMF 和 MCR 后的标样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc150494-e439-4542-85cf-64395dda9a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹\n",
    "path_data_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Data')\n",
    "path_out_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Results\\Version-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c88a75-7257-4f2e-a87d-6c7326eda1be",
   "metadata": {},
   "source": [
    "#### 标样的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ad70c-c739-4ade-9e51-cb10a0a87a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_ref_filelist = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if (item.is_dir()) and (item.parts[-1] in ['R3_MnO', 'R5_MnO2']):\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        path_ref_filelist.append(file_dir)\n",
    "display(path_ref_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7461748-ef8d-49e6-ac56-1ddded0e0591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "path_out_ref = path.joinpath(path_out_folder, r'references')\n",
    "path_out_ref.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 基线校准\n",
    "blc = scp.Baseline(\n",
    "    log_level=\"INFO\",\n",
    "    model=\"polynomial\",  # use a polynomial model\n",
    "    order='linear',  # with linear method\n",
    "    ranges=([6462., 6463.], [6510., 6511.]),)\n",
    "    \n",
    "for path_ref in path_ref_filelist:\n",
    "    \n",
    "    ref_txt_data_merge = []\n",
    "    for filetxt in path_ref.glob(r'*.txt'):\n",
    "        ref_txt_data = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        ref_txt_data_merge.append(ref_txt_data)     \n",
    "    ref_txt_data_merge = pd.concat(ref_txt_data_merge, axis=1, ignore_index=True,)\n",
    "    ref_txt_data_merge.to_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_Raw_All.csv'), index=None, header=True)\n",
    "    \n",
    "    # 画图\n",
    "    fig = plt.figure(figsize=(3.3, 2.5))\n",
    "    gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "    subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "    ax = subfig.add_axes((0, 0, 1, 1),zorder=0)\n",
    "    colors_map = ListedColormap(mpl.colormaps['Spectral'](np.linspace(0.0, 1.0, ref_txt_data_merge.shape[1]//2)), name='colors_map')\n",
    "    for i in range(ref_txt_data_merge.shape[1]//2):\n",
    "        ax.plot(ref_txt_data_merge.iloc[:, 2*i], ref_txt_data_merge.iloc[:, 2*i+1], c=colors_map.colors[i])\n",
    "    ax.set_xlim(6462, 6512)\n",
    "    ax.set_xlabel(r'Energy (eV)', fontsize=11)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=10, offset=-8))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(base=5, offset=-8))\n",
    "    ax.set_ylim(0, 16)\n",
    "    ax.set_ylabel(r\"Absorption (arb.u.)\", fontsize=11)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(base=4))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=2))\n",
    "    \n",
    "    ax.tick_params(axis='both', which='both', labelsize=9, direction='out', bottom=True, top=False, left=True, right=False,\n",
    "                  labelbottom=True, labeltop=False, labelleft=True, labelright=False,) \n",
    "\n",
    "    plt.savefig(path.joinpath(path_out_ref, f'1_300_{path_ref.parts[-2]}_all.tif'), transparent=False, pad_inches=0.05, bbox_inches='tight', dpi=300)\n",
    "    plt.savefig(path.joinpath(path_out_ref, f'1_600_{path_ref.parts[-2]}_all.tif'), transparent=False, pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "    \n",
    "    ref_data_scp = NDDataset(data=ref_txt_data_merge.iloc[:, 1::2].T.values,\n",
    "                             author=\"Cheng Liu\",\n",
    "                             description=\"Kbeta of Mn, ALBA\",\n",
    "                             history=\"creation\",\n",
    "                             )\n",
    "    ref_data_scp.x = Coord(ref_txt_data_merge.iloc[:, 0].values, name='Energy', units=ur.eV,)\n",
    "    ref_data_scp.y = Coord(np.arange((ref_txt_data_merge.shape[1]//2)), name='numbers',)\n",
    "    \n",
    "    # PCA 重构数据\n",
    "    recon_ref_data_scp = scp.denoise(ref_data_scp, ratio=99.8,)\n",
    "    # recon_ref_data_scp.plot(clear=True)\n",
    "    \n",
    "    # 平均化\n",
    "    recon_ref_data_mean = recon_ref_data_scp.mean(dim='y', keepdim=True)\n",
    "    recon_ref_data_mean = scp.stack([recon_ref_data_mean])\n",
    "    # recon_ref_data_mean.plot(clear=True)\n",
    "    \n",
    "    # 去背景\n",
    "    _ = blc.fit(recon_ref_data_mean)   # fit the baseline\n",
    "    recon_ref_data_mean_baseline = blc.baseline\n",
    "    recon_ref_data_mean_corrected = blc.corrected  # get the corrected dataset\n",
    "    # recon_ref_data_mean_corrected.plot(clear=True)\n",
    "    recon_ref_data_mean_corrected.write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_mean.csv'),)\n",
    "    \n",
    "#     # 归一化\n",
    "#     inttrapz_area = mean_corrected.trapezoid(dim=\"x\")\n",
    "#     recon_ref_data_mean_corrected_normal = np.divide(recon_ref_data_mean_corrected, inttrapz_area)\n",
    "#     recon_ref_data_mean_corrected_normal.plot(clear=True)\n",
    "#     recon_ref_data_mean_corrected_normal.write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_mean_normal.csv'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83a019-5a65-43a4-9a26-2259be327626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recon_ref_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c6a47-6ec7-478b-96b7-18ab6347a176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取标样\n",
    "path_ref_filelist = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if (item.is_dir()) and (item.parts[-1] in ['R3_MnO', 'R5_MnO2']):\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        path_ref_filelist.append(file_dir)\n",
    "path_ref_filelist = path_ref_filelist[0:]\n",
    "# display(path_ref_filelist)\n",
    "\n",
    "for path_ref in path_ref_filelist:\n",
    "    ref_txt_data_merge = pd.DataFrame()\n",
    "    for filetxt in path_ref.glob(r'*.txt'):\n",
    "        ref_txt_data = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        ref_txt_data_merge = pd.concat([ref_txt_data_merge, ref_txt_data], axis=1, ignore_index=True,)\n",
    "    ref_txt_data_merge = ref_txt_data_merge.to_numpy()\n",
    "    ref_data_scp = NDDataset(data=ref_txt_data_merge[:, 1::2].T,\n",
    "                             author=\"Cheng Liu\",\n",
    "                             description=\"Kbeta of Mn, ALBA\",\n",
    "                             history=\"creation\",\n",
    "                             )\n",
    "    ref_data_scp.x = Coord(ref_txt_data_merge[:, 0], name='Energy', units=ur.eV,)\n",
    "    ref_data_scp.y = Coord(np.arange((ref_txt_data_merge[:, 1::2].shape[1])), name='numbers', )\n",
    "    # ref_data_scp.plot()\n",
    "\n",
    "    # PCA 重构数据\n",
    "    recon_ref_data_scp = scp.denoise(ref_data_scp, ratio=99.8,)\n",
    "    # recon_ref_data_scp.plot()\n",
    "\n",
    "    # 基线校准\n",
    "    blc = scp.Baseline(\n",
    "            log_level=\"INFO\",\n",
    "            model=\"polynomial\",  # use a polynomial model\n",
    "            order='linear',  # with linear method\n",
    "            ranges=([6462., 6463.], [6510., 6511.]),\n",
    "            )\n",
    "\n",
    "    _ = blc.fit(recon_ref_data_scp)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # scp_corrected.plot()\n",
    "\n",
    "    # Evolving Factor Analysis (EFA) 计算\n",
    "    efa = scp.EFA()\n",
    "    efa.fit(scp_corrected)\n",
    "    efa.n_components = 2\n",
    "    C0 = efa.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    St = efa.get_components()\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # # NMF\n",
    "    # scp_corrected -= scp_corrected.min()\n",
    "    # model = scp.NMF(n_components=2, log_level=\"INFO\")\n",
    "    # _ = model.fit(scp_corrected)\n",
    "    # C0 = model.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    # St = model.components\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # MCR\n",
    "    mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200,\n",
    "                     nonnegConc='all', nonnegSpec='all',\n",
    "                     )\n",
    "    mcr.fit(scp_corrected, St)\n",
    "    # _ = mcr.C.T.plot()\n",
    "    # _ = mcr.St.plot()\n",
    "\n",
    "    # MCR 归一化\n",
    "    mcr_st = mcr.St\n",
    "    inttrapz_area = mcr_st.trapezoid(dim=\"x\")\n",
    "    for i in range(mcr_st.shape[0]):\n",
    "        mcr_st[i, :] = np.divide(mcr_st[i, :], inttrapz_area[i])\n",
    "\n",
    "    # EFA 归一化\n",
    "    inttrapz_area = St.trapezoid(dim=\"x\")\n",
    "    for i in range(St.shape[0]):\n",
    "        St[i, :] = np.divide(St[i, :], inttrapz_area[i])\n",
    "\n",
    "    # MEAN\n",
    "    mean = scp.mean(recon_ref_data_scp.T, dim='y', keepdims=True,).T\n",
    "    _ = blc.fit(mean)   # fit the baseline\n",
    "    mean_baseline = blc.baseline\n",
    "    mean_corrected = blc.corrected  # get the corrected dataset\n",
    "    # mean_corrected.plot()\n",
    "\n",
    "    # MEAN 归一化\n",
    "    inttrapz_area = mean_corrected.trapezoid(dim=\"x\")\n",
    "    for i in range(mean_corrected.shape[0]):\n",
    "        mean_corrected[i, :] = np.divide(mean_corrected[i, :], inttrapz_area[i])\n",
    "\n",
    "    # # 画图\n",
    "    # ax = St[1].plot(c='r')\n",
    "    # mean_corrected.plot(ax=ax, clear=False, c='b')\n",
    "    # mcr_st[0].plot(ax=ax, clear=False, c='k')\n",
    "\n",
    "    # 保存数据\n",
    "    path_out_ref = path.joinpath(path_out_folder, r'references')\n",
    "    path_out_ref.mkdir(parents=True, exist_ok=True)\n",
    "    St[1].write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_efa.csv'),)\n",
    "    mean_corrected.write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_mean.csv'),)\n",
    "    mcr_st[0].write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_mcr.csv'),)\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebb948-fdea-40d8-8ed8-5ebbfd860d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# syntax for parameters definition :\n",
    "# name : value, low_bound,  high_bound\n",
    "#  * for fixed parameters\n",
    "#  $ for variable parameters\n",
    "#  > for reference to a parameter in the COMMON block\n",
    "#    (> is forbidden in the COMMON block)\n",
    "# common block parameters should not have a _ in their names\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "COMMON:\n",
    "# common parameters ex.\n",
    "# $ gwidth: 1.0, 0.0, none\n",
    "# $ gratio: 0.5, 0.0, 1.0\n",
    "# $ gasym: 0.3, 0.0, 1.0\n",
    "\n",
    "MODEL: LINE_1\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.12, 0.10, 0.16\n",
    "    $ pos:   6492.6, 6491.3, 9494.6\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "MODEL: LINE_2\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.03, 0.01, 0.05\n",
    "    $ pos:   6477.0, 6470.0, 6480.0\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1427ad-80a1-446e-9899-582093323c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script = \"\"\"\n",
    "\n",
    "# #-----------------------------------------------------------\n",
    "# # syntax for parameters definition :\n",
    "# # name : value, low_bound,  high_bound\n",
    "# #  * for fixed parameters\n",
    "# #  $ for variable parameters\n",
    "# #  > for reference to a parameter in the COMMON block\n",
    "# #    (> is forbidden in the COMMON block)\n",
    "# # common block parameters should not have a _ in their names\n",
    "# #-----------------------------------------------------------\n",
    "# #\n",
    "# COMMON:\n",
    "# # common parameters ex.\n",
    "\n",
    "# MODEL: linez\n",
    "# shape: asymmetricvoigtmodel\n",
    "# $ ampl: 0.12, 0.10, 0.16\n",
    "# $ width: 0.5, 0.0, 10\n",
    "# $ pos: 6492.6, 6492.4,  9493.5\n",
    "# $ ratio: 0.5, 0.0, 1.0\n",
    "# $ asym: 0.3, 0.0, 1.0\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f9f25-f0c1-4db8-8fff-b476b46910c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取归一化后的 ref 谱线\n",
    "filetype = r'efa'\n",
    "path_filetype_folder = path.joinpath(path_out_folder, filetype)\n",
    "path_filetype_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filelist_ref = list(path_out_ref.glob(f'R3_*_ref_{filetype}.csv'))\n",
    "# print(filelist_ref)\n",
    "data = pd.read_csv(filelist_ref[0], comment='#', sep=r',', header=0).to_numpy()\n",
    "ref = NDDataset(data=data[:, 1], title=r'Absorption', name=f'{filelist_ref[0].stem}',)\n",
    "ref.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "# ref.plot()\n",
    "\n",
    "# 读取数据文件夹\n",
    "filelist1 = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        filelist1.append(file_dir)\n",
    "filelist1 = filelist1[0:]\n",
    "# print(filelist1)\n",
    "\n",
    "std_out = pd.DataFrame()\n",
    "for file in filelist1:\n",
    "    data = pd.DataFrame()\n",
    "    for filetxt in file.glob('*.txt'):\n",
    "        data_txt = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        data = pd.concat([data, data_txt], axis=1, ignore_index=True,)\n",
    "    data = data.to_numpy()\n",
    "    scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "                         author=\"Cheng Liu\",\n",
    "                         description=\"Kbeta of Mn, ALBA\",\n",
    "                         history=\"creation\",\n",
    "                         )\n",
    "    scp_data.x = Coord(data[:, 0], name='Energy', units=ur.eV,)\n",
    "    scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), name='numbers', )\n",
    "    # scp_data.plot()\n",
    "\n",
    "    # PCA 重构数据\n",
    "    recon_scp_data = scp.denoise(scp_data, ratio=99.8,)\n",
    "    # print(recon_scp_data.shape)\n",
    "    # recon_scp_data.plot()\n",
    "\n",
    "    # 基线校准\n",
    "    blc = scp.Baseline(\n",
    "            log_level=\"INFO\",\n",
    "            model=\"polynomial\",  # use a polynomial model\n",
    "            order='linear',  # with linear method\n",
    "            ranges=([6462., 6463.], [6510., 6511.]),\n",
    "            )\n",
    "\n",
    "    _ = blc.fit(recon_scp_data)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # scp_corrected.plot()\n",
    "\n",
    "    # scp.plot_multiple(\n",
    "    #     method=\"scatter\",\n",
    "    #     ms=5,\n",
    "    #     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "    #     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "    #     legend=\"best\",\n",
    "    # )\n",
    "\n",
    "    # Evolving Factor Analysis (EFA) 计算\n",
    "    efa = scp.EFA()\n",
    "    efa.fit(scp_corrected)\n",
    "    efa.n_components = 2\n",
    "    # C0 = efa.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    St = efa.get_components()\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # MCR\n",
    "    mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200,\n",
    "                     nonnegConc='all', nonnegSpec='all',)\n",
    "    mcr.fit(scp_corrected, St)\n",
    "    # _ = mcr.C.T.plot()\n",
    "    # _ = mcr.St.plot()\n",
    "\n",
    "    # MCR 归一化\n",
    "    mcr_st = mcr.St\n",
    "    inttrapz_area = mcr_st.trapezoid(dim=\"x\")\n",
    "    for i in range(mcr_st.shape[0]):\n",
    "        mcr_st[i, :] = np.divide(mcr_st[i, :], inttrapz_area[i])\n",
    "\n",
    "    # EFA 归一化\n",
    "    inttrapz_EFA_ref = St.trapezoid(dim=\"x\")\n",
    "    # intsimps_EFA_ref = St.simpson(dim=\"x\")\n",
    "    for i in range(St.shape[0]):\n",
    "        St[i, :] = np.divide(St[i, :], inttrapz_EFA_ref[i])\n",
    "\n",
    "    # 平均值\n",
    "    mean = scp.mean(scp_corrected.T, dim='y', keepdims=True,).T\n",
    "    _ = blc.fit(mean)   # fit the baseline\n",
    "    mean_baseline = blc.baseline\n",
    "    mean_corrected = blc.corrected  # get the corrected dataset\n",
    "    # mean_corrected.plot()\n",
    "\n",
    "    # 平均值 归一化\n",
    "    inttrapz_MEAN_ref = mean_corrected.trapezoid(dim=\"x\")\n",
    "    # intsimps_MEAN_ref = mean_corrected.simpson(dim=\"x\")\n",
    "    for i in range(mean_corrected.shape[0]):\n",
    "        mean_corrected[i, :] = np.divide(mean_corrected[i, :], inttrapz_MEAN_ref[i])\n",
    "\n",
    "    # # 画图\n",
    "    # ax = St[1].plot(c='r')\n",
    "    # mean_corrected.plot(ax=ax, clear=False, c='b')\n",
    "    # mcr_st[0].plot(ax=ax, clear=False, c='k')\n",
    "\n",
    "    # 整体数据 归一化\n",
    "    inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "#     intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "    for i in range(scp_corrected.shape[0]):\n",
    "        scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "    # _ = scp_corrected.plot(lw=1.0, figure_figsize=(3.3, 2.5), clear=True,)\n",
    "\n",
    "    # 面积，以及 std 分布\n",
    "    # (scp_corrected[:]-ref).plot()\n",
    "    inttrapz_area = scp.abs(scp_corrected[:]-ref).trapezoid(dim=\"x\")\n",
    "    inttrapz_area_std = pd.DataFrame(inttrapz_area.data).std(ddof=0)\n",
    "    # inttrapz_area.plot()\n",
    "\n",
    "    # # 寻峰，以及 std 分布\n",
    "    # peakslist = [s.find_peaks(distance=10)[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "    # peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "    # # _ = pd.DataFrame(peakslist).plot()\n",
    "\n",
    "    # 寻峰，以及 std 分布，fitting 的办法\n",
    "    peakslist = []\n",
    "    for i in range(scp_corrected.shape[0]):\n",
    "        f1 = scp.Optimize(log_level=\"WARNING\",)\n",
    "        f1.script = script\n",
    "        f1.max_iter = 2000\n",
    "        f1.fit(scp_corrected[i, :])\n",
    "\n",
    "        # # Show the result\n",
    "        # scp_corrected[i, :].plot()\n",
    "        # ax = (f1.components[:]).plot(clear=False)\n",
    "        # ax.autoscale(enable=True, axis=\"y\")\n",
    "\n",
    "        # # plotmerit\n",
    "        # som = f1.inverse_transform()\n",
    "        # f1.plotmerit(offset=0, kind=\"scatter\")\n",
    "        recon_scp_corrected = f1.inverse_transform()\n",
    "        # display(recon_scp_corrected)\n",
    "        peaks = recon_scp_corrected[6490.0:6500.0].find_peaks(distance=10)[0].x.data\n",
    "        peakslist.append(peaks)\n",
    "    # pd.DataFrame(peakslist).plot()\n",
    "    peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "\n",
    "    std = pd.concat([peakstd, inttrapz_area_std], axis=1, ignore_index=True,)\n",
    "    std_out = pd.concat([std_out, std], axis=0, ignore_index=True,)\n",
    "\n",
    "    # 保存数据\n",
    "    path_file = path.joinpath(path_filetype_folder, file.parts[-2])\n",
    "    path_file.mkdir(parents=True, exist_ok=True)\n",
    "    St[1].write_csv(path.joinpath(path_file, f'{file.parts[-2]}_efa.csv'),)\n",
    "    mean_corrected.write_csv(path.joinpath(path_file, f'{file.parts[-2]}_mean.csv'),)\n",
    "    mcr_st[0].write_csv(path.joinpath(path_file, f'{file.parts[-2]}_mcr.csv'),)\n",
    "\n",
    "    (pd.concat([pd.Series(data[:, 0]), pd.DataFrame(scp_corrected.data).T], axis=1, ignore_index=True,).\n",
    "     to_csv(path.joinpath(path_file, f'{file.parts[-2]}_spectrum_norm.csv'), index=None, header=True,))\n",
    "    (pd.concat([pd.DataFrame(peakslist), pd.DataFrame(inttrapz_area.data)], axis=1, ignore_index=True,)\n",
    "     .to_csv(path.joinpath(path_file, f'{file.parts[-2]}_peak_area.csv'),\n",
    "             index=None, header=[f'{file.parts[-2]}_peak', f'{file.parts[-2]}_area']))\n",
    "\n",
    "std_out.to_csv(path.joinpath(path_filetype_folder, f'peak_area_std_{filetype}.csv'), index=False, header=[r'peak_std', r'area_std'],)\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9927b-646a-4acb-a2a8-d0641a1daf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取 std 文件\n",
    "\n",
    "std_file = list(path_filetype_folder.glob(f'*_{filetype}.csv'))\n",
    "df_std = pd.read_csv(std_file[0], index_col=None, header=0)\n",
    "\n",
    "# 读取所有的 filetype 文件路径\n",
    "filelist2 = []\n",
    "for item in path_filetype_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        file_dir = list(item.glob(f'*_{filetype}.csv'))\n",
    "        filelist2.append(file_dir)\n",
    "filelist2 = filelist2[0:]\n",
    "# print(filelist2)\n",
    "# 将所有 Raw Data 写入 NDDataset\n",
    "data = pd.DataFrame()\n",
    "for file in filelist2:\n",
    "    df = pd.read_csv(file[0], index_col=None, header=0)\n",
    "    data = pd.concat([data, df], axis=1, ignore_index=True,)\n",
    "data = data.to_numpy()\n",
    "scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "                     author=\"Cheng Liu\",\n",
    "                     description=\"Kbeta of Mn, ALBA\",\n",
    "                     history=\"creation\",\n",
    "                     title='Count',\n",
    "                     )\n",
    "scp_data.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), title='numbers', )\n",
    "# scp_data.plot()\n",
    "\n",
    "# 基线校准\n",
    "blc = scp.Baseline(\n",
    "        log_level=\"INFO\",\n",
    "        model=\"polynomial\",  # use a polynomial model\n",
    "        order='linear',  # with linear method\n",
    "        # ranges=([6462., 6465.], [6505., 6511.]),\n",
    "        ranges=([6462., 6463.], [6510., 6511.]),\n",
    "        )\n",
    "\n",
    "_ = blc.fit(scp_data)   # fit the baseline\n",
    "scp_baseline = blc.baseline\n",
    "scp_corrected = blc.corrected  # get the corrected dataset\n",
    "\n",
    "# scp.plot_multiple(\n",
    "#     method=\"scatter\",\n",
    "#     ms=5,\n",
    "#     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "#     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "#     legend=\"best\",\n",
    "# )\n",
    "\n",
    "# 计算面积\n",
    "inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "# intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "\n",
    "# scp.plot_multiple(\n",
    "#     method=\"scatter\",\n",
    "#     ms=5,\n",
    "#     datasets=[inttrapz_area,  intsimps_area],\n",
    "#     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#     legend=\"best\",\n",
    "# )\n",
    "\n",
    "# 归一化\n",
    "for i in range(scp_corrected.shape[0]):\n",
    "    scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "# _ = scp_corrected.plot(lw=1.0, figure_figsize=(3.3, 2.5), clear=True,)\n",
    "\n",
    "# # 寻峰\n",
    "# peakslist = [s.find_peaks(distance=10, )[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "# peakslist = pd.DataFrame(peakslist)\n",
    "# # _ = peakslist.plot(lw=1.0)\n",
    "\n",
    "# 寻峰，fitting 的办法\n",
    "peakslist = []\n",
    "for i in range(scp_corrected.shape[0]):\n",
    "    f1 = scp.Optimize(log_level=\"WARNING\",)\n",
    "    f1.script = script\n",
    "    f1.max_iter = 2000\n",
    "    f1.fit(scp_corrected[i, :])\n",
    "\n",
    "    # # Show the result\n",
    "    # scp_corrected[i, :].plot()\n",
    "    # ax = (f1.components[:]).plot(clear=False)\n",
    "    # ax.autoscale(enable=True, axis=\"y\")\n",
    "\n",
    "    # # plotmerit\n",
    "    # som = f1.inverse_transform()\n",
    "    # f1.plotmerit(offset=0, kind=\"scatter\")\n",
    "    recon_scp_corrected = f1.inverse_transform()\n",
    "    # display(recon_scp_corrected)\n",
    "    peaks = recon_scp_corrected[6490.0:6500.0].find_peaks(distance=10)[0].x.data\n",
    "    peakslist.append(peaks)\n",
    "# pd.DataFrame(peakslist).plot()\n",
    "peakslist = pd.DataFrame(peakslist)\n",
    "\n",
    "# 面积\n",
    "ref = scp_corrected[2].copy()\n",
    "diff = scp_corrected[:] - ref\n",
    "diff_area = diff.abs().trapezoid(dim=\"x\")\n",
    "# _ = diff_area.plot()\n",
    "\n",
    "# 保存数据\n",
    "scp_corrected.to_xarray().to_pandas().T.to_csv(path.joinpath(path_filetype_folder, f'all_spectrum_{filetype}.csv'), header=True,)\n",
    "pd.concat([peakslist, df_std['peak_std'], pd.DataFrame(diff_area.data), df_std['area_std']], \n",
    "          axis=1, ignore_index=True,).to_csv(path.joinpath(path_filetype_folder, f'all_peak_area_{filetype}.csv'),\n",
    "                                             index=False, header=[r'peak', r'std', r'area', r'std'],)\n",
    "\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf45a4-bfcc-461e-9f71-9bfdd448a4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_out_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Results\\Version-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068448f-b9e0-496b-be3c-20f0b2020838",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Peak + std, area + std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3901b-3121-4ea8-bcbe-aafd63d0cc5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "filetype = r'mean'\n",
    "path_file = path.joinpath(path_out_folder, filetype)\n",
    "path_file.mkdir(parents=True, exist_ok=True,)\n",
    "path_filelist = list(path_file.glob(f'all_*_{filetype}.csv'))\n",
    "path_filelist = path_filelist[0:]\n",
    "display(path_filelist)\n",
    "\n",
    "data_merge = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(file, comment='#', sep=r',', header=0, index_col=None)\n",
    "    data_merge = pd.concat([data_merge, data], axis=1, ignore_index=True,)\n",
    "# display(data_merge.head(13))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(10.5, 3.3))\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1], height_ratios=[1],\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'R3_MnO', r'R4_Mn2O3', r'R5_MnO2', r'S1_pristine', r'S2_1stDisch',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "# 图 A: energy peak + std\n",
    "energy = data_merge.iloc[:, 0:2].copy().dropna()\n",
    "subfig_a = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_a.add_axes((0, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot(energy.iloc[:, 0], lw=1, ls='-', marker='o', zorder=5, color=colors[0])\n",
    "ax.fill_between(x=np.arange(energy.shape[0]), y1=(energy.iloc[:, 0] + energy.iloc[:, 1]),\n",
    "                y2=(energy.iloc[:, 0] - energy.iloc[:, 1]), color=colors[2], alpha=0.3)\n",
    "\n",
    "ax.set_ylim(6492.4, 6493.3)  # ax.set_ylim(6492.1, 6493.7)\n",
    "ax.set_xticks(np.arange(energy.shape[0]), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'Energy (eV)', fontsize=11)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=6492.0, ymax=6493.9, linestyles='dashed', alpha=0.8)\n",
    "# ax.text(0.02, 0.98, r'1$^{st}$ moment $\\mathit{K \\beta _{1,3}}$', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.3, 1.0, r'A', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 B: area + std\n",
    "area = data_merge.iloc[:, 2:4].copy().dropna()\n",
    "subfig_b = fig.add_subfigure(gs[0, 1], zorder=0)\n",
    "ax = subfig_b.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot((area.iloc[:, 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3, linewidth=1, linestyle='-', marker='o', zorder=5, color=colors[0])\n",
    "y1 = (area.iloc[:, 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y2 = (area.iloc[:, 0]-area.iloc[4, 0] - area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "# display(y1, y2)\n",
    "ax.fill_between(x=np.arange(area.shape[0]), y1=y1, y2=y2, color=colors[2], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "ax.set_ylim(2.7, 5.1)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.4))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.2))\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=1.7, ymax=5.3, linestyles='dashed')\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.22, 1.0, r'B', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 C: Spectrum\n",
    "spectrum = data_merge.iloc[:, 4:].copy().dropna()\n",
    "subfig_c = fig.add_subfigure(gs[0, 2], zorder=0)\n",
    "ax = subfig_c.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0, 1.0, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_file, f'all_{filetype}.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e850f5-5b17-49fe-87fd-4f99ad715026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "filetype = r'mean'\n",
    "path_file = path.joinpath(path_out_folder, filetype)\n",
    "path_file.mkdir(parents=True, exist_ok=True,)\n",
    "path_filelist = list(path_file.glob(f'all_*_{filetype}.csv'))\n",
    "path_filelist = path_filelist[0:]\n",
    "display(path_filelist)\n",
    "\n",
    "data_merge = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(file, comment='#', sep=r',', header=0, index_col=None)\n",
    "    data_merge = pd.concat([data_merge, data], axis=1, ignore_index=True,)\n",
    "# display(data_merge.head(13))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None,\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'$\\mathrm{Ref.MnO}$', r'$\\mathrm{Ref.Mn_2O_3}$', r'$\\mathrm{Ref.MnO_2}$', r'Pristine', r'Discharge',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "\n",
    "# 图 C: Spectrum\n",
    "spectrum = data_merge.iloc[:, 4:].copy().dropna()\n",
    "subfig_c = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_c.add_axes((0, 0, 1.0, 1.0), zorder=0)\n",
    "ax.set_box_aspect(0.8)\n",
    "\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0.0, 0.5, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "# ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, f'all_{filetype}abaa.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9df68-fcd0-4bfa-b92f-beac3c462fac",
   "metadata": {},
   "source": [
    "#### 单张图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5dbc2-f9c4-4f76-a9da-3c63a2e9cdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [r'Pristine', r'$1^{st}$ Discharge', r'$1^{st}$ Charge', r'$2^{nd}$ Discharge']\n",
    "\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "ax = fig.add_subplot()\n",
    "area = data_merge.iloc[:, 2:4].copy().dropna()\n",
    "\n",
    "y= (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = y1.dropna()\n",
    "yerror = y-y1\n",
    "\n",
    "ax.errorbar(x=np.arange(y.shape[0]), y=y.dropna().values, yerr=yerror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "ax.set_ylim(2.4, 3.6)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.3))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.15))\n",
    "\n",
    "ax.text(0.02, 0.07, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "d = (area.iloc[[5,6,9,11], 0]-area.iloc[2, 0])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "d1 =(area.iloc[[5,6,9,11], 0]-area.iloc[2, 0] + area.iloc[:, 1])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "derror = (d1-d).dropna()\n",
    "ax2.errorbar(x=np.arange(derror.shape[0]), y=d.dropna().values, yerr=derror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax2.tick_params(axis='x', labelsize=9) \n",
    "ax2.tick_params(axis='y', labelsize=9, labelcolor='k')\n",
    "\n",
    "ax2.set_ylim(4.6, 3.4)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "ax2.set_ylabel(r'Average Mn Oxidation State', fontsize=11, color='k')  # Total Magnetization\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(path.joinpath(path_out, r'Kbeta_3.tif'), transparent=False,\n",
    "            pad_inches=0.05, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eef9fb-afa9-4ab3-b0f7-a1dab1feb496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Version-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc524a-da65-4bf2-93df-720c920c7d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "# %matplotlib ipympl\n",
    "import sys\n",
    "from IPython.display import display\n",
    "import spectrochempy as scp\n",
    "from spectrochempy import Coord, CoordSet, NDDataset, ur\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path as path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.colorbar import Colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ccc98-5f68-46a2-bc66-9708eef94ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9ae84-372e-4551-b9cd-38a0412bab42",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 读取数据并 denoise, 得到平均化，NMF 和 MCR 后的标样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad7b4-00a6-4974-991d-a639e9c97dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹\n",
    "path_data_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Data')\n",
    "path_out_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Results\\Version-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d86b9e-2ad5-4095-b797-ec74af39b5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取标样\n",
    "path_ref_filelist = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if (item.is_dir()) and (item.parts[-1] in ['R3_MnO', 'R5_MnO2']):\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        path_ref_filelist.append(file_dir)\n",
    "path_ref_filelist = path_ref_filelist[0:]\n",
    "# display(path_ref_filelist)\n",
    "\n",
    "for path_ref in path_ref_filelist:\n",
    "    ref_txt_data_merge = pd.DataFrame()\n",
    "    for filetxt in path_ref.glob(r'*.txt'):\n",
    "        ref_txt_data = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        ref_txt_data_merge = pd.concat([ref_txt_data_merge, ref_txt_data], axis=1, ignore_index=True,)\n",
    "    ref_txt_data_merge = ref_txt_data_merge.to_numpy()\n",
    "    ref_data_scp = NDDataset(data=ref_txt_data_merge[:, 1::2].T,\n",
    "                             author=\"Cheng Liu\",\n",
    "                             description=\"Kbeta of Mn, ALBA\",\n",
    "                             history=\"creation\",\n",
    "                             )\n",
    "    ref_data_scp.x = Coord(ref_txt_data_merge[:, 0], name='Energy', units=ur.eV,)\n",
    "    ref_data_scp.y = Coord(np.arange((ref_txt_data_merge[:, 1::2].shape[1])), name='numbers', )\n",
    "    # ref_data_scp.plot()\n",
    "\n",
    "    # PCA 重构数据\n",
    "    recon_ref_data_scp = scp.denoise(ref_data_scp, ratio=99.8,)\n",
    "    # recon_ref_data_scp.plot()\n",
    "\n",
    "    # 基线校准\n",
    "    blc = scp.Baseline(\n",
    "            log_level=\"INFO\",\n",
    "            model=\"polynomial\",  # use a polynomial model\n",
    "            order='linear',  # with linear method\n",
    "            ranges=([6462., 6463.], [6510., 6511.]),\n",
    "            )\n",
    "\n",
    "    _ = blc.fit(recon_ref_data_scp)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # scp_corrected.plot()\n",
    "\n",
    "    # Evolving Factor Analysis (EFA) 计算\n",
    "    efa = scp.EFA()\n",
    "    efa.fit(scp_corrected)\n",
    "    efa.n_components = 2\n",
    "    C0 = efa.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    St = efa.get_components()\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # # NMF\n",
    "    # scp_corrected -= scp_corrected.min()\n",
    "    # model = scp.NMF(n_components=2, log_level=\"INFO\")\n",
    "    # _ = model.fit(scp_corrected)\n",
    "    # C0 = model.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    # St = model.components\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # MCR\n",
    "    mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200,\n",
    "                     nonnegConc='all', nonnegSpec='all',\n",
    "                     )\n",
    "    mcr.fit(scp_corrected, St)\n",
    "    # _ = mcr.C.T.plot()\n",
    "    # _ = mcr.St.plot()\n",
    "\n",
    "    # MCR 归一化\n",
    "    mcr_st = mcr.St\n",
    "    inttrapz_area = mcr_st.trapezoid(dim=\"x\")\n",
    "    for i in range(mcr_st.shape[0]):\n",
    "        mcr_st[i, :] = np.divide(mcr_st[i, :], inttrapz_area[i])\n",
    "\n",
    "    # EFA 归一化\n",
    "    inttrapz_area = St.trapezoid(dim=\"x\")\n",
    "    for i in range(St.shape[0]):\n",
    "        St[i, :] = np.divide(St[i, :], inttrapz_area[i])\n",
    "\n",
    "    # MEAN\n",
    "    mean = scp.mean(recon_ref_data_scp.T, dim='y', keepdims=True,).T\n",
    "    _ = blc.fit(mean)   # fit the baseline\n",
    "    mean_baseline = blc.baseline\n",
    "    mean_corrected = blc.corrected  # get the corrected dataset\n",
    "    # mean_corrected.plot()\n",
    "\n",
    "    # MEAN 归一化\n",
    "    inttrapz_area = mean_corrected.trapezoid(dim=\"x\")\n",
    "    for i in range(mean_corrected.shape[0]):\n",
    "        mean_corrected[i, :] = np.divide(mean_corrected[i, :], inttrapz_area[i])\n",
    "\n",
    "    # # 画图\n",
    "    # ax = St[1].plot(c='r')\n",
    "    # mean_corrected.plot(ax=ax, clear=False, c='b')\n",
    "    # mcr_st[0].plot(ax=ax, clear=False, c='k')\n",
    "\n",
    "    # 保存数据\n",
    "    path_out_ref = path.joinpath(path_out_folder, r'references')\n",
    "    path_out_ref.mkdir(parents=True, exist_ok=True)\n",
    "    St[1].write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_efa.csv'),)\n",
    "    mean_corrected.write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_mean.csv'),)\n",
    "    mcr_st[0].write_csv(path.joinpath(path_out_ref, f'{path_ref.parts[-2]}_ref_mcr.csv'),)\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086db499-c286-4bc9-af44-5cbc2c7b032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# syntax for parameters definition :\n",
    "# name : value, low_bound,  high_bound\n",
    "#  * for fixed parameters\n",
    "#  $ for variable parameters\n",
    "#  > for reference to a parameter in the COMMON block\n",
    "#    (> is forbidden in the COMMON block)\n",
    "# common block parameters should not have a _ in their names\n",
    "#-----------------------------------------------------------\n",
    "#\n",
    "COMMON:\n",
    "# common parameters ex.\n",
    "# $ gwidth: 1.0, 0.0, none\n",
    "# $ gratio: 0.5, 0.0, 1.0\n",
    "# $ gasym: 0.3, 0.0, 1.0\n",
    "\n",
    "MODEL: LINE_1\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.12, 0.10, 0.16\n",
    "    $ pos:   6492.6, 6491.3, 9494.6\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "MODEL: LINE_2\n",
    "shape: asymmetricvoigtmodel\n",
    "    $ ampl:  0.03, 0.01, 0.05\n",
    "    $ pos:   6477.0, 6470.0, 6480.0\n",
    "    $ ratio: 0.5, 0.0, 1.0\n",
    "    $ asym: 0.5, 0.0, 1.0\n",
    "    $ width: 0.5, 0.0, 10\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce704-6cd0-4973-bc46-888092474468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script = \"\"\"\n",
    "\n",
    "# #-----------------------------------------------------------\n",
    "# # syntax for parameters definition :\n",
    "# # name : value, low_bound,  high_bound\n",
    "# #  * for fixed parameters\n",
    "# #  $ for variable parameters\n",
    "# #  > for reference to a parameter in the COMMON block\n",
    "# #    (> is forbidden in the COMMON block)\n",
    "# # common block parameters should not have a _ in their names\n",
    "# #-----------------------------------------------------------\n",
    "# #\n",
    "# COMMON:\n",
    "# # common parameters ex.\n",
    "\n",
    "# MODEL: linez\n",
    "# shape: asymmetricvoigtmodel\n",
    "# $ ampl: 0.12, 0.10, 0.16\n",
    "# $ width: 0.5, 0.0, 10\n",
    "# $ pos: 6492.6, 6492.4,  9493.5\n",
    "# $ ratio: 0.5, 0.0, 1.0\n",
    "# $ asym: 0.3, 0.0, 1.0\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db15221-5b25-4842-9eac-91fa414ab3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取归一化后的 ref 谱线\n",
    "filetype = r'efa'\n",
    "path_filetype_folder = path.joinpath(path_out_folder, filetype)\n",
    "path_filetype_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filelist_ref = list(path_out_ref.glob(f'R3_*_ref_{filetype}.csv'))\n",
    "# print(filelist_ref)\n",
    "data = pd.read_csv(filelist_ref[0], comment='#', sep=r',', header=0).to_numpy()\n",
    "ref = NDDataset(data=data[:, 1], title=r'Absorption', name=f'{filelist_ref[0].stem}',)\n",
    "ref.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "# ref.plot()\n",
    "\n",
    "# 读取数据文件夹\n",
    "filelist1 = []\n",
    "for item in path_data_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        file_dir = path.joinpath(item, r'Mn')\n",
    "        filelist1.append(file_dir)\n",
    "filelist1 = filelist1[0:]\n",
    "# print(filelist1)\n",
    "\n",
    "std_out = pd.DataFrame()\n",
    "for file in filelist1:\n",
    "    data = pd.DataFrame()\n",
    "    for filetxt in file.glob('*.txt'):\n",
    "        data_txt = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "        data = pd.concat([data, data_txt], axis=1, ignore_index=True,)\n",
    "    data = data.to_numpy()\n",
    "    scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "                         author=\"Cheng Liu\",\n",
    "                         description=\"Kbeta of Mn, ALBA\",\n",
    "                         history=\"creation\",\n",
    "                         )\n",
    "    scp_data.x = Coord(data[:, 0], name='Energy', units=ur.eV,)\n",
    "    scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), name='numbers', )\n",
    "    # scp_data.plot()\n",
    "\n",
    "    # PCA 重构数据\n",
    "    recon_scp_data = scp.denoise(scp_data, ratio=99.8,)\n",
    "    # print(recon_scp_data.shape)\n",
    "    # recon_scp_data.plot()\n",
    "\n",
    "    # 基线校准\n",
    "    blc = scp.Baseline(\n",
    "            log_level=\"INFO\",\n",
    "            model=\"polynomial\",  # use a polynomial model\n",
    "            order='linear',  # with linear method\n",
    "            ranges=([6462., 6463.], [6510., 6511.]),\n",
    "            )\n",
    "\n",
    "    _ = blc.fit(recon_scp_data)   # fit the baseline\n",
    "    scp_baseline = blc.baseline\n",
    "    scp_corrected = blc.corrected  # get the corrected dataset\n",
    "    # scp_corrected.plot()\n",
    "\n",
    "    # scp.plot_multiple(\n",
    "    #     method=\"scatter\",\n",
    "    #     ms=5,\n",
    "    #     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "    #     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "    #     legend=\"best\",\n",
    "    # )\n",
    "\n",
    "    # Evolving Factor Analysis (EFA) 计算\n",
    "    efa = scp.EFA()\n",
    "    efa.fit(scp_corrected)\n",
    "    efa.n_components = 2\n",
    "    # C0 = efa.transform()\n",
    "    # _ = C0.T.plot()\n",
    "    St = efa.get_components()\n",
    "    # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "    # MCR\n",
    "    mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200,\n",
    "                     nonnegConc='all', nonnegSpec='all',)\n",
    "    mcr.fit(scp_corrected, St)\n",
    "    # _ = mcr.C.T.plot()\n",
    "    # _ = mcr.St.plot()\n",
    "\n",
    "    # MCR 归一化\n",
    "    mcr_st = mcr.St\n",
    "    inttrapz_area = mcr_st.trapezoid(dim=\"x\")\n",
    "    for i in range(mcr_st.shape[0]):\n",
    "        mcr_st[i, :] = np.divide(mcr_st[i, :], inttrapz_area[i])\n",
    "\n",
    "    # EFA 归一化\n",
    "    inttrapz_EFA_ref = St.trapezoid(dim=\"x\")\n",
    "    # intsimps_EFA_ref = St.simpson(dim=\"x\")\n",
    "    for i in range(St.shape[0]):\n",
    "        St[i, :] = np.divide(St[i, :], inttrapz_EFA_ref[i])\n",
    "\n",
    "    # 平均值\n",
    "    mean = scp.mean(scp_corrected.T, dim='y', keepdims=True,).T\n",
    "    _ = blc.fit(mean)   # fit the baseline\n",
    "    mean_baseline = blc.baseline\n",
    "    mean_corrected = blc.corrected  # get the corrected dataset\n",
    "    # mean_corrected.plot()\n",
    "\n",
    "    # 平均值 归一化\n",
    "    inttrapz_MEAN_ref = mean_corrected.trapezoid(dim=\"x\")\n",
    "    # intsimps_MEAN_ref = mean_corrected.simpson(dim=\"x\")\n",
    "    for i in range(mean_corrected.shape[0]):\n",
    "        mean_corrected[i, :] = np.divide(mean_corrected[i, :], inttrapz_MEAN_ref[i])\n",
    "\n",
    "    # # 画图\n",
    "    # ax = St[1].plot(c='r')\n",
    "    # mean_corrected.plot(ax=ax, clear=False, c='b')\n",
    "    # mcr_st[0].plot(ax=ax, clear=False, c='k')\n",
    "\n",
    "    # 整体数据 归一化\n",
    "    inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "#     intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "    for i in range(scp_corrected.shape[0]):\n",
    "        scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "    # _ = scp_corrected.plot(lw=1.0, figure_figsize=(3.3, 2.5), clear=True,)\n",
    "\n",
    "    # 面积，以及 std 分布\n",
    "    # (scp_corrected[:]-ref).plot()\n",
    "    inttrapz_area = scp.abs(scp_corrected[:]-ref).trapezoid(dim=\"x\")\n",
    "    inttrapz_area_std = pd.DataFrame(inttrapz_area.data).std(ddof=0)\n",
    "    # inttrapz_area.plot()\n",
    "\n",
    "    # # 寻峰，以及 std 分布\n",
    "    # peakslist = [s.find_peaks(distance=10)[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "    # peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "    # # _ = pd.DataFrame(peakslist).plot()\n",
    "\n",
    "    # 寻峰，以及 std 分布，fitting 的办法\n",
    "    peakslist = []\n",
    "    for i in range(scp_corrected.shape[0]):\n",
    "        f1 = scp.Optimize(log_level=\"WARNING\",)\n",
    "        f1.script = script\n",
    "        f1.max_iter = 2000\n",
    "        f1.fit(scp_corrected[i, :])\n",
    "\n",
    "        # # Show the result\n",
    "        # scp_corrected[i, :].plot()\n",
    "        # ax = (f1.components[:]).plot(clear=False)\n",
    "        # ax.autoscale(enable=True, axis=\"y\")\n",
    "\n",
    "        # # plotmerit\n",
    "        # som = f1.inverse_transform()\n",
    "        # f1.plotmerit(offset=0, kind=\"scatter\")\n",
    "        recon_scp_corrected = f1.inverse_transform()\n",
    "        # display(recon_scp_corrected)\n",
    "        peaks = recon_scp_corrected[6490.0:6500.0].find_peaks(distance=10)[0].x.data\n",
    "        peakslist.append(peaks)\n",
    "    # pd.DataFrame(peakslist).plot()\n",
    "    peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "\n",
    "    std = pd.concat([peakstd, inttrapz_area_std], axis=1, ignore_index=True,)\n",
    "    std_out = pd.concat([std_out, std], axis=0, ignore_index=True,)\n",
    "\n",
    "    # 保存数据\n",
    "    path_file = path.joinpath(path_filetype_folder, file.parts[-2])\n",
    "    path_file.mkdir(parents=True, exist_ok=True)\n",
    "    St[1].write_csv(path.joinpath(path_file, f'{file.parts[-2]}_efa.csv'),)\n",
    "    mean_corrected.write_csv(path.joinpath(path_file, f'{file.parts[-2]}_mean.csv'),)\n",
    "    mcr_st[0].write_csv(path.joinpath(path_file, f'{file.parts[-2]}_mcr.csv'),)\n",
    "\n",
    "    (pd.concat([pd.Series(data[:, 0]), pd.DataFrame(scp_corrected.data).T], axis=1, ignore_index=True,).\n",
    "     to_csv(path.joinpath(path_file, f'{file.parts[-2]}_spectrum_norm.csv'), index=None, header=True,))\n",
    "    (pd.concat([pd.DataFrame(peakslist), pd.DataFrame(inttrapz_area.data)], axis=1, ignore_index=True,)\n",
    "     .to_csv(path.joinpath(path_file, f'{file.parts[-2]}_peak_area.csv'),\n",
    "             index=None, header=[f'{file.parts[-2]}_peak', f'{file.parts[-2]}_area']))\n",
    "\n",
    "std_out.to_csv(path.joinpath(path_filetype_folder, f'peak_area_std_{filetype}.csv'), index=False, header=[r'peak_std', r'area_std'],)\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd919e1-70d1-4ca2-8bd1-13ae78464a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取 std 文件\n",
    "\n",
    "std_file = list(path_filetype_folder.glob(f'*_{filetype}.csv'))\n",
    "df_std = pd.read_csv(std_file[0], index_col=None, header=0)\n",
    "\n",
    "# 读取所有的 filetype 文件路径\n",
    "filelist2 = []\n",
    "for item in path_filetype_folder.iterdir():\n",
    "    if item.is_dir():\n",
    "        file_dir = list(item.glob(f'*_{filetype}.csv'))\n",
    "        filelist2.append(file_dir)\n",
    "filelist2 = filelist2[0:]\n",
    "# print(filelist2)\n",
    "# 将所有 Raw Data 写入 NDDataset\n",
    "data = pd.DataFrame()\n",
    "for file in filelist2:\n",
    "    df = pd.read_csv(file[0], index_col=None, header=0)\n",
    "    data = pd.concat([data, df], axis=1, ignore_index=True,)\n",
    "data = data.to_numpy()\n",
    "scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "                     author=\"Cheng Liu\",\n",
    "                     description=\"Kbeta of Mn, ALBA\",\n",
    "                     history=\"creation\",\n",
    "                     title='Count',\n",
    "                     )\n",
    "scp_data.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), title='numbers', )\n",
    "# scp_data.plot()\n",
    "\n",
    "# 基线校准\n",
    "blc = scp.Baseline(\n",
    "        log_level=\"INFO\",\n",
    "        model=\"polynomial\",  # use a polynomial model\n",
    "        order='linear',  # with linear method\n",
    "        # ranges=([6462., 6465.], [6505., 6511.]),\n",
    "        ranges=([6462., 6463.], [6510., 6511.]),\n",
    "        )\n",
    "\n",
    "_ = blc.fit(scp_data)   # fit the baseline\n",
    "scp_baseline = blc.baseline\n",
    "scp_corrected = blc.corrected  # get the corrected dataset\n",
    "\n",
    "# scp.plot_multiple(\n",
    "#     method=\"scatter\",\n",
    "#     ms=5,\n",
    "#     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "#     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "#     legend=\"best\",\n",
    "# )\n",
    "\n",
    "# 计算面积\n",
    "inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "# intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "\n",
    "# scp.plot_multiple(\n",
    "#     method=\"scatter\",\n",
    "#     ms=5,\n",
    "#     datasets=[inttrapz_area,  intsimps_area],\n",
    "#     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#     legend=\"best\",\n",
    "# )\n",
    "\n",
    "# 归一化\n",
    "for i in range(scp_corrected.shape[0]):\n",
    "    scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "# _ = scp_corrected.plot(lw=1.0, figure_figsize=(3.3, 2.5), clear=True,)\n",
    "\n",
    "# # 寻峰\n",
    "# peakslist = [s.find_peaks(distance=10, )[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "# peakslist = pd.DataFrame(peakslist)\n",
    "# # _ = peakslist.plot(lw=1.0)\n",
    "\n",
    "# 寻峰，fitting 的办法\n",
    "peakslist = []\n",
    "for i in range(scp_corrected.shape[0]):\n",
    "    f1 = scp.Optimize(log_level=\"WARNING\",)\n",
    "    f1.script = script\n",
    "    f1.max_iter = 2000\n",
    "    f1.fit(scp_corrected[i, :])\n",
    "\n",
    "    # # Show the result\n",
    "    # scp_corrected[i, :].plot()\n",
    "    # ax = (f1.components[:]).plot(clear=False)\n",
    "    # ax.autoscale(enable=True, axis=\"y\")\n",
    "\n",
    "    # # plotmerit\n",
    "    # som = f1.inverse_transform()\n",
    "    # f1.plotmerit(offset=0, kind=\"scatter\")\n",
    "    recon_scp_corrected = f1.inverse_transform()\n",
    "    # display(recon_scp_corrected)\n",
    "    peaks = recon_scp_corrected[6490.0:6500.0].find_peaks(distance=10)[0].x.data\n",
    "    peakslist.append(peaks)\n",
    "# pd.DataFrame(peakslist).plot()\n",
    "peakslist = pd.DataFrame(peakslist)\n",
    "\n",
    "# 面积\n",
    "ref = scp_corrected[2].copy()\n",
    "diff = scp_corrected[:] - ref\n",
    "diff_area = diff.abs().trapezoid(dim=\"x\")\n",
    "# _ = diff_area.plot()\n",
    "\n",
    "# 保存数据\n",
    "scp_corrected.to_xarray().to_pandas().T.to_csv(path.joinpath(path_filetype_folder, f'all_spectrum_{filetype}.csv'), header=True,)\n",
    "pd.concat([peakslist, df_std['peak_std'], pd.DataFrame(diff_area.data), df_std['area_std']], \n",
    "          axis=1, ignore_index=True,).to_csv(path.joinpath(path_filetype_folder, f'all_peak_area_{filetype}.csv'),\n",
    "                                             index=False, header=[r'peak', r'std', r'area', r'std'],)\n",
    "\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7998c32-a4f3-4a71-8282-248847f30e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_out_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\αMnO2\\Kbeta\\2023-CLAESS\\Results\\Version-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8ebc6-1d76-42ac-8b71-af04e5527365",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Peak + std, area + std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bb397-c6c7-47cf-940b-8ec093445b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "filetype = r'mean'\n",
    "path_file = path.joinpath(path_out_folder, filetype)\n",
    "path_file.mkdir(parents=True, exist_ok=True,)\n",
    "path_filelist = list(path_file.glob(f'all_*_{filetype}.csv'))\n",
    "path_filelist = path_filelist[0:]\n",
    "display(path_filelist)\n",
    "\n",
    "data_merge = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(file, comment='#', sep=r',', header=0, index_col=None)\n",
    "    data_merge = pd.concat([data_merge, data], axis=1, ignore_index=True,)\n",
    "# display(data_merge.head(13))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(10.5, 3.3))\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 1], height_ratios=[1],\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'R3_MnO', r'R4_Mn2O3', r'R5_MnO2', r'S1_pristine', r'S2_1stDisch',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "# 图 A: energy peak + std\n",
    "energy = data_merge.iloc[:, 0:2].copy().dropna()\n",
    "subfig_a = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_a.add_axes((0, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot(energy.iloc[:, 0], lw=1, ls='-', marker='o', zorder=5, color=colors[0])\n",
    "ax.fill_between(x=np.arange(energy.shape[0]), y1=(energy.iloc[:, 0] + energy.iloc[:, 1]),\n",
    "                y2=(energy.iloc[:, 0] - energy.iloc[:, 1]), color=colors[2], alpha=0.3)\n",
    "\n",
    "ax.set_ylim(6492.4, 6493.3)  # ax.set_ylim(6492.1, 6493.7)\n",
    "ax.set_xticks(np.arange(energy.shape[0]), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'Energy (eV)', fontsize=11)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9)\n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=6492.0, ymax=6493.9, linestyles='dashed', alpha=0.8)\n",
    "# ax.text(0.02, 0.98, r'1$^{st}$ moment $\\mathit{K \\beta _{1,3}}$', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.3, 1.0, r'A', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 B: area + std\n",
    "area = data_merge.iloc[:, 2:4].copy().dropna()\n",
    "subfig_b = fig.add_subfigure(gs[0, 1], zorder=0)\n",
    "ax = subfig_b.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "\n",
    "ax.plot((area.iloc[:, 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3, linewidth=1, linestyle='-', marker='o', zorder=5, color=colors[0])\n",
    "y1 = (area.iloc[:, 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y2 = (area.iloc[:, 0]-area.iloc[4, 0] - area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "# display(y1, y2)\n",
    "ax.fill_between(x=np.arange(area.shape[0]), y1=y1, y2=y2, color=colors[2], alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "ax.set_ylim(2.7, 5.1)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.4))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.2))\n",
    "\n",
    "ax.vlines(x=4, colors='k', ymin=1.7, ymax=5.3, linestyles='dashed')\n",
    "ax.text(0.02, 0.1, r'References', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(0.58, 0.95, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "ax.text(-0.22, 1.0, r'B', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "# 图 C: Spectrum\n",
    "spectrum = data_merge.iloc[:, 4:].copy().dropna()\n",
    "subfig_c = fig.add_subfigure(gs[0, 2], zorder=0)\n",
    "ax = subfig_c.add_axes((0.01, 0, 0.8, 0.8), zorder=0)\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0, 1.0, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-1):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 1+i], lw=1, label=labels[i], color=colormap.colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_file, f'all_{filetype}.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a1b53-3a29-48b6-ad6c-89e9b6bc2e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取数据文件夹以及文件\n",
    "filetype = r'mean'\n",
    "path_file = path.joinpath(path_out_folder, filetype)\n",
    "path_file.mkdir(parents=True, exist_ok=True,)\n",
    "path_filelist = list(path_file.glob(f'all_*_{filetype}.csv'))\n",
    "path_filelist = path_filelist[0:]\n",
    "display(path_filelist)\n",
    "\n",
    "data_merge = pd.DataFrame()\n",
    "for file in path_filelist:\n",
    "    data = pd.read_csv(file, comment='#', sep=r',', header=0, index_col=None)\n",
    "    data_merge = pd.concat([data_merge, data], axis=1, ignore_index=True,)\n",
    "# display(data_merge.head(13))\n",
    "\n",
    "# 画图\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None,\n",
    "                       wspace=None, hspace=None, figure=fig)\n",
    "labels = [r'R1_MnOOH', r'R2_ZnMn2O4', r'$\\mathrm{Ref.MnO}$', r'$\\mathrm{Ref.Mn_2O_3}$', r'$\\mathrm{Ref.MnO_2}$', r'Pristine', r'Discharge',\n",
    "          r'S3_1stHCh_1p53V', r'S4_1stHCh_1p63V', r'S5_1stCh', r'S6_2ndDisch_1p3V', r'S7_2ndDisch']\n",
    "\n",
    "\n",
    "# 图 C: Spectrum\n",
    "spectrum = data_merge.iloc[:, 4:].copy().dropna()\n",
    "subfig_c = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig_c.add_axes((0, 0, 1.0, 1.0), zorder=0)\n",
    "ax.set_box_aspect(0.8)\n",
    "\n",
    "colormap = ListedColormap(mpl.colormaps['sunset'](np.linspace(0.0, 0.5, spectrum.shape[1]-1)), name=r'colormap')\n",
    "\n",
    "# 多线叠加\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    ax.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=5, alpha=1-0.01*i)\n",
    "\n",
    "ax.set_xlabel(r'Energy (eV)', fontsize=11, labelpad=3)\n",
    "ax.set_xlim(6460, 6510)\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "ax.set_ylabel(ylabel=r'Intensity (a.u.)', fontsize=11, labelpad=3)\n",
    "ax.set_ylim(0, 0.17)\n",
    "ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(base=0.04))\n",
    "ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(base=0.02))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=9) \n",
    "ax.tick_params(axis='y', labelsize=9)\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.01, 1.0), ncols=1, frameon=False,\n",
    "          labelcolor='linecolor', fontsize=8, columnspacing=0.5)\n",
    "# ax.text(-0.22, 1.0, r'C', weight='bold', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=13)\n",
    "\n",
    "axins = ax.inset_axes([0.78, 0.32, 0.2, 0.65])\n",
    "for i in range(spectrum.shape[1]-8):\n",
    "    axins.plot(spectrum.iloc[:, 0], spectrum.iloc[:, 3+i], lw=1, label=labels[i+2], color=colors[i], zorder=0, alpha=1-0.01*i)\n",
    "axins.set_xlim(6491, 6495)\n",
    "axins.spines.right.set_visible(False)\n",
    "axins.spines.bottom.set_visible(False)\n",
    "axins.spines.top.set_visible(False)\n",
    "axins.spines.left.set_visible(False)\n",
    "axins.set(xticks=[], xlabel=None, yticks=[], ylabel=None)\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, f'all_{filetype}abaa.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600)\n",
    "# plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea5c68-f778-49ac-ba4f-f0aebeac1047",
   "metadata": {},
   "source": [
    "#### 单张图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fd425-009d-4323-9741-0b3e9d90aebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [r'Pristine', r'$1^{st}$ Discharge', r'$1^{st}$ Charge', r'$2^{nd}$ Discharge']\n",
    "\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "ax = fig.add_subplot()\n",
    "area = data_merge.iloc[:, 2:4].copy().dropna()\n",
    "\n",
    "y= (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = (area.iloc[[5,6,9,11], 0]-area.iloc[4, 0] + area.iloc[:, 1])*(2/(area.iloc[2, 0] - area.iloc[4, 0]))+3\n",
    "y1 = y1.dropna()\n",
    "yerror = y-y1\n",
    "\n",
    "ax.errorbar(x=np.arange(y.shape[0]), y=y.dropna().values, yerr=yerror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
    "ax.set_ylabel(r'local magnetic moment ($\\mathrm{\\mu _B}$)', fontsize=11)  # Total Magnetization\n",
    "ax.set_ylim(2.4, 3.6)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(base=0.3))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.15))\n",
    "\n",
    "ax.text(0.02, 0.07, r'Charged States', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "d = (area.iloc[[5,6,9,11], 0]-area.iloc[2, 0])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "d1 =(area.iloc[[5,6,9,11], 0]-area.iloc[2, 0] + area.iloc[:, 1])*(2/(area.iloc[4, 0] - area.iloc[2, 0]))+2\n",
    "derror = (d1-d).dropna()\n",
    "ax2.errorbar(x=np.arange(derror.shape[0]), y=d.dropna().values, yerr=derror, linewidth=1, linestyle='-', marker='o', zorder=5, color='k', capsize=6)\n",
    "\n",
    "ax2.tick_params(axis='x', labelsize=9) \n",
    "ax2.tick_params(axis='y', labelsize=9, labelcolor='k')\n",
    "\n",
    "ax2.set_ylim(4.6, 3.4)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(base=0.2))\n",
    "ax2.yaxis.set_minor_locator(ticker.MultipleLocator(base=0.1))\n",
    "ax2.set_ylabel(r'Average Mn Oxidation State', fontsize=11, color='k')  # Total Magnetization\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.savefig(path.joinpath(path_out, r'Kbeta_3.tif'), transparent=False,\n",
    "            pad_inches=0.05, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32571283-d04c-438d-86dc-bb264cfc575c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Version-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94222df1-e45e-449c-96bc-e8966aa53763",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 读取数据并 denoise, 得到峰和面积的 std, 后面再平均化， NMF 和 MCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a72f12-62c0-4bdd-bbb1-ea56980ac6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读取数据文件夹\n",
    "# data_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\Kbeta\\2023-CLAESS\\Data')\n",
    "# filelist1 = []\n",
    "# for item in data_folder.iterdir():\n",
    "#     if item.is_dir():\n",
    "#         file_dir = path.joinpath(item, r'Mn')\n",
    "#         filelist1.append(file_dir)\n",
    "# filelist1 = filelist1[0:]\n",
    "# # print(filelist1)\n",
    "# std_out = pd.DataFrame()\n",
    "# for file in filelist1:\n",
    "#     data = pd.DataFrame()\n",
    "#     for filetxt in file.glob('*.txt'):\n",
    "#         data_txt = pd.read_csv(filetxt, comment='#', sep=r'\\s+', header=None)\n",
    "#         data = pd.concat([data, data_txt], axis=1, ignore_index=True,)\n",
    "#     data = data.to_numpy()\n",
    "#     scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "#                          author=\"Cheng Liu\",\n",
    "#                          description=\"Kbeta of Mn, ALBA\",\n",
    "#                          history=\"creation\",\n",
    "#                          )\n",
    "#     scp_data.x = Coord(data[:, 0], name='Energy', units=ur.eV,)\n",
    "#     scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), name='numbers', )\n",
    "#     # scp_data.plot()\n",
    "\n",
    "#     # PCA 重构数据\n",
    "#     recon_scp_data = scp.denoise(scp_data, ratio=99.8,)\n",
    "#     # print(recon_scp_data.shape)\n",
    "#     # recon_scp_data.plot()\n",
    "\n",
    "#     # 基线校准\n",
    "#     blc = scp.Baseline(\n",
    "#             log_level=\"INFO\",\n",
    "#             model=\"polynomial\",  # use a polynomial model\n",
    "#             order='linear',  # with linear method\n",
    "#             ranges=([6462., 6463.], [6510., 6511.]),\n",
    "#             )\n",
    "\n",
    "#     _ = blc.fit(scp_data)   # fit the baseline\n",
    "#     scp_baseline = blc.baseline\n",
    "#     scp_corrected = blc.corrected  # get the corrected dataset\n",
    "#     # scp_corrected.plot()\n",
    "#     # scp.plot_multiple(\n",
    "#     #     method=\"scatter\",\n",
    "#     #     ms=5,\n",
    "#     #     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "#     #     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "#     #     legend=\"best\",\n",
    "#     # )\n",
    "    \n",
    "#     # 寻峰，以及 std 分布\n",
    "#     peakslist = [s.find_peaks(distance=10)[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "#     pd.DataFrame(peakslist).to_csv(path.joinpath(file, f'{file.parts[-2]}_all_peaks.csv'),index=None, header=[f'{file.parts[-2]}_peaks'])\n",
    "#     peakstd = pd.DataFrame(peakslist).std(ddof=0)\n",
    "#     # _ = peakslist.plot()\n",
    "    \n",
    "#     # 计算面积，以及 std 分布\n",
    "#     inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "#     # intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "#     pd.DataFrame(inttrapz_area.data).to_csv(path.joinpath(file, f'{file.parts[-2]}_all_areas.csv'),index=None, header=[f'{file.parts[-2]}_areas'])\n",
    "#     inttrapz_area_std = pd.DataFrame(inttrapz_area.data).std(ddof=0)/np.mean(inttrapz_area.data)\n",
    "    \n",
    "#     # scp.plot_multiple(\n",
    "#     #     method=\"scatter\",\n",
    "#     #     ms=5,\n",
    "#     #     datasets=[inttrapz_area,  intsimps_area],\n",
    "#     #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#     #     legend=\"best\",\n",
    "#     # )\n",
    "#     std = pd.concat([peakstd, inttrapz_area_std], axis=1, ignore_index=True,)\n",
    "#     std_out = pd.concat([std_out, std], axis=0, ignore_index=True,)\n",
    "    \n",
    "#     # Evolving Factor Analysis (EFA) 计算\n",
    "#     efa = scp.EFA()\n",
    "#     efa.fit(recon_scp_data)\n",
    "#     efa.n_components = 2\n",
    "#     # C0 = efa.transform()\n",
    "#     # _ = C0.T.plot()\n",
    "#     St = efa.get_components()\n",
    "#     # _ = St.plot(title=\"components\", legend=St.k.labels)\n",
    "\n",
    "#     mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200,\n",
    "#                      nonnegConc='all', nonnegSpec='all',\n",
    "#                      )\n",
    "#     mcr.fit(recon_scp_data, St)\n",
    "#     # _ = mcr.C.T.plot()\n",
    "#     # _ = (mcr.St[1]/mcr.St[1].max()).plot()\n",
    "#     # _ = (St[1]/St[1].max()).plot(clear=False)\n",
    "#     # _ = (scp.mean(scp_data.T, dim='y')/scp.mean(scp_data.T, dim='y').max()).plot(clear=False)\n",
    "#     St[1].write_csv(path.joinpath(file, f'{file.parts[-2]}_NMF.csv'),)\n",
    "#     scp.mean(scp_data.T, dim='y').write_csv(path.joinpath(file, f'{file.parts[-2]}_MEAN.csv'),)\n",
    "#     mcr.St[1].write_csv(path.joinpath(file, f'{file.parts[-2]}_MCR.csv'),)\n",
    "    \n",
    "# std_out.to_csv(path.joinpath(data_folder, f'all_peak_std.csv'), index=False, header=[r'peak_std', r'area_std'],)\n",
    "# print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac6a88-028d-4606-b7eb-d32d9d75a437",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 平均化， NMF 和 MCR 数据 去背景，归一化，计算 IDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4652e3d-aa3f-4fd2-aef7-e866ece7e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读取 std 文件\n",
    "# # data_folder = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\XAS\\ExSitu\\Kbeta\\2023-CLAESS\\Data')\n",
    "# std_file = list(data_folder.glob(f'*_std.csv'))\n",
    "# df_std = pd.read_csv(std_file[0], index_col=None, header=0)\n",
    "\n",
    "# # 读取所有的 NMF 文件路径\n",
    "# filename = r'MEAN'\n",
    "# filelist2 = []\n",
    "# for item in data_folder.iterdir():\n",
    "#     if item.is_dir():\n",
    "#         file_dir = list(path.joinpath(item, r'Mn').glob(f'*_{filename}.csv'))\n",
    "#         filelist2.append(file_dir)\n",
    "# filelist2 = filelist2[0:]\n",
    "# # print(len(filelist2))\n",
    "# # 将所有 Raw Data 写入 NDDataset\n",
    "# data = pd.DataFrame()\n",
    "# for file in filelist2:\n",
    "#     df = pd.read_csv(file[0], index_col=None, header=0)\n",
    "#     data = pd.concat([data, df], axis=1, ignore_index=True,)\n",
    "# data = data.to_numpy()\n",
    "# scp_data = NDDataset(data=data[:, 1::2].T,\n",
    "#                      author=\"Cheng Liu\",\n",
    "#                      description=\"Kbeta of Mn, ALBA\",\n",
    "#                      history=\"creation\",\n",
    "#                      title='Count',\n",
    "#                      )\n",
    "# scp_data.x = Coord(data[:, 0], title='Energy', units=ur.eV,)\n",
    "# scp_data.y = Coord(np.arange((data[:, 1::2].shape[1])), title='numbers', )\n",
    "# # scp_data.plot()\n",
    "\n",
    "# # 基线校准\n",
    "# blc = scp.Baseline(\n",
    "#         log_level=\"INFO\",\n",
    "#         model=\"polynomial\",  # use a polynomial model\n",
    "#         order='linear',  # with linear method\n",
    "#         # ranges=([6462., 6465.], [6505., 6511.]),\n",
    "#         ranges=([6462., 6463.], [6510., 6511.]),\n",
    "#         )\n",
    "\n",
    "# _ = blc.fit(scp_data)   # fit the baseline\n",
    "# scp_baseline = blc.baseline\n",
    "# scp_corrected = blc.corrected  # get the corrected dataset\n",
    "\n",
    "# # scp.plot_multiple(\n",
    "# #     method=\"scatter\",\n",
    "# #     ms=5,\n",
    "# #     datasets=[scp_baseline[1], scp_corrected[1], scp_data[1]],\n",
    "# #     labels=[\"baseline\", \"corrected_data\", 'average_raw'],\n",
    "# #     legend=\"best\",\n",
    "# # )\n",
    "\n",
    "# # 计算面积\n",
    "# inttrapz_area = scp_corrected.trapezoid(dim=\"x\")\n",
    "# # intsimps_area = scp_corrected.simpson(dim=\"x\")\n",
    "\n",
    "# # scp.plot_multiple(\n",
    "# #     method=\"scatter\",\n",
    "# #     ms=5,\n",
    "# #     datasets=[inttrapz_area,  intsimps_area],\n",
    "# #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "# #     legend=\"best\",\n",
    "# # )\n",
    "\n",
    "# # 归一化\n",
    "# for i in range(scp_corrected.shape[0]):\n",
    "#     scp_corrected[i, :] = np.divide(scp_corrected[i, :], inttrapz_area[i])\n",
    "# scp_corrected.to_xarray().to_pandas().T.to_csv(path.joinpath(data_folder, f'all_spect_{filename}.csv'), header=True,)\n",
    "# _ = scp_corrected.plot(lw=1.0, figure_figsize=(3.3, 2.5), clear=True,)\n",
    "\n",
    "# # 寻峰\n",
    "# peakslist = [s.find_peaks(distance=10, )[0].x.data for s in scp_corrected[:, 6490.0:6500.0]]\n",
    "# peakslist = pd.DataFrame(peakslist)\n",
    "# _ = peakslist.plot(lw=1.0)\n",
    "\n",
    "# pd.concat([peakslist, df_std['peak_std']], \n",
    "#           axis=1, ignore_index=True,).to_csv(path.joinpath(data_folder, f'all_peak_std_{filename}.csv'),\n",
    "#                                              index=False, header=[r'peak', r'std'],)\n",
    "# # # 面积\n",
    "# # std = np.divide(df_std['area_std'].to_numpy(), inttrapz_area.data)\n",
    "# # diff_std = np.sqrt(std[:]**2 + std[2]**2)\n",
    "\n",
    "# # MNO = scp_corrected[2].copy()\n",
    "# # diff = scp_corrected[:] - MNO\n",
    "# # diff_area = diff.abs().trapezoid(dim=\"x\")\n",
    "# # _ = diff_area.plot()\n",
    "# print(r'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ef503-84a0-4d8e-af62-5eac588bf26f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Version-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805daa56-de47-4c0e-983e-b9b732238508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spectrochempy as scp\n",
    "# from spectrochempy import Coord, ur\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import ticker\n",
    "# import os\n",
    "# import glob\n",
    "# import matplotlib.transforms as transforms\n",
    "# import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d72a77-75bc-448e-86bb-eeb1382c89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_folder_names(folder_path):\n",
    "#     folder_names = []\n",
    "#     for entry in os.scandir(folder_path):\n",
    "#         if entry.is_dir():\n",
    "#             folder_names.append(entry.name)\n",
    "#     return folder_names\n",
    "\n",
    "# def create_folders(folder_out_path, folder_names):\n",
    "#     for folder_name in folder_names:\n",
    "#         folder_path = os.path.join(folder_out_path, folder_name)\n",
    "#         try:\n",
    "#             os.mkdir(folder_path)\n",
    "#             print(f\"Created folder: {folder_name}\")\n",
    "#         except OSError as e:\n",
    "#             print(f\"Failed to create folder: {folder_name} - Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0e46c-b8a7-4b5b-854b-d9431b357ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path=r'C:\\Users\\chengliu\\Desktop\\Done\\Ex Situ\\AA\\All\\Data'\n",
    "# file_key='*.txt'\n",
    "# folder_out_path=r'C:\\Users\\chengliu\\Desktop\\Done\\Ex Situ\\AA\\All\\Done'\n",
    "\n",
    "# folder_names = get_folder_names(folder_path)\n",
    "# # create_folders(folder_out_path, folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7ca51-fc23-4aa4-9847-1621aa97603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kbeta  A 框数据集\n",
    "\n",
    "# energy_max = pd.Series()\n",
    "# energy_max_A = pd.Series()\n",
    "# energy_max_B = pd.Series()\n",
    "\n",
    "# for foldername in folder_names:\n",
    "\n",
    "#     filelist = glob.glob(os.path.join(folder_path, foldername, 'Mn', file_key))\n",
    "#     # scan_out_folder = os.path.join(folder_out_path, foldername)\n",
    "\n",
    "#     AA = pd.Series()\n",
    "\n",
    "#     for filetxt in filelist:\n",
    "\n",
    "#         file_name = os.path.split(filetxt)[-1][:-4]\n",
    "\n",
    "#         # 读取单一文件\n",
    "#         data_A_txt = np.loadtxt(filetxt, comments='#')\n",
    "#         data_A_scp = scp.NDDataset(data=[data_A_txt[:, 1]], title='Intensity (counts)',\n",
    "#                                    author=\"Cheng Liu\",\n",
    "#                                    description=\"Kbeta of Mn, ALBA\",\n",
    "#                                    history=\"creation\")\n",
    "#         data_A_scp.x = Coord(data_A_txt[:, 0], title=\"Energy (eV)\")\n",
    "#         data_A_scp.y = Coord([0], title=\"Spectrum Number\")\n",
    "#         # display(data_A_scp)\n",
    "#         # _ = data_A_scp.plot(title=file_name)\n",
    "\n",
    "#         # 基线校准\n",
    "#         blc = scp.Baseline(\n",
    "#                             log_level=\"INFO\",\n",
    "#                             model=\"polynomial\",  # use a polynomial model\n",
    "#                             order='linear'  # with linear method\n",
    "#                             )\n",
    "#         # blc = scp.Baseline(\n",
    "#         #     log_level=\"INFO\",\n",
    "#         #     model=\"polynomial\",  # use a polynomial model\n",
    "#         #     order='linear',  # with linear method\n",
    "#         #     ranges=([6462., 6463.], [6510., 6511.]),\n",
    "#         #     )\n",
    "\n",
    "#         _ = blc.fit(data_A_scp)   # fit the baseline\n",
    "#         baseline_scp = blc.baseline\n",
    "#         corrected_scp = blc.corrected  # get the corrected dataset\n",
    "\n",
    "#         # scp.plot_multiple(\n",
    "#         #     method=\"scatter\",\n",
    "#         #     ms=5,\n",
    "#         #     datasets=[baseline_scp, corrected_scp, data_scp],\n",
    "#         #     labels=[\"baseline\", \"corrected_data\", 'data'],\n",
    "#         #     legend=\"best\",\n",
    "#         # )\n",
    "\n",
    "#         # 计算面积\n",
    "#         inttrapz_A = corrected_scp.trapezoid(dim=\"x\")\n",
    "#         # intsimps_A = corrected_scp.simpson(dim=\"x\")\n",
    "\n",
    "#         # scp.plot_multiple(\n",
    "#         #     method=\"scatter\",\n",
    "#         #     ms=5,\n",
    "#         #     datasets=[inttrapz_A,  intsimps_A],\n",
    "#         #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#         #     legend=\"best\",\n",
    "#         # )\n",
    "#         # display(inttrapz_A)\n",
    "\n",
    "#         # 归一化，并检查归一化后的数据面积是否为一\n",
    "#         data_norm = corrected_scp/inttrapz_A\n",
    "#         # data_norm = corrected_scp/intsimps_A\n",
    "#         # area_check = data_norm.simpson(dim=\"x\")\n",
    "#         # display(area_check)\n",
    "#         # display(data_norm)\n",
    "\n",
    "#         # 合并单一测试数据 且输出\n",
    "#         energy_pd = pd.Series(data=data_A_txt[:, 0], name='energy')\n",
    "#         data_norm_pd = pd.Series(data=data_norm.data.squeeze(), name='normalized_intensity')\n",
    "\n",
    "#         # (pd.concat([energy_pd, data_norm_pd], axis=1, ignore_index=False)\n",
    "#         #  .to_csv(os.path.join(scan_out_folder, f\"{file_name}.dat\"),\n",
    "#         #          header=True, index=None, sep=' '))\n",
    "\n",
    "#         # 合并同一样品的多组测试数据（已经归一化），名字为对应的 _norm_all.txt\n",
    "#         AA = pd.concat([AA, data_norm_pd], axis=1, ignore_index=False)\n",
    "#     data_norm_sum = pd.concat([energy_pd, AA.iloc[:, 1:]], axis=1, ignore_index=False)\n",
    "#     data_norm_sum.to_csv(os.path.join(folder_out_path, 'sample', f\"{foldername}_norm_all.dat\"), header=True, index=None, sep=',')\n",
    "#     # display(data_norm_sum)\n",
    "\n",
    "#     # 将每一个样本数据平均化，然后再归一化\n",
    "#     data_sum = scp.NDDataset(data=AA.iloc[:, 1:].to_numpy(), title='Intensity (counts)',\n",
    "#                              name='Normalized Data sum')\n",
    "#     data_sum.y = Coord(energy_pd.to_numpy(), title=\"Energy (eV)\")\n",
    "#     data_sum.x = Coord(np.arange(AA.shape[1]-1), title=\"Spectrum Number\")\n",
    "#     data_sum.swapdims('y', 'x', inplace=True)\n",
    "#     # display(data_sum)\n",
    "#     # _ =  data_sum.plot(title=f\"{foldername}_data_sum\")\n",
    "    \n",
    "#     # 单一样品 平均化\n",
    "#     data_average_A = scp.mean(data_sum, dim='x', keepdims=True)\n",
    "#     # display(data_average_A)\n",
    "#     # _ = data_average_A.plot()\n",
    "\n",
    "#     # 计算面积\n",
    "#     inttrapz_A2 = data_average_A.trapezoid(dim=\"y\")\n",
    "#     # intsimps_A2 = scp.simpson(data_average_A, dim=\"y\")\n",
    "\n",
    "#     # scp.plot_multiple(\n",
    "#     #     method=\"scatter\",\n",
    "#     #     ms=5,\n",
    "#     #     datasets=[inttrapz_A2, intsimps_A2],\n",
    "#     #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#     #     legend=\"best\",\n",
    "#     # )\n",
    "\n",
    "#     # 归一化，并检查归一化后的数据面积是否为一\n",
    "#     data_average_norm = data_average_A/inttrapz_A2\n",
    "#     # data_average_norm = data_average_A/intsimps_A2\n",
    "#     # area_check2 = data_average_norm.simpson(dim=\"y\")\n",
    "#     # display(area_check2)\n",
    "#     # _ = data_average_norm.plot()\n",
    "\n",
    "#     # 每个样品单一测试的 峰位置，以及 标准偏差\n",
    "#     positions = [s.find_peaks(distance=6)[0].y.values for s in data_sum[:, 6490.0: 6496.0]]\n",
    "#     energy_mean = scp.NDDataset(data=positions).mean()\n",
    "#     energy_std = scp.NDDataset(data=positions).std()\n",
    "#     energy = pd.DataFrame({'sample': f'{foldername}', \"energy_max\": [energy_mean], 'std': [energy_std]})\n",
    "#     energy_max = pd.concat([energy_max, energy], axis=0, ignore_index=False)\n",
    "\n",
    "#     # 画出单一样品的峰位置\n",
    "#     # peakslist = [s.find_peaks(distance=6)[0] for s in data_sum[:, 6490.0: 6496.0]]\n",
    "#     # ax = data_sum[:, 6490.0: 6496.0].plot()\n",
    "#     # for peaks in peakslist:\n",
    "#     #   peaks.plot_scatter(\n",
    "#     #       ax=ax,\n",
    "#     #       marker=\"v\",\n",
    "#     #       ms=3,\n",
    "#     #       color=\"red\",\n",
    "#     #       clear=False,\n",
    "#     #       data_only=True,\n",
    "#     #       ylim=(-0.01, 0.20),\n",
    "#     #   )\n",
    "\n",
    "#     # 对比一下与上述找到峰的 mean 的区别, 结论是有区别\n",
    "#     positions_A = [s.find_peaks(distance=6)[0].y.values for s in data_average_norm[:, 6490.0: 6496.0]]\n",
    "#     peak = pd.DataFrame({'sample': f'{foldername}', \"energy_average\": positions_A})\n",
    "#     energy_max_A = pd.concat([energy_max_A, peak], axis=0, ignore_index=False)\n",
    "\n",
    "#     # scp.plot_multiple(\n",
    "#     #     method=\"scatter\",\n",
    "#     #     ms=5,\n",
    "#     #     datasets=[[positions_A], energy_mean],\n",
    "#     #     labels=[\"average_peak\", \"data_mean_peak\"],\n",
    "#     #     legend=\"best\",\n",
    "#     # )\n",
    "\n",
    "#     # PCA 计算\n",
    "#     pca = scp.PCA()\n",
    "#     pca.fit(data_sum.T)\n",
    "#     # pca.printev()\n",
    "#     # _ = pca.screeplot()\n",
    "#     scores = pca.transform()\n",
    "#     # _ = pca.loadings.plot()\n",
    "#     # _ = pca.scores.T.plot()\n",
    "\n",
    "#     # Evolving Factor Analysis (EFA) 计算\n",
    "#     efa = scp.EFA()\n",
    "#     efa.fit(data_sum.T)\n",
    "#     efa.n_components = 2\n",
    "#     C0 = efa.transform()\n",
    "#     # _ = C0.T.plot()\n",
    "#     mcr = scp.MCRALS(max_iter=100, normSpec=\"euclid\", tol=0.0001, maxdiv=200)\n",
    "#     mcr.fit(data_sum.T, C0)\n",
    "\n",
    "#     # 输出 mcr als 成分的图像\n",
    "#     ax = mcr.C.T.plot()\n",
    "#     # _ = mcr.St.plot()\n",
    "#     plt.legend(loc='upper left', frameon=False, labelcolor='linecolor', labels=['component1', 'component2'])\n",
    "#     plt.savefig(os.path.join(folder_out_path, 'sample', f\"{foldername}_mcr_n=2.tif\"), dpi=600)\n",
    "#     plt.close()\n",
    "\n",
    "#     # MCR_ALS 结果归一化\n",
    "#     # 计算面积\n",
    "#     inttrapz_A3 = mcr.C.T[1, :].trapezoid(dim=\"y\")\n",
    "#     # intsimps_A3 = mcr.C.T[1, :].simpson(dim='y')\n",
    "\n",
    "#     # scp.plot_multiple(\n",
    "#     #     method=\"scatter\",\n",
    "#     #     ms=5,\n",
    "#     #     datasets=[inttrapz_A3, intsimps_A3],\n",
    "#     #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#     #     legend=\"best\",\n",
    "#     # )\n",
    "\n",
    "#     # 检查积分面积是否为归一化结果\n",
    "#     mcr_norm = mcr.C.T[1, :]/inttrapz_A3\n",
    "#     # mcr_norm = mcr.C.T[1, :]/intsimps_A3\n",
    "#     # area_check3 = mcr_norm.simpson(dim = 'y')\n",
    "#     # display(area_check3)\n",
    "#     # _ = mcr_norm.plot()\n",
    "\n",
    "#     # 比较归一化后的 平均化 和 MCR_ALS_norm 的结果\n",
    "#     ax = mcr_norm.plot(label='mcr_norm', color='blue', linewidth=1.5)\n",
    "#     ax.set_xlabel('Energy (eV)')\n",
    "#     ax.set_ylabel('Intensity(a.u.)')\n",
    "#     ax.set_title(f\"Kbeta, {foldername}\")\n",
    "#     _ = data_average_norm.plot(ax=ax, clear=False, data_only=True, label='average_norm', color='red', linewidth=1.5)\n",
    "#     plt.legend(loc='upper left', frameon=False, labelcolor='linecolor')\n",
    "#     plt.savefig(os.path.join(folder_out_path, 'sample', f\"{foldername}_average+mcr_norm.tif\"), dpi=600)\n",
    "#     plt.close()\n",
    "    \n",
    "#     # 将 mcr 的结果找到它的 peak\n",
    "#     positions_B = [s.find_peaks(distance=6)[0].y.values for s in  mcr_norm[:, 6490.0: 6496.0]]\n",
    "#     peak = pd.DataFrame({'sample': f'{foldername}', \"energy_mcr\": positions_B})\n",
    "#     energy_max_B = pd.concat([energy_max_B, peak], axis=0, ignore_index=False)\n",
    "\n",
    "#     # 输出结果\n",
    "\n",
    "#     # 输出每个样本平均化，归一化后的谱线数据， 以及 MCR-ALS 后 归一化的数据\n",
    "#     (pd.DataFrame({\"enegry\": energy_pd.to_numpy(), \"average_norm\": data_average_norm.data.squeeze(), \"mcr_norm\": mcr_norm.data.squeeze()})\n",
    "#      .to_csv(os.path.join(folder_out_path, 'sample',f\"{foldername}_average+mcr_norm.dat\"), header=True, index=None, sep = ' '))\n",
    "\n",
    "#     # 输出 MCR-ALS 成分的谱线数据\n",
    "#     (pd.concat([energy_pd, pd.DataFrame(mcr.C.data)], axis=1, ignore_index=False)\n",
    "#      .to_csv(os.path.join(folder_out_path, 'sample', f\"{foldername}_mcr_n=2.dat\"), header=['energy', 'n1', 'mcr_n2'], index=None, sep = ' '))\n",
    "\n",
    "# # 输出每个样品的峰位置 以及 标准误差，不基于 平均化的谱线\n",
    "# energy_max.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"energy_average_std.dat\"), header=True, index=None, sep = ' ')\n",
    "# # 输出每个样品的平均化的峰位置\n",
    "# energy_max_A.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"energy_average.dat\"), header=True, index=None, sep = ' ')\n",
    "# energy_max_B.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"energy_mcr.dat\"), header=True, index=None, sep = ' ')\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328af7a-bd49-48ac-8465-bed33548c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # averaged 的 HL 以及 标准偏差\n",
    "\n",
    "# average_path_list = glob.glob(os.path.join(folder_out_path, 'sample', r'*_average+mcr_norm.dat'))\n",
    "# spectrum_list = glob.glob(os.path.join(folder_out_path, 'sample', r'*_norm_all.dat'))\n",
    "# # display(average_path_list)\n",
    "# # display(spectrum_list)\n",
    "\n",
    "# BB = pd.Series(name='empty')\n",
    "# area_sum = pd.Series(name='empty')\n",
    "\n",
    "# for average_path in average_path_list:\n",
    "\n",
    "#     # 读取单一文件\n",
    "#     file_name = os.path.split(average_path)[-1][:-21]\n",
    "#     # display(file_name)\n",
    "\n",
    "#     average_pd = pd.read_csv(average_path, comment='#', header=None, skiprows=1,\n",
    "#                              names=['energy', file_name, 'std_norm'], sep='\\s+')\n",
    "#     # display(average_pd.head())\n",
    "\n",
    "#     # 合并\n",
    "#     BB = pd.concat([BB, average_pd], axis=1, ignore_index=False)\n",
    "# # display(BB.head())\n",
    "\n",
    "# average_sum_B = scp.NDDataset(data=BB.iloc[:, 2::3].to_numpy(), title='Intensity (counts)', name='average_sum')\n",
    "# average_sum_B.y = Coord(BB.iloc[:, 1].to_numpy(), title=\"Energy (eV)\")\n",
    "# average_sum_B.x = Coord(np.arange(BB.shape[1]/3-1), title=\"Spectrum Number\")\n",
    "# average_sum_B.swapdims('y', 'x', inplace=True)\n",
    "# # display(average_sum_B)\n",
    "# # _ = average_sum_B.plot(title=r'creay!')\n",
    "\n",
    "# average_MnO2 = average_sum_B[4, :].copy()\n",
    "# # display(average_MnO2)\n",
    "# # _ = average_MnO2.plot()\n",
    "\n",
    "# # 计算平均化谱线的差分\n",
    "# average_sum_B.data -= average_sum_B.data[4]\n",
    "# # display(average_sum_B)\n",
    "# # ax = average_sum_B.plot()\n",
    "# # plt.legend(loc='upper left', ncols=2, frameon=False, labelcolor='linecolor')\n",
    "# # plt.savefig(os.path.join(folder_out_path, \"average_HL_difference.tif\"), dpi=600)\n",
    "# # # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# # 计算平均化后的谱线的差分面积\n",
    "# inttrapz_B = (scp.abs(average_sum_B)).trapezoid(dim=\"y\")\n",
    "# intsimps_B = (scp.abs(average_sum_B)).simpson(dim='y')\n",
    "\n",
    "# # ax = scp.plot_multiple(\n",
    "# #     method=\"scatter\",\n",
    "# #     ms=5,\n",
    "# #     datasets=[inttrapz_B, intsimps_B],\n",
    "# #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "# #     legend=\"best\",\n",
    "# #     title=\"averaged spectrum difference area\"\n",
    "# # )\n",
    "# # plt.savefig(os.path.join(folder_out_path, \"average_HL_area.tif\"), dpi=600)\n",
    "# # # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# for data_list in spectrum_list:\n",
    "\n",
    "#     data_list_name = os.path.split(data_list)[-1][:-4]\n",
    "#     data_pd = pd.read_csv(data_list, comment='#', header=0, sep=',')\n",
    "#     spectrum_sum = scp.NDDataset(data=data_pd.iloc[:, 1:].to_numpy(), title='Intensity (counts)', name='spectrum_sum')\n",
    "#     spectrum_sum.y = Coord(data_pd.iloc[:, 0].to_numpy(), title=\"Energy (eV)\")\n",
    "#     spectrum_sum.x = Coord(np.arange(data_pd.shape[1]-1), title=\"Spectrum Number\")\n",
    "#     spectrum_sum.swapdims('y', 'x', inplace=True)\n",
    "#     # display(spectrum_sum)\n",
    "\n",
    "#     # 每个样品的每个测试结果 减去 LS MnO2 的平均值的谱线，得到每条谱线的差分谱线\n",
    "#     spectrum_sum.data = spectrum_sum.data - average_MnO2.data\n",
    "#     inttrapz_B2 = (scp.abs(spectrum_sum)).trapezoid(dim=\"y\")\n",
    "#     intsimps_B2 = (scp.abs(spectrum_sum)).simpson(dim='y')\n",
    "\n",
    "#     ax = scp.plot_multiple(\n",
    "#         method=\"scatter\",\n",
    "#         ms=5,\n",
    "#         datasets=[inttrapz_B2, intsimps_B2],\n",
    "#         labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#         legend=\"best\",\n",
    "#         title=f\"{data_list_name}_all_difference_area\"\n",
    "#     )\n",
    "#     plt.savefig(os.path.join(folder_out_path, 'sample', f\"{data_list_name}_all_HL_area.tif\"), dpi=600)\n",
    "#     plt.close()\n",
    "\n",
    "#     # 归一化，计算面积\n",
    "#     area_average = inttrapz_B2.mean()\n",
    "#     area_std = inttrapz_B2.std()\n",
    "#     # area_average = intsimps_B2.mean()\n",
    "#     # area_std = intsimps_B2.std()\n",
    "#     area = pd.DataFrame({'sample': f'{data_list_name}', \"area_average\": [area_average], 'std': [area_std]})\n",
    "#     area_sum = pd.concat([area_sum, area], axis=0, ignore_index=False)\n",
    "\n",
    "# # 输出结果\n",
    "\n",
    "# # 所有的样品平均化后的谱线，以备画图\n",
    "# BB.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"spectrum_averaged_all.dat\"), header=True, index=None, sep = ' ')\n",
    "\n",
    "# # 所有的平均化后的谱线的差分面积\n",
    "# (pd.DataFrame({\"area_HL\": intsimps_B.data.squeeze()})\n",
    "#  .to_csv(os.path.join(folder_out_path, \"area_average_HL.dat\"), header=True, index=None, sep=' '))\n",
    "# # (pd.DataFrame({\"area_HL\": inttrapz_B.data.squeeze()})\n",
    "# #  .to_csv(os.path.join(folder_out_path, \"area_average_HL.dat\"), header=True, index=None, sep=' '))\n",
    "\n",
    "# # 所有样品的差分面积，包括标准偏差\n",
    "# (area_sum.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"area_average_std_HL.dat\"), header=True, index=None, sep=' '))\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0a7ae-f86e-41b2-b48e-4877f0672bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mcr 的 HL 以及 标准偏差\n",
    "\n",
    "# average_path_list = glob.glob(os.path.join(folder_out_path, 'sample', r'*_average+mcr_norm.dat'))\n",
    "# spectrum_list = glob.glob(os.path.join(folder_out_path, 'Sample', r'*_norm_all.dat'))\n",
    "# # display(average_path_list)\n",
    "# # display(spectrum_list)\n",
    "\n",
    "# BB = pd.Series(name='empty')\n",
    "# area_sum = pd.Series(name='empty')\n",
    "\n",
    "# for average_path in average_path_list:\n",
    "\n",
    "#     # 读取单一文件\n",
    "#     file_name = os.path.split(average_path)[-1][:-21]\n",
    "#     # display(file_name)\n",
    "\n",
    "#     average_pd = pd.read_csv(average_path, comment='#', header=None, skiprows=1,\n",
    "#                              names=['energy', file_name, 'std_norm'], sep='\\s+')\n",
    "#     # display(average_pd.head())\n",
    "\n",
    "#     # 合并\n",
    "#     BB = pd.concat([BB, average_pd], axis=1, ignore_index=False)\n",
    "# # display(BB.head())\n",
    "\n",
    "# average_sum_B = scp.NDDataset(data=BB.iloc[:, 3::3].to_numpy(), title='Intensity (counts)', name='mcr_sum')\n",
    "# average_sum_B.y = Coord(BB.iloc[:, 1].to_numpy(), title=\"Energy (eV)\")\n",
    "# average_sum_B.x = Coord(np.arange(BB.shape[1]/3-1), title=\"Spectrum Number\")\n",
    "# average_sum_B.swapdims('y', 'x', inplace=True)\n",
    "# # display(average_sum_B)\n",
    "# # _ = average_sum_B.plot(title=r'creay!')\n",
    "\n",
    "# average_MnO2 = average_sum_B[4, :].copy()\n",
    "# # display(average_MnO2)\n",
    "# # _ = average_MnO2.plot()\n",
    "\n",
    "# # 计算平均化谱线的差分\n",
    "# average_sum_B.data -= average_sum_B.data[4]\n",
    "# # display(average_sum_B)\n",
    "# # ax = average_sum_B.plot()\n",
    "# # plt.legend(loc='upper left', ncols=2, frameon=False, labelcolor='linecolor')\n",
    "# # plt.savefig(os.path.join(folder_out_path, \"average_HL_difference.tif\"), dpi=600)\n",
    "# # # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# # 计算平均化后的谱线的差分面积\n",
    "# inttrapz_B = (scp.abs(average_sum_B)).trapezoid(dim=\"y\")\n",
    "# intsimps_B = (scp.abs(average_sum_B)).simpson(dim='y')\n",
    "\n",
    "# # ax = scp.plot_multiple(\n",
    "# #     method=\"scatter\",\n",
    "# #     ms=5,\n",
    "# #     datasets=[inttrapz_B, intsimps_B],\n",
    "# #     labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "# #     legend=\"best\",\n",
    "# #     title=\"averaged spectrum difference area\"\n",
    "# # )\n",
    "# # plt.savefig(os.path.join(folder_out_path, \"average_HL_area.tif\"), dpi=600)\n",
    "# # # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# for data_list in spectrum_list:\n",
    "\n",
    "#     data_list_name = os.path.split(data_list)[-1][:-4]\n",
    "#     data_pd = pd.read_csv(data_list, comment='#', header=0, sep=',')\n",
    "#     spectrum_sum = scp.NDDataset(data=data_pd.iloc[:, 1:].to_numpy(), title='Intensity (counts)', name='spectrum_sum')\n",
    "#     spectrum_sum.y = Coord(data_pd.iloc[:, 0].to_numpy(), title=\"Energy (eV)\")\n",
    "#     spectrum_sum.x = Coord(np.arange(data_pd.shape[1]-1), title=\"Spectrum Number\")\n",
    "#     spectrum_sum.swapdims('y', 'x', inplace=True)\n",
    "#     # display(spectrum_sum)\n",
    "\n",
    "#     # 每个样品的每个测试结果 减去 LS MnO2 的平均值的谱线，得到每条谱线的差分谱线\n",
    "#     spectrum_sum.data = spectrum_sum.data - average_MnO2.data\n",
    "#     inttrapz_B2 = (scp.abs(spectrum_sum)).trapezoid(dim=\"y\")\n",
    "#     intsimps_B2 = (scp.abs(spectrum_sum)).simpson(dim='y')\n",
    "\n",
    "#     ax = scp.plot_multiple(\n",
    "#         method=\"scatter\",\n",
    "#         ms=5,\n",
    "#         datasets=[inttrapz_B2, intsimps_B2],\n",
    "#         labels=[\"trapzoidal rule\", \"simpson' rule\"],\n",
    "#         legend=\"best\",\n",
    "#         title=f\"{data_list_name}_all_mcr_difference_area\"\n",
    "#     )\n",
    "#     plt.savefig(os.path.join(folder_out_path, 'sample', f\"{data_list_name}_all_mcr_HL_area.tif\"), dpi=600)\n",
    "#     plt.close()\n",
    "\n",
    "#     # 归一化，计算面积\n",
    "#     area_average = inttrapz_B2.mean()\n",
    "#     area_std = inttrapz_B2.std()\n",
    "#     # area_average = intsimps_B2.mean()\n",
    "#     # area_std = intsimps_B2.std()\n",
    "#     area = pd.DataFrame({'sample': f'{data_list_name}', \"area_average\": [area_average], 'std': [area_std]})\n",
    "#     area_sum = pd.concat([area_sum, area], axis=0, ignore_index=False)\n",
    "\n",
    "# # 输出结果\n",
    "\n",
    "# # 所有的样品平均化后的谱线，以备画图\n",
    "# BB.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"spectrum_mcr_all.dat\"), header=True, index=None, sep = ' ')\n",
    "\n",
    "# # 所有的平均化后的谱线的差分面积\n",
    "# (pd.DataFrame({\"area_HL\": intsimps_B.data.squeeze()})\n",
    "#  .to_csv(os.path.join(folder_out_path, \"area_mcr_HL.dat\"), header=True, index=None, sep=' '))\n",
    "# # (pd.DataFrame({\"area_HL\": inttrapz_B.data.squeeze()})\n",
    "# #  .to_csv(os.path.join(folder_out_path, \"area_average_HL.dat\"), header=True, index=None, sep=' '))\n",
    "\n",
    "# # 所有样品的差分面积，包括标准偏差\n",
    "# (area_sum.iloc[:, 1:].to_csv(os.path.join(folder_out_path, \"area_mcr_std_HL.dat\"), header=True, index=None, sep=' '))\n",
    "\n",
    "# print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
