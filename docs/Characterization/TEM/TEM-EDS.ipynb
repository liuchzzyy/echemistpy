{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import display\n",
    "from pathlib import Path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hyperspy.api as hs\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LinearSegmentedColormap, to_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画图的初始设置\n",
    "plt.style.use(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-python\\Figure\\liuchzzyy.mplstyle')\n",
    "# display(plt.style.available)\n",
    "\n",
    "# 颜色设定\n",
    "sys.path.append(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Python\\Figure')\n",
    "from colors import tol_cmap, tol_cset\n",
    "colors = list(tol_cset('vibrant'))\n",
    "if r'sunset' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('sunset'))\n",
    "if r'rainbow_PuRd' not in plt.colormaps():\n",
    "    plt.colormaps.register(tol_cmap('rainbow_PuRd')) # 备用 plasma\n",
    "\n",
    "# 输出的文件夹\n",
    "path_out = path(r\"C:\\Users\\chengliu\\Desktop\\Figure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "def add_sizebar(ax, size, data, color):\n",
    "    asb = AnchoredSizeBar(ax.transData,\n",
    "                          size / data.axes_manager[\"y\"].scale,\n",
    "                          '{} {}'.format(size, data.axes_manager['y'].units),\n",
    "                          loc='lower left',\n",
    "                          pad=0.1, borderpad=0.5, sep=0.5,\n",
    "                          frameon=False,\n",
    "                          color=color,\n",
    "                         label_top=True)\n",
    "    ax.add_artist(asb)\n",
    "        \n",
    "def transparent_single_color_cmap(color):\n",
    "    \"\"\"Return a single color matplotlib cmap with the transparency increasing\n",
    "    linearly from 0 to 1.\"\"\"\n",
    "    return LinearSegmentedColormap.from_list(\"\", [to_rgba(color, 0), to_rgba(color, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_file = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\TEM\\ExSitu\\αMnO2\\Charge\\1st0.9V\\αMnO2 + PVDF + SP\\1M ZnSO4 + 1M MnSO4\\2024-EMCA\\EDS\\0003 - B8_HAADF_67000_x')\n",
    "file = path.joinpath(path_file, r'Data', r'0003 - B8_HAADF_67000_x.emd')\n",
    "data = hs.load(file) # type: ignore\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in data:\n",
    "    if len(file.axes_manager.shape) >= 2:\n",
    "        if len(file.axes_manager.navigation_shape) == 2:\n",
    "            if file.axes_manager.navigation_axes[0].units == r'µm':\n",
    "                file.axes_manager.convert_units(axes=\"navigation\", units='nm', same_units=True, factor=1000)\n",
    "        elif len(file.axes_manager.signal_shape) == 2:\n",
    "            if file.axes_manager.signal_axes[0].units == r'µm':\n",
    "                file.axes_manager.convert_units(axes=\"signal\", units='nm', same_units=True, factor=1000)\n",
    "\n",
    "    if len(file.axes_manager.shape) ==3:\n",
    "        if len(file.axes_manager.navigation_shape) == 2:\n",
    "            for axis in file.axes_manager.navigation_axes:\n",
    "                axis.offset = 0\n",
    "        elif len(file.axes_manager.signal_shape) == 2:\n",
    "            for axis in file.axes_manager.signal_axes:\n",
    "                axis.offset = 0\n",
    "\n",
    "data[-1].axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HADDF 图\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig.add_subplot()\n",
    "ax.set_position([0, 0, 1.0, 1.0])\n",
    "\n",
    "ax.imshow(data[5].data, cmap='gray', aspect=1.0) # HADDF\n",
    "add_sizebar(ax, 50, data[5], 'w')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, r'TEM_EDS_HADDF_600.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDS mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEM 图\n",
    "%matplotlib inline\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None, wspace=0, hspace=0, figure=fig)\n",
    "\n",
    "subfig = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfig.add_subplot()\n",
    "ax.set_position([0, 0, 1.0, 1.0])\n",
    "\n",
    "ax.imshow(data[4].data, cmap=transparent_single_color_cmap(colors[0]), aspect=1.0)\n",
    "ax.imshow(data[6].data, cmap=transparent_single_color_cmap(colors[1]), aspect=1.0)\n",
    "ax.imshow(data[10].data, cmap=transparent_single_color_cmap(colors[2]), aspect=1.0, alpha=1.0)\n",
    "add_sizebar(ax, 50, data[4], 'k')\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, labelbottom=False, labelleft=False,)\n",
    "\n",
    "# plt.savefig(path.joinpath(path_out, r'TEM_EDS_Mixed_Mappings_Mn_Zn_S_300_V0_0.tif'), pad_inches=0.05, bbox_inches='tight', dpi=300, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "# plt.savefig(path.joinpath(path_out, r'TEM_EDS_Mixed_Mappings_Mn_Zn_S_600_V0_0.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EDSsum quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from IPython.utils.io import capture_output\n",
    "\n",
    "def EDS_Fit(\n",
    "    data,\n",
    "    elements: List[str],\n",
    "    energy_range: Tuple[float, float] = (0.14, 10.0),\n",
    "    data_plot: bool = True,\n",
    "    offsetA: float = 1000,\n",
    "    colors: List[str] = colors[0:4],\n",
    "    axislims: Tuple[List[float], List[float]] = ([-0.01, 10.0], [-2000, 10000]),\n",
    "    tickers: Tuple[List[float], List[float]] = ([2, 1], [2000, 1000]),\n",
    "    save_data: bool = True,\n",
    "    output_dir: path = path_out,\n",
    "    output_name: str = \"Sum\"\n",
    ") -> None:\n",
    "    \"\"\"处理输入数据，创建并拟合模型\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 输入数据对象\n",
    "    elements : 需要分析的元素列表\n",
    "    energy_range : 能量范围筛选区间\n",
    "    data_plot : 是否绘制图表\n",
    "    offsetA : 残差曲线偏移量\n",
    "    xlims : X轴显示范围\n",
    "    ylims : Y轴显示范围\n",
    "    save_data : 是否保存数据\n",
    "    output_dir : 输出目录路径\n",
    "    \"\"\"\n",
    "    # 参数校验\n",
    "    if not isinstance(energy_range, tuple) or len(energy_range) != 2:\n",
    "        raise ValueError(\"energy_range must be a tuple of two floats\")\n",
    "    if not isinstance(elements, list):\n",
    "        raise TypeError(\"elements must be a list of strings\")\n",
    "\n",
    "    # 数据处理\n",
    "    spectrum = data.sum().isig[energy_range[0]:energy_range[1]].deepcopy()\n",
    "    spectrum.set_elements(elements)\n",
    "    model = spectrum.create_model()\n",
    "    \n",
    "    # 模型校准和拟合\n",
    "    model.fit_background()\n",
    "    # model.calibrate_energy_axis(calibrate='resolution')\n",
    "    model.calibrate_xray_lines('energy', bound=50)\n",
    "    model.calibrate_xray_lines('width', bound=10)\n",
    "    # model.calibrate_xray_lines('sub_weight', bound=10)\n",
    "    model.multifit()\n",
    "\n",
    "    # 计算定量结果（无论是否保存数据都需要）\n",
    "    intensities = [model.get_lines_intensity()[i] for i in [4,5,6,7,9,11,12]]\n",
    "    # K_Ka, Mn_Ka, Mn_La, O_Ka, S_Ka, Zn_Ka, Zn_La\n",
    "    kfactors = [0.606, 0.753, 1.84, 0.691, 0.585, 0.950, 1.23]  \n",
    "    quant = spectrum.quantification(\n",
    "        intensities, \n",
    "        method=\"CL\", \n",
    "        factors=kfactors, \n",
    "        plot_result=False, \n",
    "        composition_units=\"atomic\"\n",
    "    )\n",
    "\n",
    "    # 数据可视化\n",
    "    if data_plot:\n",
    "        plot_spectrum(\n",
    "            spectrum=spectrum,\n",
    "            model=model,\n",
    "            offsetA=offsetA,\n",
    "            colors=colors,\n",
    "            axislims=axislims,\n",
    "            tickers=tickers,\n",
    "            save_path=output_dir,\n",
    "            save_name=output_name\n",
    "        )\n",
    "\n",
    "    # 数据保存\n",
    "    if save_data:\n",
    "        save_quantification_data(\n",
    "            spectrum=spectrum,\n",
    "            model=model,\n",
    "            quant=quant,\n",
    "            save_path=output_dir,\n",
    "            save_name=output_name\n",
    "        )\n",
    "\n",
    "    # 保存参数细节\n",
    "    with capture_output() as captured:\n",
    "        model.print_current_values()\n",
    "\n",
    "    # 保存参数细节\n",
    "    with open(path.joinpath(output_dir, f'EDS_Model_Parameters_{output_name}.txt'), 'w') as file:\n",
    "        file.write(\"\\n\".join(create_attrs_dict(quant, displayA=True)))\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(str(captured.outputs[0].data['text/plain']))  \n",
    "\n",
    "    # 打印定量结果\n",
    "    print(\"\\n\".join(create_attrs_dict(quant, displayA=True)))\n",
    "\n",
    "    return None\n",
    "\n",
    "def plot_spectrum(\n",
    "    spectrum,\n",
    "    model,\n",
    "    offsetA: float,\n",
    "    colors: List[str],\n",
    "    axislims: Tuple[List[float], List[float]],\n",
    "    tickers: Tuple[List[float], List[float]],\n",
    "    save_path: path,\n",
    "    save_name: str,\n",
    ") -> None:\n",
    "    \n",
    "    save_path = path.joinpath(save_path, f'EDS_Fit_{save_name}_300.tif')\n",
    "\n",
    "    plt.close('all')\n",
    "    \"\"\"绘制光谱拟合结果\"\"\"\n",
    "    fitted_signal = model.as_signal()\n",
    "    energy_axis = spectrum.axes_manager[\"X-ray energy\"].axis\n",
    "    original_data = spectrum.data\n",
    "    fitted_data = fitted_signal.data\n",
    "    residual = original_data - fitted_data\n",
    "\n",
    "    fig = plt.figure(figsize=(3.3, 2.5), dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_position([0.15, 0.15, 0.8, 0.8])  # 调整边距\n",
    "\n",
    "    ax.plot(energy_axis, original_data, \"-\", color=colors[0], label=\"Experimental\")\n",
    "    ax.plot(energy_axis, fitted_data, \"--\", color=colors[1], label=\"Fit\")\n",
    "    ax.plot(energy_axis, residual - offsetA, \"--\", color=colors[2], label=\"Residuals\")\n",
    "\n",
    "    ax.set_xlabel(\"Energy (keV)\", fontsize=11)\n",
    "    ax.set_ylabel(\"Total Counts\", fontsize=11)\n",
    "    ax.set_xlim(axislims[0])\n",
    "    ax.set_ylim(axislims[1])\n",
    "\n",
    "    # 设置刻度\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(tickers[0][0]))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(tickers[0][1]))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(tickers[1][0]))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(tickers[1][1]))\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelsize=9)\n",
    "    ax.legend(\n",
    "        loc=\"upper right\",\n",
    "        frameon=False,\n",
    "        fontsize=9,\n",
    "        handlelength=1.5,\n",
    "        borderpad=0.2\n",
    "    )\n",
    "\n",
    "    plt.savefig(\n",
    "        save_path,\n",
    "        bbox_inches=\"tight\",\n",
    "        dpi=600,\n",
    "        transparent=False,\n",
    "        pil_kwargs={\"compression\": \"tiff_lzw\"}\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "def save_quantification_data(\n",
    "    spectrum,\n",
    "    model,\n",
    "    quant,\n",
    "    save_path: path,\n",
    "    save_name: str,\n",
    ") -> None:\n",
    "    \n",
    "    \"\"\"保存定量分析结果\"\"\"\n",
    "    # 创建数据集\n",
    "    energy_coord = model.as_signal().axes_manager[\"X-ray energy\"].axis\n",
    "    \n",
    "    datasets = [\n",
    "        xr.DataArray(\n",
    "            data=spectrum.data,\n",
    "            coords={\"Energy\": energy_coord},\n",
    "            dims=[\"Energy\"],\n",
    "            name=\"EDS_Sum_Data\"\n",
    "        ),\n",
    "        xr.DataArray(\n",
    "            data=model.as_signal().data,\n",
    "            coords={\"Energy\": energy_coord},\n",
    "            dims=[\"Energy\"],\n",
    "            name=\"EDS_Sum_Fit\",\n",
    "            attrs=create_attrs_dict(quant, displayA=False)\n",
    "        ),\n",
    "        xr.DataArray(\n",
    "            data=spectrum.data - model.as_signal().data,\n",
    "            coords={\"Energy\": energy_coord},\n",
    "            dims=[\"Energy\"],\n",
    "            name=\"EDS_Sum_Residuals\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 合并保存\n",
    "    xr.merge(datasets).to_netcdf(\n",
    "        path.joinpath(save_path, f\"EDS_Fit_{save_name}.NETCDF4\"),\n",
    "        engine=\"h5netcdf\"\n",
    "    )\n",
    "    \n",
    "    # 保存模型参数\n",
    "    model.save_parameters2file(path.joinpath(save_path, f\"EDS_Model_Parameters_{save_name}.npz\"))\n",
    "    model.save(path.joinpath(save_path, f\"EDS_Models_{save_name}\"), overwrite=True)\n",
    "\n",
    "def create_attrs_dict(quant, displayA: bool = False):\n",
    "    \"\"\"创建属性字典\"\"\"\n",
    "    # 使用更具可读性的变量名\n",
    "    k = quant[0].data[0]\n",
    "    mn_ka = quant[1].data[0]\n",
    "    mn_la = quant[2].data[0]\n",
    "    o = quant[3].data[0]\n",
    "    s = quant[4].data[0]\n",
    "    zn_ka = quant[5].data[0]\n",
    "    zn_la = quant[6].data[0]\n",
    "\n",
    "    # 计算各种比率\n",
    "    total_mn = mn_ka + mn_la\n",
    "    total_zn = zn_ka + zn_la\n",
    "    others_1 = 100 - k - mn_ka - o - s - zn_ka\n",
    "    others_2 = 100 - k - total_mn - o - s - total_zn\n",
    "\n",
    "    # 创建属性字典\n",
    "    params = {\n",
    "        \"Ratio_S_Zn_1\": s / zn_ka,\n",
    "        \"Ratio_K_Mn_1\": k / mn_ka,\n",
    "        \"Ratio_Zn_Mn_1\": zn_ka / mn_ka,\n",
    "        \"K_Mn_O_Zn_S_Others_1\": f\"{k}, {mn_ka}, {o}, {s}, {zn_ka}, {others_1}\",\n",
    "        \"Ratio_S_Zn_2\": s / total_zn,\n",
    "        \"Ratio_K_Mn_2\": k / total_mn,\n",
    "        \"Ratio_Zn_Mn_2\": total_zn / total_mn,\n",
    "        \"K_Mn_O_Zn_S_Others_2\": f\"{k}, {total_mn}, {o}, {s}, {total_zn}, {others_2}\",\n",
    "    }\n",
    "    if displayA:\n",
    "        lines = []\n",
    "        lines.append(f\"{'Ratio_at':20} | {'Value':>12}\")\n",
    "        lines.append(\"=\" * 40)\n",
    "        for key, value in params.items():\n",
    "            line = f\"{key:20} | {str(value):>12}\"\n",
    "            lines.append(line)\n",
    "    return lines if displayA else params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 考虑全局"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDS_Fit(\n",
    "    data=data[-1],\n",
    "    elements=['K', 'Mn', 'O', 'S', 'Si', 'Zn', 'C', 'Cu', 'Al', 'P'],\n",
    "    energy_range=(0.14, 10.0),\n",
    "    data_plot=True,\n",
    "    offsetA=500,\n",
    "    axislims=([-0.01, 10.0], [-1000, 4000]),\n",
    "    tickers=([2, 1], [1000, 500]),\n",
    "    save_data=True,\n",
    "    output_dir=path_out,\n",
    "    output_name=r\"Sum\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:46:16.784597Z",
     "iopub.status.busy": "2024-09-26T14:46:16.784597Z",
     "iopub.status.idle": "2024-09-26T14:46:16.798163Z",
     "shell.execute_reply": "2024-09-26T14:46:16.797060Z",
     "shell.execute_reply.started": "2024-09-26T14:46:16.784597Z"
    }
   },
   "source": [
    "#### 选择某些区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "data[5].plot()\n",
    "rectangular_roi_1 = hs.roi.RectangularROI(left=170, right=400, top=180, bottom=200)\n",
    "roi2D_1 = rectangular_roi_1.interactive(data[5], color=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "data[-1].plot()\n",
    "rectangular_roi_1 = hs.roi.RectangularROI(left=280, right=420, top=110, bottom=140)\n",
    "rectangular_roi_2 = hs.roi.RectangularROI(left=250, right=420, top=180, bottom=200)\n",
    "# rectangular_roi_3 = hs.roi.RectangularROI(left=730, right=1000, top=2200, bottom=2700)\n",
    "# rectangular_roi_4 = hs.roi.RectangularROI(left=2300, right=2700, top=1350, bottom=1650)\n",
    "\n",
    "roi2D_1 = rectangular_roi_1.interactive(data[-1], color=\"yellow\")\n",
    "roi2D_2 = rectangular_roi_2.interactive(data[-1], color=\"yellow\")\n",
    "# roi2D_3 = rectangular_roi_3.interactive(data[-1], color=\"yellow\")\n",
    "# roi2D_4 = rectangular_roi_4.interactive(data[-1], color=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(3.3, 2.5))\n",
    "gs = gridspec.GridSpec(1, 1, width_ratios=None, height_ratios=None,\n",
    "                        wspace=0, hspace=0, figure=fig)\n",
    "# 图 A\n",
    "subfiga = fig.add_subfigure(gs[0, 0], zorder=0)\n",
    "ax = subfiga.add_subplot()\n",
    "ax.set_position([0.0, 0, 1.0, 1.0])\n",
    "ax.imshow(data[6].data, cmap='gray',)\n",
    "add_sizebar(ax, 20, data[6], 'w')\n",
    "ax.set_axis_off()\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, labelbottom=False, labelleft=False,)\n",
    "\n",
    "rect1 = mpl.patches.Rectangle((int(rectangular_roi_1.x/data[-1].axes_manager[0].scale), int(rectangular_roi_1.y/data[-1].axes_manager[1].scale)), int(rectangular_roi_1.width/data[-1].axes_manager[0].scale), int(rectangular_roi_1.height/data[-1].axes_manager[1].scale), linewidth=1, edgecolor='y', facecolor='none', transform=ax.transData, zorder=5)\n",
    "rect2 = mpl.patches.Rectangle((int(rectangular_roi_2.x/data[-1].axes_manager[0].scale), int(rectangular_roi_2.y/data[-1].axes_manager[1].scale)), int(rectangular_roi_2.width/data[-1].axes_manager[0].scale), int(rectangular_roi_2.height/data[-1].axes_manager[1].scale), linewidth=1, edgecolor='y', facecolor='none', transform=ax.transData, zorder=5)\n",
    "# rect3 = mpl.patches.Rectangle((int(rectangular_roi_3.x/data[-1].axes_manager[0].scale), int(rectangular_roi_3.y/data[-1].axes_manager[1].scale)), int(rectangular_roi_3.width/data[-1].axes_manager[0].scale), int(rectangular_roi_3.height/data[-1].axes_manager[1].scale), linewidth=1, edgecolor='y', facecolor='none', transform=ax.transData, zorder=5)\n",
    "# rect4 = mpl.patches.Rectangle((int(rectangular_roi_4.x/data[-1].axes_manager[0].scale), int(rectangular_roi_4.y/data[-1].axes_manager[1].scale)), int(rectangular_roi_4.width/data[-1].axes_manager[0].scale), int(rectangular_roi_4.height/data[-1].axes_manager[1].scale), linewidth=1, edgecolor='y', facecolor='none', transform=ax.transData, zorder=5)\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)\n",
    "# ax.add_patch(rect3)\n",
    "# ax.add_patch(rect4)\n",
    "ax.text(rectangular_roi_1.x/data[-1].axes_manager[0].scale+10, rectangular_roi_1.y/data[-1].axes_manager[1].scale, r'Roi_1', fontsize=10, color='w', ha='center', va='center', transform=ax.transData)\n",
    "ax.text(rectangular_roi_2.x/data[-1].axes_manager[0].scale+10, rectangular_roi_2.y/data[-1].axes_manager[1].scale-5, r'Roi_2', fontsize=10, color='w', ha='center', va='center', transform=ax.transData)\n",
    "# ax.text(rectangular_roi_3.x/data[-1].axes_manager[0].scale, rectangular_roi_3.y/data[-1].axes_manager[1].scale-15, r'Roi_3', fontsize=10, color='w', ha='center', va='center', transform=ax.transData)\n",
    "# ax.text(rectangular_roi_4.x/data[-1].axes_manager[0].scale, rectangular_roi_4.y/data[-1].axes_manager[1].scale-50, r'Roi_4', fontsize=10, color='w', ha='center', va='center', transform=ax.transData)\n",
    "\n",
    "plt.savefig(path.joinpath(path_out, r'TEM_EDS_Selected_Regions_600.tif'), pad_inches=0.05, bbox_inches='tight', dpi=600, transparent=False, pil_kwargs={\"compression\": \"tiff_lzw\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDSsum Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = [roi2D_1, roi2D_2,]\n",
    "offsetA = [20, 20, 20]\n",
    "axislims = ([[-0.01, 10.0], [-50, 300]], [[-0.01, 10.0], [-40, 250]], )\n",
    "tickers = ([[2, 1], [60, 30]], [[2, 1], [50, 25]],)\n",
    "for i, file in enumerate(rois):\n",
    "    EDS_Fit(\n",
    "        data=file,\n",
    "        elements=['K', 'Mn', 'O', 'S', 'Si', 'Zn', 'C', 'Cu', 'Al', 'P'],\n",
    "        energy_range=(0.14, 10.0),\n",
    "        data_plot=True,\n",
    "        offsetA=offsetA[i],\n",
    "        axislims=axislims[i],\n",
    "        tickers=tickers[i],\n",
    "        save_data=True,\n",
    "        output_dir=path_out,\n",
    "        output_name=f\"roi2D_{i+1}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP_rn-C29YOQ",
    "tags": []
   },
   "source": [
    "### EDS-Sigma 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4362PEEZfpQB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入相关的包\n",
    "import sigma\n",
    "from sigma.utils import normalisation as norm\n",
    "from sigma.utils import visualisation as visual\n",
    "from sigma.utils.load import SEMDataset\n",
    "from sigma.utils.loadtem import TEMDataset\n",
    "from sigma.src.utils import same_seeds\n",
    "from sigma.src.dim_reduction import Experiment\n",
    "from sigma.models.autoencoder import AutoEncoder, VariationalAutoEncoder\n",
    "from sigma.src.segmentation import PixelSegmenter\n",
    "from sigma.gui import gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_file = path(r'C:\\Users\\chengliu\\OneDrive - UAB\\ICMAB-Data\\Zn-Mn\\Uno\\Result\\TEM\\ExSitu\\αMnO2\\Pristine\\αMnO2\\2023-EMCA\\EDS\\0007 - B2 HAADF\\Data')\n",
    "file = path.joinpath(path_file, r'0007 - B2 HAADF.emd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjAcFFVvi4Ej",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = TEMDataset(file)\n",
    "# 设置对应的元素\n",
    "data.set_xray_lines(['O_Ka', 'Mn_Ka', 'K_Ka', 'Cu_Ka', 'Zn_Ka', 'S_Ka', 'P_Ka', 'Si_Ka', 'Al_Ka'])\n",
    "# visual.plot_sum_spectrum(data.spectra)\n",
    "# 数据预处理\n",
    "# # Rebin both edx and bse dataset\n",
    "# data.rebin_signal(size=(7,7))\n",
    "# Remove the first peak until the energy of 0.1 keV\n",
    "data.remove_fist_peak(end=0.4)\n",
    "# normalisation to make the spectrum of each pixel summing to 1.\n",
    "data.peak_intensity_normalisation()\n",
    "# View the dataset (bse, edx etc.) again to check differences.\n",
    "visual.plot_sum_spectrum(data.spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVnf6Uy29YOW"
   },
   "outputs": [],
   "source": [
    "path_normalisation = path(path.joinpath(path_out_folder, file.stem))\n",
    "path_normalisation.mkdir(parents=True, exist_ok=True)\n",
    "# Normalise the dataset using the (optional) sequential three methods.\n",
    "data.normalisation([\n",
    "    # norm.neighbour_averaging,\n",
    "    norm.zscore,\n",
    "    norm.softmax,])\n",
    "# gui.view_intensity_maps(spectra=data.normalised_elemental_data,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NgJc6JT9YOW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Trainning Method 1: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Autoencoder = path.joinpath(path_normalisation, r'Autoencoder')\n",
    "path_Autoencoder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgajwhO3rNv1"
   },
   "outputs": [],
   "source": [
    "for testtype in ['eval', 'all']:\n",
    "    batch_size = 64\n",
    "    # The integer in this function can determine different initialised parameters of model (tuning sudo randomness)\n",
    "    # This can influence the result of dimensionality reduction and change the latent space.\n",
    "    same_seeds(1)\n",
    "\n",
    "    # set the folder path to save the model(the model will automatically save in the specified folder)\n",
    "    path_result_folder = path_AutoEncoder\n",
    "    # Set up the experiment, e.g. determining the model structure, dataset for training etc.\n",
    "    ex = Experiment(descriptor=f'softmax-100-{batch_size}-{testtype}-AutoEncoder',\n",
    "                    general_results_dir=path_result_folder,\n",
    "                    model=AutoEncoder,\n",
    "                    model_args={'hidden_layer_sizes':(512,256,128)},\n",
    "                    chosen_dataset=data.normalised_elemental_data,\n",
    "                    save_model_every_epoch=False)\n",
    "    # Train the model\n",
    "    # The recommended procedure is to run the 'train_eval' for hyperparameter selection, and 'train_all' for the final analysis.\n",
    "    ex.run_model(num_epochs=100, batch_size=batch_size, learning_rate=1e-4, weight_decay=0.0, task=f'train_{testtype}', criterion='MSE')\n",
    "    # 获得在 loss 的数据\n",
    "    if ex.task in ['train_eval']:\n",
    "        model_training_loss = ex.train_loss\n",
    "        model_validation_loss = ex.test_loss\n",
    "    else:\n",
    "        model_all_data_loss = ex.train_loss\n",
    "\n",
    "latent = ex.get_latent()\n",
    "# # (Optional) Load pre-trained Autoencoder\n",
    "# model_path = r'C:\\Users\\chengliu\\Desktop\\Cheng\\2024-05-07_Model-softmax\\params\\Model-softmax_epoch100'  # model path (the model path should be stored in the folder 'result_folder_path')\n",
    "# ex.load_trained_model(model_path)\n",
    "# latent = ex.get_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01LDBFyDs5B",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pixel segmentation Method 1: Gaussian mixture modelling (GMM) clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_list = PixelSegmenter.bic(latent=latent,\n",
    "             model='GaussianMixture',\n",
    "             n_components=14,\n",
    "             model_args={'random_state': 6, 'init_params':'kmeans'})\n",
    "# 确定大概分解成几个 clusters\n",
    "pd.DataFrame(bic_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"GaussianMixture\",\n",
    "                    method_args={'n_components': n_components, 'random_state': 6, 'init_params':'kmeans'})\n",
    "                    # can change random_state to different integer i.e. 10 or 0 to adjust the clustering result.\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "BIC_GMM_parameters = {'model':'GaussianMixture', 'n_components':14, 'random_state': 6, 'init_params':'kmeans', \n",
    "                      'method': \"GaussianMixture\", 'n_components': n_components, 'random_state': 6, 'init_params':'kmeans'}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_AutoEncoder, r'BIC_GMM.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, model_means = ps.model.means_, model_covariances = ps.model.covariances_, model_weights = ps.model.weights_,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, prob_maps=ps.prob_map, spectra_profiles=spectra_profiles, binary_map=binary_maps,\n",
    "         BIC_GMM_parameters=BIC_GMM_parameters, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2,3,4,5,6,7,8]\n",
    "with pd.ExcelWriter(path.joinpath(path_AutoEncoder, r'BIC_GMM_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pixel segmentation Method 2: HDBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning can be found https://scikit-learn.org/stable/auto_examples/cluster/plot_hdbscan.html#hyperparameter-robustness\n",
    "min_cluster_size, min_samples = 25, 25\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"HDBSCAN\",\n",
    "                    method_args=dict(min_cluster_size=min_cluster_size, min_samples=min_samples,\n",
    "                                     max_cluster_size=int(len(latent)/10),\n",
    "                                     cluster_selection_epsilon=2e-1))\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "HDBSCAN_parameters = {'method': \"HDBSCAN\", 'min_cluster_size':min_cluster_size,'min_samples':min_samples, 'max_cluster_size':'int(len(latent)/10)', 'cluster_selection_epsilon':2e-1}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_AutoEncoder, r'HDBSCAN.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, HDBSCAN_parameters = HDBSCAN_parameters, prob_maps=ps.prob_map,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, spectra_profiles=spectra_profiles, binary_map=binary_maps, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2,3,4,5,6,7,8]\n",
    "with pd.ExcelWriter(path.joinpath(path_AutoEncoder, r'HDBSCAN_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2,3]\n",
    "with pd.ExcelWriter(path.joinpath(path_UMAP, r'BIC_GMM_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOkwqm-5HflB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Trainning Method 2: VariationalAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_VariationalAutoEncoder = path.joinpath(path_normalisation, r'VariationalAutoEncoder')\n",
    "path_VariationalAutoEncoder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo18wAiZHflC"
   },
   "outputs": [],
   "source": [
    "for testtype in ['eval', 'all']:\n",
    "    batch_size = 64\n",
    "    # The integer in this function can determine different initialised parameters of model (tuning sudo randomness)\n",
    "    # This can influence the result of dimensionality reduction and change the latent space.\n",
    "    same_seeds(1)\n",
    "    \n",
    "    # set the folder path to save the model(the model will automatically save in the specified folder)\n",
    "    path_result_folder = path_VariationalAutoEncoder\n",
    "    # Set up the experiment, e.g. determining the model structure, dataset for training etc.\n",
    "    ex = Experiment(descriptor=f'softmax-100-{batch_size}-{testtype}-VariationalAutoEncoder',\n",
    "                    general_results_dir=path_result_folder,               \n",
    "                    model=VariationalAutoEncoder,\n",
    "                    model_args={'hidden_layer_sizes':(512,256,128)},\n",
    "                    chosen_dataset=data.normalised_elemental_data,\n",
    "                    save_model_every_epoch=False)\n",
    "    # Train the model\n",
    "    # The recommended procedure is to run the 'train_eval' for hyperparameter selection, and 'train_all' for the final analysis.\n",
    "    ex.run_model(num_epochs=100, batch_size=batch_size, learning_rate=1e-4, weight_decay=0.0, task=f'train_{testtype}', criterion='MSE')\n",
    "    # 获得在 loss 的数据\n",
    "    if ex.task in ['train_eval']:\n",
    "        model_training_loss = ex.train_loss\n",
    "        model_validation_loss = ex.test_loss\n",
    "    else:\n",
    "        model_all_data_loss = ex.train_loss\n",
    "        \n",
    "latent = ex.get_latent()\n",
    "# # (Optional) Load pre-trained Autoencoder\n",
    "# model_path = r'C:\\Users\\chengliu\\Desktop\\Cheng\\2024-05-07_Model-softmax\\params\\Model-softmax_epoch100'  # model path (the model path should be stored in the folder 'result_folder_path')\n",
    "# ex.load_trained_model(model_path)\n",
    "# latent = ex.get_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01LDBFyDs5B",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pixel segmentation Method 1: Gaussian mixture modelling (GMM) clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_list = PixelSegmenter.bic(latent=latent,\n",
    "             model='GaussianMixture',\n",
    "             n_components=14,\n",
    "             model_args={'random_state': 6, 'init_params':'kmeans'})\n",
    "# 确定大概分解成几个 clusters\n",
    "pd.DataFrame(bic_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"GaussianMixture\",\n",
    "                    method_args={'n_components':n_components, 'random_state': 6, 'init_params':'kmeans'})\n",
    "                    # can change random_state to different integer i.e. 10 or 0 to adjust the clustering result.\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "BIC_GMM_parameters = {'model':'GaussianMixture', 'n_components':14, 'random_state': 6, 'init_params':'kmeans', \n",
    "                      'method': \"GaussianMixture\", 'n_components': n_components, 'random_state': 6, 'init_params':'kmeans'}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_VariationalAutoEncoder, r'BIC_GMM.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, model_means = ps.model.means_, model_covariances = ps.model.covariances_, model_weights = ps.model.weights_,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, prob_maps=ps.prob_map, spectra_profiles=spectra_profiles, binary_map=binary_maps,\n",
    "         BIC_GMM_parameters=BIC_GMM_parameters, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4. Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "with pd.ExcelWriter(path.joinpath(path_VariationalAutoEncoder, r'BIC_GMM_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pixel segmentation Method 2: HDBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning can be found https://scikit-learn.org/stable/auto_examples/cluster/plot_hdbscan.html#hyperparameter-robustness\n",
    "min_cluster_size, min_samples = 25 , 25\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"HDBSCAN\",\n",
    "                    method_args=dict(min_cluster_size=min_cluster_size, min_samples=min_samples,\n",
    "                                     max_cluster_size=int(len(latent)/10),\n",
    "                                     cluster_selection_epsilon=2e-1))\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "HDBSCAN_parameters = {'method': \"HDBSCAN\", 'min_cluster_size':min_cluster_size,'min_samples':min_samples, 'max_cluster_size':'int(len(latent)/10)', 'cluster_selection_epsilon':2e-1}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_VariationalAutoEncoder, r'HDBSCAN.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, HDBSCAN_parameters = HDBSCAN_parameters, prob_maps=ps.prob_map,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, spectra_profiles=spectra_profiles, binary_map=binary_maps, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2,3]\n",
    "with pd.ExcelWriter(path.joinpath(path_UMAP, r'BIC_GMM_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWeg9UomrmzX"
   },
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2]\n",
    "with pd.ExcelWriter(path.joinpath(path_VariationalAutoEncoder, r'HDBSCAN_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvF1KgXrDs5B",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Trainning Method 3: UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_UMAP = path.joinpath(path_normalisation, r'UMAP')\n",
    "path_UMAP.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rLvu5azDs5B"
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "n_neighbors, min_dist = 50, 0.1\n",
    "# Parameter tuning can be found https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "data_umap = data.normalised_elemental_data.reshape(-1,len(data.feature_list))\n",
    "umap = UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        metric='euclidean'\n",
    "    )\n",
    "latent = umap.fit_transform(data_umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01LDBFyDs5B",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pixel segmentation Method 1: Gaussian mixture modelling (GMM) clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_list = PixelSegmenter.bic(latent=latent,\n",
    "             model='GaussianMixture',\n",
    "             n_components=14,\n",
    "             model_args={'random_state': 6, 'init_params':'kmeans'})\n",
    "# 确定大概分解成几个 clusters\n",
    "pd.DataFrame(bic_list).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=5\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"GaussianMixture\",\n",
    "                    method_args={'n_components':n_components, 'random_state': 6, 'init_params':'kmeans'})\n",
    "                    # can change random_state to different integer i.e. 10 or 0 to adjust the clustering result.\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "BIC_GMM_parameters = {'model':'GaussianMixture', 'n_components':14, 'random_state': 6, 'init_params':'kmeans', \n",
    "                      'method': \"GaussianMixture\", 'n_components': n_components, 'random_state': 6, 'init_params':'kmeans',\n",
    "                      'n_neighbors':n_neighbors, 'min_dist':min_dist, 'n_components':2, 'metric':'euclidean'}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_UMAP, r'BIC_GMM.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, model_means = ps.model.means_, model_covariances = ps.model.covariances_, model_weights = ps.model.weights_,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, prob_maps=ps.prob_map, spectra_profiles=spectra_profiles, binary_map=binary_maps,\n",
    "         BIC_GMM_parameters=BIC_GMM_parameters, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pixel segmentation Method 2: HDBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning can be found https://scikit-learn.org/stable/auto_examples/cluster/plot_hdbscan.html#hyperparameter-robustness\n",
    "min_cluster_size, min_samples = 300, 50\n",
    "ps = PixelSegmenter(latent=latent,\n",
    "                    dataset=data,\n",
    "                    method=\"HDBSCAN\",\n",
    "                    method_args=dict(min_cluster_size=min_cluster_size, min_samples=min_samples,\n",
    "                                     max_cluster_size=int(len(latent)/10),\n",
    "                                     cluster_selection_epsilon=2e-1))\n",
    "# visualise the latent space\n",
    "# gui.check_latent_space(ps=ps, ratio_to_be_shown=1.0, show_map=True)\n",
    "gui.view_clusters_sum_spectra(ps=ps, normalisation=True, spectra_range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意修改 parameter 参数\n",
    "HDBSCAN_parameters = {'n_neighbors':n_neighbors, 'min_dist':min_dist, 'n_components':2, 'metric':'euclidean',\n",
    "                      'method': \"HDBSCAN\", 'min_cluster_size':min_cluster_size,'min_samples':min_samples, 'max_cluster_size':'int(len(latent)/10)', 'cluster_selection_epsilon':2e-1}\n",
    "spectra_profiles = []\n",
    "binary_maps = []\n",
    "binary_map_indicess = []\n",
    "for i in range(ps.n_components):\n",
    "    binary_map, binary_map_indices, spectra_profile = ps.get_binary_map_spectra_profile(cluster_num=i, use_label=True)\n",
    "    spectra_profiles.append(spectra_profile[\"intensity\"])\n",
    "    binary_maps.append(binary_map)\n",
    "    binary_map_indicess.append(binary_map_indices)\n",
    "binary_maps = np.asarray(binary_maps)\n",
    "spectra_profiles = np.vstack(spectra_profiles)\n",
    "binary_map_indicess = np.asarray(binary_map_indicess, dtype=object)\n",
    "np.savez(path.joinpath(path_UMAP, r'HDBSCAN.npz'), energy=ps.energy_axis, raw_data= data.spectra.sum().data, normalised_elemental_data=data.normalised_elemental_data, peak_list=ps.peak_list,\n",
    "         peak_dict=list(ps.peak_dict.items()), latent=latent, bic=bic_list, labels=ps.labels, HDBSCAN_parameters = HDBSCAN_parameters, prob_maps=ps.prob_map,\n",
    "         model_training_loss = model_training_loss, model_validation_loss = model_validation_loss, model_all_data_loss = ex.train_loss, spectra_profiles=spectra_profiles, binary_map=binary_maps, binary_map_indices=binary_map_indicess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Unmixing cluster spectrums using Non-negative Matrix Fatorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me57SkqNrpSg"
   },
   "outputs": [],
   "source": [
    "number_clusters = [2,3,5,7,9]\n",
    "weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=2,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "gui.show_unmixed_weights_and_compoments(ps=ps, weights=weights, components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_clusters = [0,1,2,3]\n",
    "with pd.ExcelWriter(path.joinpath(path_UMAP, r'BIC_GMM_NMF.xlsx')) as writer:\n",
    "    n_components = 7 if 7 <= len(number_clusters)+1 else len(number_clusters)+1\n",
    "    for i in range(2, n_components):\n",
    "        weights, components = ps.get_unmixed_spectra_profile(clusters_to_be_calculated=number_clusters,\n",
    "                                                         n_components=i,\n",
    "                                                         normalised=True,\n",
    "                                                         method='NMF',\n",
    "                                                         method_args={'init':'nndsvd'})\n",
    "        (pd.concat([weights.reset_index(), pd.DataFrame(ps.energy_axis), components], axis=1, ignore_index=True,)\n",
    "         .to_excel(writer, sheet_name=f\"n_components_{i}\", header=True))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "txm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
